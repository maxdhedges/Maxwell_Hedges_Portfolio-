{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab433777-8d9d-40d8-8c6f-209b1486407c",
   "metadata": {},
   "source": [
    "# NHL ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5aa01ec1-8220-4da4-b27b-64dcadac1f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be791f38-cc15-4334-9782-0c553feb0c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157b7e82-422c-4e71-83d8-584ef5f1b2d6",
   "metadata": {},
   "source": [
    "### About the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031929e0-83dc-49a2-80d5-e53f734ff363",
   "metadata": {},
   "source": [
    "###### NHL Team Data for last 11 Season 2010-2021. Data Includes \n",
    "Team: TeamSeason: SeasonGP: Games PlayedW: WinsL: LossesT: TiesOT: Overtime LossesP: PointsP%: Point PctgRW: Regulation Wins (a Standings tiebreaker since 2019-20)ROW: Regulation Plus Overtime Wins (a Standings tiebreaker since 2010-11)S/O Win: Shootout Games Won (since 2005-06)GF: Goals ForGA: Goals AgainstGF/GP: Goals For Per Game PlayedGA/GP: Goals Against Per Game PlayedPP%: Power Play Percentage (since 1977-78)PK%: Penalty Kill Percentage (since 1977-78)Net PP%: Power Play Net PctNet PK%: Penalty Kill Net PctShots/GP: Shots For Per Game PlayedSA/GP: Shots Against Per Game PlayedFOW%: Faceoff Win Percentage (since 1997-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b7b481f-e4ea-4584-9335-af131dae7bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.read_csv(\"Summary (1).csv\")\n",
    "stats1=pd.read_csv(\"Summary (2).csv\")\n",
    "stats2=pd.read_csv(\"Summary (3).csv\")\n",
    "stats3=pd.read_csv(\"Summary (4).csv\")\n",
    "stats4=pd.read_csv(\"Summary (5).csv\")\n",
    "stats5=pd.read_csv(\"Summary (6).csv\")\n",
    "stats6=pd.read_csv(\"Summary (7).csv\")\n",
    "stats7=pd.read_csv(\"Summary (8).csv\")\n",
    "stats8=pd.read_csv(\"Summary (9).csv\")\n",
    "stats9=pd.read_csv(\"Summary (10).csv\")\n",
    "stats10=pd.read_csv(\"Summary (11).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e00f2748-6824-4ca5-ac80-3d84fc4462b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = stats.append(stats1, ignore_index = True)\n",
    "stats=stats.append(stats2,ignore_index = True)\n",
    "stats=stats.append(stats3,ignore_index = True)\n",
    "stats=stats.append(stats4,ignore_index = True)\n",
    "stats=stats.append(stats5,ignore_index = True)\n",
    "stats=stats.append(stats6,ignore_index = True)\n",
    "stats=stats.append(stats7,ignore_index = True)\n",
    "stats=stats.append(stats8,ignore_index = True)\n",
    "stats=stats.append(stats9,ignore_index = True)\n",
    "stats=stats.append(stats10,ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9e1e2ab-853b-455d-ad28-2b013c11bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats['cup']=0\n",
    "stats['rp']=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78dd89d-b2ec-425d-9c22-dcc221d02bae",
   "metadata": {},
   "source": [
    "## Add in Binary Varible if the Team won the Stanley Cup or Not, 1 if won 0 if did not Win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1501718d-d711-4a16-af3e-5233f09092f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [stats['Team'].eq(\"Tampa Bay Lightning\") & stats['Season'].eq(20202021),\n",
    "              stats['Team'].eq(\"Tampa Bay Lightning\") & stats['Season'].eq(20192020),\n",
    "              stats['Team'].eq(\"St. Louis Blues\") & stats['Season'].eq(20182019),\n",
    "              stats['Team'].eq(\"Washington Capitals\") & stats['Season'].eq(20172018),\n",
    "              stats['Team'].eq(\"Pittsburgh Penguins\") & stats['Season'].eq(20162017),\n",
    "              stats['Team'].eq(\"Pittsburgh Penguins\") & stats['Season'].eq(20152016),\n",
    "              stats['Team'].eq(\"Chicago Blackhawks\") & stats['Season'].eq(20142015),\n",
    "              stats['Team'].eq(\"Los Angeles Kings\") & stats['Season'].eq(20132014),\n",
    "              stats['Team'].eq(\"Chicago Blackhawks\") & stats['Season'].eq(20122013),\n",
    "              stats['Team'].eq(\"Los Angeles Kings\") & stats['Season'].eq(20112012),\n",
    "              stats['Team'].eq(\"Boston Bruins\") & stats['Season'].eq(20102011)]\n",
    "\n",
    "choices = [1,1,1,1,1,1,1,1,1,1,1]\n",
    "stats['cup'] = np.select(conditions, choices, default= stats['cup'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b3664a-1f54-43ce-9856-b1393a1ffa3b",
   "metadata": {},
   "source": [
    "### Add Multiclasication varible for how far in the Stanley cup Playoffs \n",
    "0- Did not make Playoffs \n",
    "1- made it to the first round \n",
    "2- made it to the 2nd round\n",
    "3- made it to the 3rd round \n",
    "4- made it to the final round "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2824700-fefe-4989-b21c-584490ba5667",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [stats['Team'].eq(\"Boston Bruins\") & stats['Season'].eq(20102011),\n",
    "             stats['Team'].eq(\"Washington Capitals\") & stats['Season'].eq(20102011),\n",
    "             stats['Team'].eq(\"New York Rangers\") & stats['Season'].eq(20102011),\n",
    "             stats['Team'].eq(\"Philadelphia Flyers\") & stats['Season'].eq(20102011),\n",
    "             stats['Team'].eq(\"Buffalo Sabres\") & stats['Season'].eq(20102011),\n",
    "             stats['Team'].eq(\"Montréal Canadiens\") & stats['Season'].eq(20102011),\n",
    "             stats['Team'].eq(\"Pittsburgh Penguins\") & stats['Season'].eq(20102011),\n",
    "             stats['Team'].eq(\"Tampa Bay Lightning\") & stats['Season'].eq(20102011),\n",
    "             stats['Team'].eq(\"Vancouver Canucks\") & stats['Season'].eq(20102011),\n",
    "             stats['Team'].eq(\"Chicago Blackhawks\") & stats['Season'].eq(20102011),\n",
    "             stats['Team'].eq(\"San Jose Sharks\") & stats['Season'].eq(20102011),\n",
    "             stats['Team'].eq(\"Los Angeles Kings\") & stats['Season'].eq(20102011),\n",
    "             stats['Team'].eq(\"Arizona Coyotes\") & stats['Season'].eq(20102011),\n",
    "             stats['Team'].eq(\"Detroit Red Wings\") & stats['Season'].eq(20102011),\n",
    "             stats['Team'].eq(\"Anaheim Ducks\") & stats['Season'].eq(20102011),\n",
    "             stats['Team'].eq(\"Nashville Predators\t\") & stats['Season'].eq(20102011)]\n",
    "              \n",
    "choices = [4,2,1,2,1,1,1,3,4,1,3,1,2,1,1,2]\n",
    "stats['rp'] = np.select(conditions, choices, default= stats['rp'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b00f799a-560e-4723-8a6f-2edaea5a43b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [stats['Team'].eq(\"Boston Bruins\") & stats['Season'].eq(20112012),\n",
    "             stats['Team'].eq(\"Washington Capitals\") & stats['Season'].eq(20112012),\n",
    "             stats['Team'].eq(\"New York Rangers\") & stats['Season'].eq(20112012),\n",
    "             stats['Team'].eq(\"Philadelphia Flyers\") & stats['Season'].eq(20112012),\n",
    "             stats['Team'].eq(\"Ottawa Senators\") & stats['Season'].eq(20112012),\n",
    "             stats['Team'].eq(\"Florida Panthers\") & stats['Season'].eq(20112012),\n",
    "             stats['Team'].eq(\"Pittsburgh Penguins\") & stats['Season'].eq(20112012),\n",
    "             stats['Team'].eq(\"St. Louis Blues\") & stats['Season'].eq(20112012),\n",
    "             stats['Team'].eq(\"Vancouver Canucks\") & stats['Season'].eq(20112012),\n",
    "             stats['Team'].eq(\"Chicago Blackhawks\") & stats['Season'].eq(20112012),\n",
    "             stats['Team'].eq(\"San Jose Sharks\") & stats['Season'].eq(20112012),\n",
    "             stats['Team'].eq(\"Los Angeles Kings\") & stats['Season'].eq(20112012),\n",
    "             stats['Team'].eq(\"Arizona Coyotes\") & stats['Season'].eq(20112012),\n",
    "             stats['Team'].eq(\"Detroit Red Wings\") & stats['Season'].eq(20112012),\n",
    "             stats['Team'].eq(\"New Jersey Devils\") & stats['Season'].eq(20112012),\n",
    "             stats['Team'].eq(\"Nashville Predators\") & stats['Season'].eq(20112012)]\n",
    "              \n",
    "choices = [1,2,3,2,1,1,1,2,1,1,1,4,3,1,4,2]\n",
    "stats['rp'] = np.select(conditions, choices, default= stats['rp'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d49a9f0a-65e8-4068-b24b-34be983c89fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [stats['Team'].eq(\"Boston Bruins\") & stats['Season'].eq(20122013),\n",
    "             stats['Team'].eq(\"Montréal Canadiens\") & stats['Season'].eq(20122013),\n",
    "             stats['Team'].eq(\"New York Rangers\") & stats['Season'].eq(20122013),\n",
    "             stats['Team'].eq(\"New York Islanders\") & stats['Season'].eq(20122013),\n",
    "             stats['Team'].eq(\"Ottawa Senators\") & stats['Season'].eq(20122013),\n",
    "             stats['Team'].eq(\"Washington Capitals\t\") & stats['Season'].eq(20122013),\n",
    "             stats['Team'].eq(\"Pittsburgh Penguins\") & stats['Season'].eq(20122013),\n",
    "             stats['Team'].eq(\"St. Louis Blues\") & stats['Season'].eq(20122013),\n",
    "             stats['Team'].eq(\"Vancouver Canucks\") & stats['Season'].eq(20122013),\n",
    "             stats['Team'].eq(\"Chicago Blackhawks\") & stats['Season'].eq(20122013),\n",
    "             stats['Team'].eq(\"San Jose Sharks\") & stats['Season'].eq(20122013),\n",
    "             stats['Team'].eq(\"Los Angeles Kings\") & stats['Season'].eq(20122013),\n",
    "             stats['Team'].eq(\"Toronto Maple Leafs\") & stats['Season'].eq(20122013),\n",
    "             stats['Team'].eq(\"Detroit Red Wings\") & stats['Season'].eq(20122013),\n",
    "             stats['Team'].eq(\"Minnesota Wild\") & stats['Season'].eq(20122013),\n",
    "             stats['Team'].eq(\"Anaheim Ducks\") & stats['Season'].eq(20122013)]\n",
    "choices = [4,1,2,1,2,1,3,1,1,4,2,3,1,2,1,1]\n",
    "stats['rp'] = np.select(conditions, choices, default= stats['rp'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be45ab12-2e1e-4821-b7bb-d62155a7d8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [stats['Team'].eq(\"Boston Bruins\") & stats['Season'].eq(20132014),\n",
    "             stats['Team'].eq(\"Montréal Canadiens\") & stats['Season'].eq(20132014),\n",
    "             stats['Team'].eq(\"New York Rangers\") & stats['Season'].eq(20132014),\n",
    "             stats['Team'].eq(\"Tampa Bay Lightning\") & stats['Season'].eq(20132014),\n",
    "             stats['Team'].eq(\"Columbus Blue Jackets\") & stats['Season'].eq(20132014),\n",
    "             stats['Team'].eq(\"Colorado Avalanche\") & stats['Season'].eq(20132014),\n",
    "             stats['Team'].eq(\"Pittsburgh Penguins\") & stats['Season'].eq(20132014),\n",
    "             stats['Team'].eq(\"St. Louis Blues\") & stats['Season'].eq(20132014),\n",
    "             stats['Team'].eq(\"Philadelphia Flyers\") & stats['Season'].eq(20132014),\n",
    "             stats['Team'].eq(\"Chicago Blackhawks\") & stats['Season'].eq(20132014),\n",
    "             stats['Team'].eq(\"San Jose Sharks\") & stats['Season'].eq(20132014),\n",
    "             stats['Team'].eq(\"Los Angeles Kings\") & stats['Season'].eq(20132014),\n",
    "             stats['Team'].eq(\"Dallas Stars\") & stats['Season'].eq(20132014),\n",
    "             stats['Team'].eq(\"Detroit Red Wings\") & stats['Season'].eq(20132014),\n",
    "             stats['Team'].eq(\"Minnesota Wild\") & stats['Season'].eq(20132014),\n",
    "             stats['Team'].eq(\"Anaheim Ducks\") & stats['Season'].eq(20132014)]\n",
    "choices = [2,3,4,1,1,1,2,1,1,3,1,4,1,1,2,2]\n",
    "stats['rp'] = np.select(conditions, choices, default= stats['rp'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9d7724d-9e7b-4c15-a287-073a95e04670",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [stats['Team'].eq(\"Tampa Bay Lightning\") & stats['Season'].eq(20142015),\n",
    "             stats['Team'].eq(\"Montréal Canadiens\") & stats['Season'].eq(20142015),\n",
    "             stats['Team'].eq(\"New York Rangers\") & stats['Season'].eq(20142015),\n",
    "             stats['Team'].eq(\"New York Islanders\") & stats['Season'].eq(20142015),\n",
    "             stats['Team'].eq(\"Ottawa Senators\") & stats['Season'].eq(20142015),\n",
    "             stats['Team'].eq(\"Washington Capitals\t\") & stats['Season'].eq(20142015),\n",
    "             stats['Team'].eq(\"Pittsburgh Penguins\") & stats['Season'].eq(20142015),\n",
    "             stats['Team'].eq(\"St. Louis Blues\") & stats['Season'].eq(20142015),\n",
    "             stats['Team'].eq(\"Vancouver Canucks\") & stats['Season'].eq(20142015),\n",
    "             stats['Team'].eq(\"Chicago Blackhawks\") & stats['Season'].eq(20142015),\n",
    "             stats['Team'].eq(\"Nashville Predators\") & stats['Season'].eq(20142015),\n",
    "             stats['Team'].eq(\"Winnipeg Jets\") & stats['Season'].eq(20142015),\n",
    "             stats['Team'].eq(\"Calgary Flames\") & stats['Season'].eq(20142015),\n",
    "             stats['Team'].eq(\"Detroit Red Wings\") & stats['Season'].eq(20142015),\n",
    "             stats['Team'].eq(\"Minnesota Wild\") & stats['Season'].eq(20142015),\n",
    "             stats['Team'].eq(\"Anaheim Ducks\") & stats['Season'].eq(20142015)]\n",
    "choices = [4,2,3,1,1,2,1,1,1,4,1,1,2,1,2,3]\n",
    "stats['rp'] = np.select(conditions, choices, default= stats['rp'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb20cd55-9c66-4b25-bf68-caadfaa42669",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [stats['Team'].eq(\"Tampa Bay Lightning\") & stats['Season'].eq(20152016),\n",
    "             stats['Team'].eq(\"Florida Panthers\") & stats['Season'].eq(20152016),\n",
    "             stats['Team'].eq(\"New York Rangers\") & stats['Season'].eq(20152016),\n",
    "             stats['Team'].eq(\"New York Islanders\") & stats['Season'].eq(20152016),\n",
    "             stats['Team'].eq(\"Philadelphia Flyers\") & stats['Season'].eq(20152016),\n",
    "             stats['Team'].eq(\"Washington Capitals\t\") & stats['Season'].eq(20152016),\n",
    "             stats['Team'].eq(\"Pittsburgh Penguins\") & stats['Season'].eq(20152016),\n",
    "             stats['Team'].eq(\"St. Louis Blues\") & stats['Season'].eq(20152016),\n",
    "             stats['Team'].eq(\"Dallas Stars\") & stats['Season'].eq(20152016),\n",
    "             stats['Team'].eq(\"Chicago Blackhawks\") & stats['Season'].eq(20152016),\n",
    "             stats['Team'].eq(\"Nashville Predators\") & stats['Season'].eq(20152016),\n",
    "             stats['Team'].eq(\"Los Angeles Kings\") & stats['Season'].eq(20152016),\n",
    "             stats['Team'].eq(\"San Jose Sharks\") & stats['Season'].eq(20152016),\n",
    "             stats['Team'].eq(\"Detroit Red Wings\") & stats['Season'].eq(20152016),\n",
    "             stats['Team'].eq(\"Minnesota Wild\") & stats['Season'].eq(20152016),\n",
    "             stats['Team'].eq(\"Anaheim Ducks\") & stats['Season'].eq(20152016)]\n",
    "choices = [3,1,1,2,1,2,4,3,2,1,2,1,4,1,1,1]\n",
    "stats['rp'] = np.select(conditions, choices, default= stats['rp'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47db3fa6-3f70-44df-9775-5efd3030181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [stats['Team'].eq(\"Montréal Canadiens\") & stats['Season'].eq(20162017),\n",
    "             stats['Team'].eq(\"Boston Bruins\") & stats['Season'].eq(20162017),\n",
    "             stats['Team'].eq(\"New York Rangers\") & stats['Season'].eq(20162017),\n",
    "             stats['Team'].eq(\"Ottawa Senators\") & stats['Season'].eq(20162017),\n",
    "             stats['Team'].eq(\"Columbus Blue Jackets\") & stats['Season'].eq(20162017),\n",
    "             stats['Team'].eq(\"Washington Capitals\t\") & stats['Season'].eq(20162017),\n",
    "             stats['Team'].eq(\"Pittsburgh Penguins\") & stats['Season'].eq(20162017),\n",
    "             stats['Team'].eq(\"St. Louis Blues\") & stats['Season'].eq(20162017),\n",
    "             stats['Team'].eq(\"Toronto Maple Leafs\") & stats['Season'].eq(20162017),\n",
    "             stats['Team'].eq(\"Chicago Blackhawks\") & stats['Season'].eq(20162017),\n",
    "             stats['Team'].eq(\"Nashville Predators\") & stats['Season'].eq(20162017),\n",
    "             stats['Team'].eq(\"Calgary Flames\") & stats['Season'].eq(20162017),\n",
    "             stats['Team'].eq(\"San Jose Sharks\") & stats['Season'].eq(20162017),\n",
    "             stats['Team'].eq(\"Edmonton Oilers\") & stats['Season'].eq(20162017),\n",
    "             stats['Team'].eq(\"Minnesota Wild\") & stats['Season'].eq(20162017),\n",
    "             stats['Team'].eq(\"Anaheim Ducks\") & stats['Season'].eq(20162017)]\n",
    "choices = [1,1,2,3,1,2,4,2,1,1,4,1,1,2,1,3]\n",
    "stats['rp'] = np.select(conditions, choices, default= stats['rp'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31e5de54-d41c-4129-a778-57435c62bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [stats['Team'].eq(\"Tampa Bay Lightning\") & stats['Season'].eq(20172018),\n",
    "             stats['Team'].eq(\"Boston Bruins\") & stats['Season'].eq(20172018),\n",
    "             stats['Team'].eq(\"New Jersey Devils\") & stats['Season'].eq(20172018),\n",
    "             stats['Team'].eq(\"Philadelphia Flyers\") & stats['Season'].eq(20172018),\n",
    "             stats['Team'].eq(\"Columbus Blue Jackets\") & stats['Season'].eq(20172018),\n",
    "             stats['Team'].eq(\"Washington Capitals\t\") & stats['Season'].eq(20172018),\n",
    "             stats['Team'].eq(\"Pittsburgh Penguins\") & stats['Season'].eq(20172018),\n",
    "             stats['Team'].eq(\"Colorado Avalanche\") & stats['Season'].eq(20172018),\n",
    "             stats['Team'].eq(\"Toronto Maple Leafs\") & stats['Season'].eq(20172018),\n",
    "             stats['Team'].eq(\"Winnipeg Jets\") & stats['Season'].eq(20172018),\n",
    "             stats['Team'].eq(\"Nashville Predators\") & stats['Season'].eq(20172018),\n",
    "             stats['Team'].eq(\"Vegas Golden Knights\") & stats['Season'].eq(20172018),\n",
    "             stats['Team'].eq(\"San Jose Sharks\") & stats['Season'].eq(20172018),\n",
    "             stats['Team'].eq(\"Los Angeles Kings\") & stats['Season'].eq(20172018),\n",
    "             stats['Team'].eq(\"Minnesota Wild\") & stats['Season'].eq(20172018),\n",
    "             stats['Team'].eq(\"Anaheim Ducks\") & stats['Season'].eq(20172018)]\n",
    "choices = [3,2,1,1,1,4,2,1,1,3,2,4,2,1,1,1]\n",
    "stats['rp'] = np.select(conditions, choices, default= stats['rp'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adfc9252-22ff-4f6e-8d50-22432f42f67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [stats['Team'].eq(\"Tampa Bay Lightning\") & stats['Season'].eq(20182019),\n",
    "             stats['Team'].eq(\"Boston Bruins\") & stats['Season'].eq(20182019),\n",
    "             stats['Team'].eq(\"Calgary Flames\") & stats['Season'].eq(20182019),\n",
    "             stats['Team'].eq(\"Carolina Hurricanes\") & stats['Season'].eq(20182019),\n",
    "             stats['Team'].eq(\"Columbus Blue Jackets\") & stats['Season'].eq(20182019),\n",
    "             stats['Team'].eq(\"Washington Capitals\") & stats['Season'].eq(20182019),\n",
    "             stats['Team'].eq(\"Pittsburgh Penguins\") & stats['Season'].eq(20182019),\n",
    "             stats['Team'].eq(\"Colorado Avalanche\") & stats['Season'].eq(20182019),\n",
    "             stats['Team'].eq(\"Toronto Maple Leafs\") & stats['Season'].eq(20182019),\n",
    "             stats['Team'].eq(\"Winnipeg Jets\") & stats['Season'].eq(20182019),\n",
    "             stats['Team'].eq(\"Nashville Predators\") & stats['Season'].eq(20182019),\n",
    "             stats['Team'].eq(\"Vegas Golden Knights\") & stats['Season'].eq(20182019),\n",
    "             stats['Team'].eq(\"San Jose Sharks\") & stats['Season'].eq(20182019),\n",
    "             stats['Team'].eq(\"Dallas Stars\") & stats['Season'].eq(20182019),\n",
    "             stats['Team'].eq(\"New York Islanders\") & stats['Season'].eq(20182019),\n",
    "             stats['Team'].eq(\"St. Louis Blues\") & stats['Season'].eq(20182019)]\n",
    "choices = [1,4,1,3,2,1,1,2,1,1,1,1,3,2,2,4]\n",
    "stats['rp'] = np.select(conditions, choices, default= stats['rp'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03e17dbf-7615-4b82-b727-0bb6d60e430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [stats['Team'].eq(\"Tampa Bay Lightning\") & stats['Season'].eq(20192020),\n",
    "             stats['Team'].eq(\"Boston Bruins\") & stats['Season'].eq(20192020),\n",
    "             stats['Team'].eq(\"Calgary Flames\") & stats['Season'].eq(20192020),\n",
    "             stats['Team'].eq(\"Carolina Hurricanes\") & stats['Season'].eq(20192020),\n",
    "             stats['Team'].eq(\"Columbus Blue Jackets\") & stats['Season'].eq(20192020),\n",
    "             stats['Team'].eq(\"Washington Capitals\") & stats['Season'].eq(20192020),\n",
    "             stats['Team'].eq(\"Arizona Coyotes\") & stats['Season'].eq(20192020),\n",
    "             stats['Team'].eq(\"Colorado Avalanche\") & stats['Season'].eq(20192020),\n",
    "             stats['Team'].eq(\"Chicago Blackhawks\") & stats['Season'].eq(20192020),\n",
    "             stats['Team'].eq(\"Montréal Canadiens\") & stats['Season'].eq(20192020),\n",
    "             stats['Team'].eq(\"Philadelphia Flyers\") & stats['Season'].eq(20192020),\n",
    "             stats['Team'].eq(\"Vegas Golden Knights\") & stats['Season'].eq(20192020),\n",
    "             stats['Team'].eq(\"Vancouver Canucks\") & stats['Season'].eq(20192020),\n",
    "             stats['Team'].eq(\"Dallas Stars\") & stats['Season'].eq(20192020),\n",
    "             stats['Team'].eq(\"New York Islanders\") & stats['Season'].eq(20192020),\n",
    "             stats['Team'].eq(\"St. Louis Blues\") & stats['Season'].eq(20192020)]\n",
    "choices = [4,2,1,1,1,1,1,2,1,1,2,3,2,4,3,1]\n",
    "stats['rp'] = np.select(conditions, choices, default= stats['rp'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42cb9853-1194-441f-a0b6-a4fbb11cecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [stats['Team'].eq(\"Tampa Bay Lightning\") & stats['Season'].eq(20202021),\n",
    "             stats['Team'].eq(\"Boston Bruins\") & stats['Season'].eq(20202021),\n",
    "             stats['Team'].eq(\"Nashville Predators\") & stats['Season'].eq(20202021),\n",
    "             stats['Team'].eq(\"Carolina Hurricanes\") & stats['Season'].eq(20202021),\n",
    "             stats['Team'].eq(\"Florida Panthers\") & stats['Season'].eq(20202021),\n",
    "             stats['Team'].eq(\"Washington Capitals\") & stats['Season'].eq(20202021),\n",
    "             stats['Team'].eq(\"Pittsburgh Penguins\") & stats['Season'].eq(20202021),\n",
    "             stats['Team'].eq(\"Colorado Avalanche\") & stats['Season'].eq(20202021),\n",
    "             stats['Team'].eq(\"Toronto Maple Leafs\") & stats['Season'].eq(20202021),\n",
    "             stats['Team'].eq(\"Montréal Canadiens\") & stats['Season'].eq(20202021),\n",
    "             stats['Team'].eq(\"Edmonton Oilers\") & stats['Season'].eq(20202021),\n",
    "             stats['Team'].eq(\"Vegas Golden Knights\") & stats['Season'].eq(20202021),\n",
    "             stats['Team'].eq(\"Winnipeg Jets\") & stats['Season'].eq(20202021),\n",
    "             stats['Team'].eq(\"Minnesota Wild\") & stats['Season'].eq(20202021),\n",
    "             stats['Team'].eq(\"New York Islanders\") & stats['Season'].eq(20202021),\n",
    "             stats['Team'].eq(\"St. Louis Blues\") & stats['Season'].eq(20202021)]\n",
    "choices = [4,2,1,2,1,1,1,2,1,4,1,3,2,1,3,1]\n",
    "stats['rp'] = np.select(conditions, choices, default= stats['rp'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c948719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats=stats.drop(['T'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b34a48e-1cea-4d5c-90e3-c10aecc789a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 334 entries, 0 to 333\n",
      "Data columns (total 24 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Team      334 non-null    object \n",
      " 1   Season    334 non-null    int64  \n",
      " 2   GP        334 non-null    int64  \n",
      " 3   W         334 non-null    int64  \n",
      " 4   L         334 non-null    int64  \n",
      " 5   OT        334 non-null    int64  \n",
      " 6   P         334 non-null    int64  \n",
      " 7   P%        334 non-null    float64\n",
      " 8   RW        334 non-null    int64  \n",
      " 9   ROW       334 non-null    int64  \n",
      " 10  S/O Win   334 non-null    int64  \n",
      " 11  GF        334 non-null    int64  \n",
      " 12  GA        334 non-null    int64  \n",
      " 13  GF/GP     334 non-null    float64\n",
      " 14  GA/GP     334 non-null    float64\n",
      " 15  PP%       334 non-null    float64\n",
      " 16  PK%       334 non-null    float64\n",
      " 17  Net PP%   334 non-null    float64\n",
      " 18  Net PK%   334 non-null    float64\n",
      " 19  Shots/GP  334 non-null    float64\n",
      " 20  SA/GP     334 non-null    float64\n",
      " 21  FOW%      334 non-null    float64\n",
      " 22  cup       334 non-null    int64  \n",
      " 23  rp        334 non-null    int64  \n",
      "dtypes: float64(10), int64(13), object(1)\n",
      "memory usage: 62.8+ KB\n"
     ]
    }
   ],
   "source": [
    "stats.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecffd85",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c268969c-9c96-48a4-af9e-8431e705eff4",
   "metadata": {},
   "source": [
    "Using season stats to determine how many wins a team will have in a season "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f363f175",
   "metadata": {},
   "outputs": [],
   "source": [
    "features =['GF', 'GA', 'GF/GP', 'GA/GP', 'PP%', 'PK%', 'Net PP%', 'Net PK%',\n",
    "       'Shots/GP', 'SA/GP', 'FOW%']\n",
    "target = \"W\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25508b12-ba46-488f-9f27-f6704f159017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X = stats[features]\n",
    "y = stats[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e53aa72-2a27-43f1-ad2b-c308b27b1445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((267, 11), (267,), (67, 11), (67,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = stats[features]\n",
    "y = stats[target]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bd29714-4c3a-4d0a-a800-44a0dd7e76ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = MinMaxScaler().fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cf60b3b-87bf-4bf7-a623-81c093285ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.17142857, 0.45098039, ..., 0.42990654, 0.6171875 ,\n",
       "        0.19672131],\n",
       "       [1.        , 0.2047619 , 0.1372549 , ..., 0.44859813, 0.4140625 ,\n",
       "        0.59016393],\n",
       "       [1.        , 0.31904762, 0.28431373, ..., 0.42056075, 0.515625  ,\n",
       "        0.02459016],\n",
       "       ...,\n",
       "       [1.        , 0.63809524, 0.54411765, ..., 0.96261682, 0.453125  ,\n",
       "        0.77868852],\n",
       "       [1.        , 0.48095238, 0.75      , ..., 0.59813084, 0.5234375 ,\n",
       "        0.57377049],\n",
       "       [1.        , 0.44761905, 0.64215686, ..., 0.18691589, 0.6953125 ,\n",
       "        0.54098361]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.add_constant(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0b77ff9-feef-49e5-ae2b-1246574e8c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = sm.add_constant(X_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db5a777e-c7e5-4fc4-a3c7-02954521b23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[\"const\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "232a2b1a-86c8-471f-a3e1-d0ebe2028987",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = pd.DataFrame(data=X_scaled, columns=[\"const\"]+features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d4bbbc3-6694-420a-9aa7-e520f3891e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(endog=y, exog=X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84121288-588a-4da7-a2d0-e631fd749671",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "309d77f7-dbf9-4d36-8400-8d438e03a58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const: 33.68227 (0.0)\n",
      "GF: 59.95423 (0.0)\n",
      "GA: -20.71947 (0.0)\n",
      "GF/GP: -11.83871 (0.00088)\n",
      "GA/GP: -10.89576 (0.00047)\n",
      "PK%: 5.59458 (0.0182)\n",
      "Net PK%: -6.98841 (0.00571)\n",
      "Shots/GP: -2.35349 (0.01073)\n"
     ]
    }
   ],
   "source": [
    "for feature, param, pval in zip(model.exog_names, results.params, results.pvalues):\n",
    "    if pval <= .05:     \n",
    "        print(f\"{feature}: {round(param, 5)} ({round(pval, 5)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9581e6d-5104-4a40-a610-0deac6de8c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      W   R-squared:                       0.935\n",
      "Model:                            OLS   Adj. R-squared:                  0.933\n",
      "Method:                 Least Squares   F-statistic:                     422.8\n",
      "Date:                Thu, 05 Aug 2021   Prob (F-statistic):          5.29e-184\n",
      "Time:                        17:00:43   Log-Likelihood:                -757.20\n",
      "No. Observations:                 334   AIC:                             1538.\n",
      "Df Residuals:                     322   BIC:                             1584.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         33.6823      1.344     25.068      0.000      31.039      36.326\n",
      "GF            59.9542      4.573     13.112      0.000      50.958      68.950\n",
      "GA           -20.7195      4.434     -4.673      0.000     -29.443     -11.996\n",
      "GF/GP        -11.8387      3.526     -3.357      0.001     -18.776      -4.902\n",
      "GA/GP        -10.8958      3.084     -3.533      0.000     -16.963      -4.829\n",
      "PP%            0.8405      2.732      0.308      0.759      -4.535       6.216\n",
      "PK%            5.5946      2.357      2.374      0.018       0.957      10.232\n",
      "Net PP%       -3.0637      2.750     -1.114      0.266      -8.474       2.347\n",
      "Net PK%       -6.9884      2.512     -2.782      0.006     -11.930      -2.047\n",
      "Shots/GP      -2.3535      0.917     -2.566      0.011      -4.158      -0.549\n",
      "SA/GP         -0.1044      1.032     -0.101      0.920      -2.135       1.927\n",
      "FOW%           0.7356      0.850      0.865      0.388      -0.938       2.409\n",
      "==============================================================================\n",
      "Omnibus:                        4.536   Durbin-Watson:                   2.001\n",
      "Prob(Omnibus):                  0.104   Jarque-Bera (JB):                4.820\n",
      "Skew:                          -0.166   Prob(JB):                       0.0898\n",
      "Kurtosis:                       3.486   Cond. No.                         118.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da09ace8-564c-4e2a-80a8-e1dd34b3b713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const: 33.68227 (0.0)\n",
      "GF: 59.95423 (0.0)\n",
      "GA: -20.71947 (0.0)\n",
      "GF/GP: -11.83871 (0.00088)\n",
      "GA/GP: -10.89576 (0.00047)\n",
      "PK%: 5.59458 (0.0182)\n",
      "Net PK%: -6.98841 (0.00571)\n",
      "Shots/GP: -2.35349 (0.01073)\n"
     ]
    }
   ],
   "source": [
    "for feature, param, pval in zip(model.exog_names, results.params, results.pvalues):\n",
    "    if pval <= .05:     \n",
    "        print(f\"{feature}: {round(param, 5)} ({round(pval, 5)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9640263-61cc-4f50-848f-9eb2f170cc43",
   "metadata": {},
   "source": [
    "# Take out ignsignficant varibles and highly relatedvaribles to get more accurate score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f944d763-0841-408d-b198-dbf7b2c3d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features =['GF', 'GA', 'GF/GP', 'GA/GP', 'PK%',\n",
    "       'Shots/GP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33481052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((267, 6), (267,), (67, 6), (67,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = stats[features]\n",
    "y = stats[target]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f441bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = MinMaxScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a310ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eea79140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def train_test4(X_train, X_test, y_train, y_test, param_grid, reg):\n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"*** Parameter estimation results: \")\n",
    "    print(reg.cv_results_)\n",
    "    print()\n",
    "    \n",
    "    print(\"*** Grid scores: \")\n",
    "    means = reg.cv_results_['mean_test_score']\n",
    "    stds = reg.cv_results_['std_test_score']\n",
    "    params = reg.cv_results_['params']\n",
    "\n",
    "    for mean, std, param in zip(means, stds, params):\n",
    "        print(f\"{round(mean, 3)} (+/-{round(std*2, 3)}) for {param}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"*** Highest R^2 score: \")\n",
    "    print(f\"{round(means.max(), 3)}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"*** Best parameters set found: \")\n",
    "    print(reg.best_params_)\n",
    "    print()\n",
    "    \n",
    "    print(\"*** Final R^2 score: \")\n",
    "    y_true, y_pred = y_test, reg.predict(X_test)\n",
    "    r2_score = round(metrics.r2_score(y_true, y_pred), 3)\n",
    "    print(r2_score)\n",
    "    \n",
    "    return reg, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a06f7cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 5\n",
    "summary = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c6ca1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.00100136, 0.00122576, 0.00069809, 0.00081692, 0.00050006]), 'std_fit_time': array([2.74750906e-06, 9.90942538e-04, 3.98466369e-04, 4.09901314e-04,\n",
      "       4.47234506e-04]), 'mean_score_time': array([0.0015543 , 0.00118198, 0.00074224, 0.00138841, 0.00158725]), 'std_score_time': array([0.0006693 , 0.00022292, 0.00038765, 0.00046136, 0.00077655]), 'param_n_neighbors': masked_array(data=[1, 3, 10, 30, 100],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_neighbors': 1}, {'n_neighbors': 3}, {'n_neighbors': 10}, {'n_neighbors': 30}, {'n_neighbors': 100}], 'split0_test_score': array([0.72163581, 0.81418265, 0.82604891, 0.77115494, 0.44746396]), 'split1_test_score': array([0.77687345, 0.8356107 , 0.87547593, 0.82250631, 0.53204129]), 'split2_test_score': array([0.78063452, 0.90225438, 0.88548022, 0.79565558, 0.45288962]), 'split3_test_score': array([0.76661495, 0.85400672, 0.85085409, 0.81644613, 0.50272127]), 'split4_test_score': array([0.80797856, 0.8427286 , 0.84028916, 0.7870392 , 0.45903649]), 'mean_test_score': array([0.77074746, 0.84975661, 0.85562966, 0.79856043, 0.47883053]), 'std_test_score': array([0.0281086 , 0.02928852, 0.02199131, 0.01889731, 0.03301742]), 'rank_test_score': array([4, 2, 1, 3, 5])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.771 (+/-0.056) for {'n_neighbors': 1}\n",
      "0.85 (+/-0.059) for {'n_neighbors': 3}\n",
      "0.856 (+/-0.044) for {'n_neighbors': 10}\n",
      "0.799 (+/-0.038) for {'n_neighbors': 30}\n",
      "0.479 (+/-0.066) for {'n_neighbors': 100}\n",
      "\n",
      "*** Highest R^2 score: \n",
      "0.856\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'n_neighbors': 10}\n",
      "\n",
      "*** Final R^2 score: \n",
      "0.851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.851}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "param_grid = [{\"n_neighbors\": [1, 3, 10, 30, 100]}]\n",
    "knr = GridSearchCV(KNeighborsRegressor(), param_grid, cv=cv)\n",
    "knr, score = train_test4(X_train_scaled, X_test_scaled, y_train, y_test, param_grid, knr)\n",
    "summary[\"k-NNs\"] = score\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bcf2cbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.00122752, 0.00019846]), 'std_fit_time': array([0.00097047, 0.00039692]), 'mean_score_time': array([0.00012074, 0.00019975]), 'std_score_time': array([0.00024147, 0.00039949]), 'param_fit_intercept': masked_array(data=[True, False],\n",
      "             mask=[False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'fit_intercept': True}, {'fit_intercept': False}], 'split0_test_score': array([0.92511105, 0.70758002]), 'split1_test_score': array([0.91901831, 0.77788961]), 'split2_test_score': array([0.91447906, 0.66156492]), 'split3_test_score': array([0.93318031, 0.73152618]), 'split4_test_score': array([0.93872934, 0.73125808]), 'mean_test_score': array([0.92610361, 0.72196376]), 'std_test_score': array([0.00889725, 0.03784293]), 'rank_test_score': array([1, 2])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.926 (+/-0.018) for {'fit_intercept': True}\n",
      "0.722 (+/-0.076) for {'fit_intercept': False}\n",
      "\n",
      "*** Highest R^2 score: \n",
      "0.926\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'fit_intercept': True}\n",
      "\n",
      "*** Final R^2 score: \n",
      "0.936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.851, 'Linear Regression': 0.936}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "param_grid = [{\"fit_intercept\": [True, False]}]\n",
    "lr = GridSearchCV(LinearRegression(), param_grid, cv=cv)\n",
    "lr, score = train_test4(X_train_scaled, X_test_scaled, y_train, y_test, param_grid, lr)\n",
    "summary[\"Linear Regression\"] = score\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "374640ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.0008008 , 0.00080924, 0.        , 0.        , 0.00038142,\n",
      "       0.00098467, 0.00040102]), 'std_fit_time': array([4.00405116e-04, 4.05026178e-04, 0.00000000e+00, 0.00000000e+00,\n",
      "       4.75386329e-04, 6.62458797e-05, 4.91149125e-04]), 'mean_score_time': array([0.00040035, 0.0002511 , 0.00100083, 0.00059891, 0.00040846,\n",
      "       0.00060048, 0.00059977]), 'std_score_time': array([4.90329667e-04, 4.03761379e-04, 4.19887542e-06, 4.89021114e-04,\n",
      "       3.76951503e-04, 4.90304074e-04, 4.89718136e-04]), 'param_alpha': masked_array(data=[0.1, 0.3, 1, 3, 10, 30, 100],\n",
      "             mask=[False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'alpha': 0.1}, {'alpha': 0.3}, {'alpha': 1}, {'alpha': 3}, {'alpha': 10}, {'alpha': 30}, {'alpha': 100}], 'split0_test_score': array([0.92253769, 0.91776957, 0.90036413, 0.84665123, 0.69449229,\n",
      "       0.45263675, 0.20013066]), 'split1_test_score': array([0.92020021, 0.91740799, 0.90536022, 0.86278366, 0.71598821,\n",
      "       0.45935622, 0.19055781]), 'split2_test_score': array([0.90737695, 0.90558811, 0.8990081 , 0.85197901, 0.69410726,\n",
      "       0.45094674, 0.19972191]), 'split3_test_score': array([0.93068141, 0.92531215, 0.9092192 , 0.86077766, 0.709837  ,\n",
      "       0.46217133, 0.20504128]), 'split4_test_score': array([0.93866626, 0.93825432, 0.93137361, 0.88888934, 0.73731133,\n",
      "       0.48410884, 0.21644768]), 'mean_test_score': array([0.9238925 , 0.92086643, 0.90906505, 0.86221618, 0.71034722,\n",
      "       0.46184398, 0.20237987]), 'std_test_score': array([0.01051271, 0.0107432 , 0.0117326 , 0.01456651, 0.01596408,\n",
      "       0.01187892, 0.00844833]), 'rank_test_score': array([1, 2, 3, 4, 5, 6, 7])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.924 (+/-0.021) for {'alpha': 0.1}\n",
      "0.921 (+/-0.021) for {'alpha': 0.3}\n",
      "0.909 (+/-0.023) for {'alpha': 1}\n",
      "0.862 (+/-0.029) for {'alpha': 3}\n",
      "0.71 (+/-0.032) for {'alpha': 10}\n",
      "0.462 (+/-0.024) for {'alpha': 30}\n",
      "0.202 (+/-0.017) for {'alpha': 100}\n",
      "\n",
      "*** Highest R^2 score: \n",
      "0.924\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'alpha': 0.1}\n",
      "\n",
      "*** Final R^2 score: \n",
      "0.938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.851, 'Linear Regression': 0.936, 'Ridge Regression': 0.938}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "param_grid = [{\"alpha\": [0.1, 0.3, 1, 3, 10, 30, 100]}]\n",
    "ridge = GridSearchCV(Ridge(), param_grid, cv=cv)\n",
    "ridge, score = train_test4(X_train_scaled, X_test_scaled, y_train, y_test, param_grid, ridge)\n",
    "summary[\"Ridge Regression\"] = score\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "29ff9884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.00105433, 0.00120144, 0.00079999, 0.00139918, 0.00059915,\n",
      "       0.00120258, 0.00099864, 0.00039983, 0.00019979, 0.00100989,\n",
      "       0.00079985, 0.00080104, 0.00060086, 0.00080061]), 'std_fit_time': array([6.04313548e-05, 3.99347217e-04, 3.99994889e-04, 8.07884113e-04,\n",
      "       4.89201159e-04, 4.03644387e-04, 6.31732299e-04, 4.89687292e-04,\n",
      "       3.99589539e-04, 2.00602848e-05, 3.99926636e-04, 4.00542571e-04,\n",
      "       4.90614330e-04, 4.00308330e-04]), 'mean_score_time': array([0.00068812, 0.00040817, 0.00020003, 0.00071211, 0.0004005 ,\n",
      "       0.00027957, 0.00020022, 0.0006001 , 0.00082645, 0.00019975,\n",
      "       0.00059996, 0.00019999, 0.00039949, 0.00040097]), 'std_score_time': array([0.00058382, 0.00050007, 0.00040007, 0.00061511, 0.00049051,\n",
      "       0.00039125, 0.00040045, 0.00048998, 0.00034635, 0.00039949,\n",
      "       0.00048986, 0.00039997, 0.00048928, 0.00049112]), 'param_alpha': masked_array(data=[0.1, 0.1, 0.3, 0.3, 1, 1, 3, 3, 10, 10, 30, 30, 100,\n",
      "                   100],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_iter': masked_array(data=[1000, 10000, 1000, 10000, 1000, 10000, 1000, 10000,\n",
      "                   1000, 10000, 1000, 10000, 1000, 10000],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'alpha': 0.1, 'max_iter': 1000}, {'alpha': 0.1, 'max_iter': 10000}, {'alpha': 0.3, 'max_iter': 1000}, {'alpha': 0.3, 'max_iter': 10000}, {'alpha': 1, 'max_iter': 1000}, {'alpha': 1, 'max_iter': 10000}, {'alpha': 3, 'max_iter': 1000}, {'alpha': 3, 'max_iter': 10000}, {'alpha': 10, 'max_iter': 1000}, {'alpha': 10, 'max_iter': 10000}, {'alpha': 30, 'max_iter': 1000}, {'alpha': 30, 'max_iter': 10000}, {'alpha': 100, 'max_iter': 1000}, {'alpha': 100, 'max_iter': 10000}], 'split0_test_score': array([ 0.91518014,  0.91518014,  0.85849315,  0.85849315,  0.40250529,\n",
      "        0.40250529, -0.00276049, -0.00276049, -0.00276049, -0.00276049,\n",
      "       -0.00276049, -0.00276049, -0.00276049, -0.00276049]), 'split1_test_score': array([ 0.90855653,  0.90855653,  0.85195325,  0.85195325,  0.40359091,\n",
      "        0.40359091, -0.0209119 , -0.0209119 , -0.0209119 , -0.0209119 ,\n",
      "       -0.0209119 , -0.0209119 , -0.0209119 , -0.0209119 ]), 'split2_test_score': array([ 0.90612713,  0.90612713,  0.86939051,  0.86939051,  0.44698789,\n",
      "        0.44698789, -0.0038077 , -0.0038077 , -0.0038077 , -0.0038077 ,\n",
      "       -0.0038077 , -0.0038077 , -0.0038077 , -0.0038077 ]), 'split3_test_score': array([ 9.19792359e-01,  9.19792359e-01,  8.56961933e-01,  8.56961933e-01,\n",
      "        4.13951384e-01,  4.13951384e-01, -5.19985378e-04, -5.19985378e-04,\n",
      "       -5.19985378e-04, -5.19985378e-04, -5.19985378e-04, -5.19985378e-04,\n",
      "       -5.19985378e-04, -5.19985378e-04]), 'split4_test_score': array([ 9.34728569e-01,  9.34728569e-01,  8.93503347e-01,  8.93503347e-01,\n",
      "        4.63727295e-01,  4.63727295e-01, -5.88986265e-04, -5.88986265e-04,\n",
      "       -5.88986265e-04, -5.88986265e-04, -5.88986265e-04, -5.88986265e-04,\n",
      "       -5.88986265e-04, -5.88986265e-04]), 'mean_test_score': array([ 0.91687695,  0.91687695,  0.86606044,  0.86606044,  0.42615255,\n",
      "        0.42615255, -0.00571781, -0.00571781, -0.00571781, -0.00571781,\n",
      "       -0.00571781, -0.00571781, -0.00571781, -0.00571781]), 'std_test_score': array([0.01014738, 0.01014738, 0.01485437, 0.01485437, 0.02475101,\n",
      "       0.02475101, 0.00770165, 0.00770165, 0.00770165, 0.00770165,\n",
      "       0.00770165, 0.00770165, 0.00770165, 0.00770165]), 'rank_test_score': array([1, 1, 3, 3, 5, 5, 7, 7, 7, 7, 7, 7, 7, 7])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.917 (+/-0.02) for {'alpha': 0.1, 'max_iter': 1000}\n",
      "0.917 (+/-0.02) for {'alpha': 0.1, 'max_iter': 10000}\n",
      "0.866 (+/-0.03) for {'alpha': 0.3, 'max_iter': 1000}\n",
      "0.866 (+/-0.03) for {'alpha': 0.3, 'max_iter': 10000}\n",
      "0.426 (+/-0.05) for {'alpha': 1, 'max_iter': 1000}\n",
      "0.426 (+/-0.05) for {'alpha': 1, 'max_iter': 10000}\n",
      "-0.006 (+/-0.015) for {'alpha': 3, 'max_iter': 1000}\n",
      "-0.006 (+/-0.015) for {'alpha': 3, 'max_iter': 10000}\n",
      "-0.006 (+/-0.015) for {'alpha': 10, 'max_iter': 1000}\n",
      "-0.006 (+/-0.015) for {'alpha': 10, 'max_iter': 10000}\n",
      "-0.006 (+/-0.015) for {'alpha': 30, 'max_iter': 1000}\n",
      "-0.006 (+/-0.015) for {'alpha': 30, 'max_iter': 10000}\n",
      "-0.006 (+/-0.015) for {'alpha': 100, 'max_iter': 1000}\n",
      "-0.006 (+/-0.015) for {'alpha': 100, 'max_iter': 10000}\n",
      "\n",
      "*** Highest R^2 score: \n",
      "0.917\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'alpha': 0.1, 'max_iter': 1000}\n",
      "\n",
      "*** Final R^2 score: \n",
      "0.928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.851,\n",
       " 'Linear Regression': 0.936,\n",
       " 'Ridge Regression': 0.938,\n",
       " 'Lasso Regression': 0.928}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "param_grid = [{\"alpha\": [0.1, 0.3, 1, 3, 10, 30, 100], \"max_iter\": [1000, 10000]}]\n",
    "lasso = GridSearchCV(Lasso(), param_grid, cv=cv)\n",
    "lasso, score = train_test4(X_train_scaled, X_test_scaled, y_train, y_test, param_grid, lasso)\n",
    "summary[\"Lasso Regression\"] = score\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84764956-2eb3-4855-a00b-f3db361fd48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.851,\n",
       " 'Linear Regression': 0.936,\n",
       " 'Ridge Regression': 0.938,\n",
       " 'Lasso Regression': 0.928}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6fa9df",
   "metadata": {},
   "source": [
    "Best Model Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "911c8b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GF: 39.84\n",
      "GA: -7.267\n",
      "GF/GP: -3.129\n",
      "GA/GP: -19.004\n",
      "PK%: 0.113\n",
      "Shots/GP: -1.843\n"
     ]
    }
   ],
   "source": [
    "for feature, coef in zip(features, ridge.best_estimator_.coef_):\n",
    "    print(f\"{feature}: {round(coef, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa0daa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GF: 39.84\n",
      "PK%: 0.113\n"
     ]
    }
   ],
   "source": [
    "for feature, coef in zip(features, ridge.best_estimator_.coef_):\n",
    "    if coef > 0:               \n",
    "        print(f\"{feature}: {round(coef, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ed3c36-7d65-45ea-b431-45a1ab7016c6",
   "metadata": {},
   "source": [
    "## Take away \n",
    "\n",
    "Goals is an obvious indicator of sucess, but PK% being signficant and more than Power Play is interesting and not expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb55c14",
   "metadata": {},
   "source": [
    "### Multi Class\n",
    "predicting what round of playoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b9692c",
   "metadata": {},
   "source": [
    "### 0 didnt make playoffs, 1, first round,2 second round,3 3rd round, 4 made it to teh stanleycup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4fe5edfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = stats.columns[2:23]\n",
    "target = \"rp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0a5e8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((267, 21), (267,), (67, 21), (67,))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = stats[features]\n",
    "y = stats[target]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "50c8ba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def train_test3(X_train, X_test, y_train, y_test, param_grid, clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"*** Parameter estimation results: \")\n",
    "    print(clf.cv_results_)\n",
    "    print()\n",
    "    \n",
    "    print(\"*** Grid scores: \")\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    params = clf.cv_results_['params']\n",
    "\n",
    "    for mean, std, param in zip(means, stds, params):\n",
    "        print(f\"{round(mean, 3)} (+/-{round(std*2, 3)}) for {param}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"*** Highest accuracy score: \")\n",
    "    print(f\"{round(clf.best_score_, 3)}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"*** Best parameters set found: \")\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    \n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    \n",
    "    print(\"*** Classification report for the best parameters set: \")\n",
    "    print(metrics.classification_report(y_true, y_pred))\n",
    "    print()\n",
    "    \n",
    "    print(\"*** Confusion matrix for the best parameters set: \")\n",
    "    print(metrics.confusion_matrix(y_true, y_pred))\n",
    "    print()\n",
    "    \n",
    "    print(\"*** Final f1-score: \")\n",
    "    f1_score = round(metrics.f1_score(y_true, y_pred, average=\"micro\"), 3)\n",
    "    print(f1_score)\n",
    "    \n",
    "    return clf, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf4e5874",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 5\n",
    "summary1 = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a4b52b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.00292206, 0.00285654, 0.00239115, 0.00245175, 0.00206633]), 'std_fit_time': array([0.00120485, 0.00123674, 0.00081062, 0.0010165 , 0.001016  ]), 'mean_score_time': array([0.00320196, 0.00372519, 0.00427356, 0.00338297, 0.00343838]), 'std_score_time': array([0.00098191, 0.00155261, 0.00103639, 0.00047618, 0.00100541]), 'param_n_neighbors': masked_array(data=[1, 3, 10, 30, 100],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_neighbors': 1}, {'n_neighbors': 3}, {'n_neighbors': 10}, {'n_neighbors': 30}, {'n_neighbors': 100}], 'split0_test_score': array([0.57407407, 0.59259259, 0.62962963, 0.51851852, 0.53703704]), 'split1_test_score': array([0.57407407, 0.61111111, 0.64814815, 0.64814815, 0.57407407]), 'split2_test_score': array([0.60377358, 0.60377358, 0.64150943, 0.66037736, 0.64150943]), 'split3_test_score': array([0.62264151, 0.64150943, 0.69811321, 0.71698113, 0.62264151]), 'split4_test_score': array([0.58490566, 0.60377358, 0.62264151, 0.62264151, 0.60377358]), 'mean_test_score': array([0.59189378, 0.61055206, 0.64800839, 0.63333333, 0.59580713]), 'std_test_score': array([0.01881739, 0.01657172, 0.02658573, 0.06518369, 0.03687411]), 'rank_test_score': array([5, 3, 1, 2, 4])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.592 (+/-0.038) for {'n_neighbors': 1}\n",
      "0.611 (+/-0.033) for {'n_neighbors': 3}\n",
      "0.648 (+/-0.053) for {'n_neighbors': 10}\n",
      "0.633 (+/-0.13) for {'n_neighbors': 30}\n",
      "0.596 (+/-0.074) for {'n_neighbors': 100}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.648\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'n_neighbors': 10}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.97      0.85        33\n",
      "           1       0.43      0.59      0.50        17\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.63        67\n",
      "   macro avg       0.24      0.31      0.27        67\n",
      "weighted avg       0.49      0.63      0.55        67\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[32  1  0  0  0]\n",
      " [ 6 10  0  1  0]\n",
      " [ 2  6  0  0  0]\n",
      " [ 0  3  1  0  0]\n",
      " [ 2  3  0  0  0]]\n",
      "\n",
      "*** Final f1-score: \n",
      "0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.627}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_grid = [{\"n_neighbors\": [1, 3, 10, 30, 100]}]\n",
    "knc = GridSearchCV(KNeighborsClassifier(), param_grid, cv=cv)\n",
    "knc, score = train_test3(X_train, X_test, y_train, y_test, param_grid, knc)\n",
    "summary1[\"k-NNs\"] = score\n",
    "summary1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b83c25d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.02835588, 0.00686541, 0.03699455, 0.00608482, 0.03147726,\n",
      "       0.00652514, 0.0291306 , 0.00928121, 0.03128347, 0.00813861,\n",
      "       0.02769332, 0.00987072, 0.02426944, 0.01039762]), 'std_fit_time': array([0.00151182, 0.00073767, 0.00577025, 0.00130864, 0.00509465,\n",
      "       0.00089886, 0.00281849, 0.00168403, 0.00324419, 0.00044637,\n",
      "       0.00355192, 0.00033942, 0.00106693, 0.00111195]), 'mean_score_time': array([0.00236044, 0.00236468, 0.00256948, 0.00153818, 0.00239158,\n",
      "       0.00179763, 0.002177  , 0.00225396, 0.00221519, 0.00120101,\n",
      "       0.00219951, 0.00100656, 0.00204649, 0.00139108]), 'std_score_time': array([7.76103616e-04, 4.90231164e-04, 1.37014332e-03, 6.71789007e-04,\n",
      "       5.09953365e-04, 3.98738702e-04, 4.14269334e-04, 3.88501225e-04,\n",
      "       1.00766701e-03, 4.00257139e-04, 4.00507153e-04, 2.49173765e-05,\n",
      "       7.98151339e-05, 8.04625123e-04]), 'param_C': masked_array(data=[0.01, 0.01, 0.03, 0.03, 0.1, 0.1, 0.3, 0.3, 1, 1, 3, 3,\n",
      "                   10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_solver': masked_array(data=['lbfgs', 'liblinear', 'lbfgs', 'liblinear', 'lbfgs',\n",
      "                   'liblinear', 'lbfgs', 'liblinear', 'lbfgs',\n",
      "                   'liblinear', 'lbfgs', 'liblinear', 'lbfgs',\n",
      "                   'liblinear'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.01, 'solver': 'lbfgs'}, {'C': 0.01, 'solver': 'liblinear'}, {'C': 0.03, 'solver': 'lbfgs'}, {'C': 0.03, 'solver': 'liblinear'}, {'C': 0.1, 'solver': 'lbfgs'}, {'C': 0.1, 'solver': 'liblinear'}, {'C': 0.3, 'solver': 'lbfgs'}, {'C': 0.3, 'solver': 'liblinear'}, {'C': 1, 'solver': 'lbfgs'}, {'C': 1, 'solver': 'liblinear'}, {'C': 3, 'solver': 'lbfgs'}, {'C': 3, 'solver': 'liblinear'}, {'C': 10, 'solver': 'lbfgs'}, {'C': 10, 'solver': 'liblinear'}], 'split0_test_score': array([0.62962963, 0.61111111, 0.59259259, 0.62962963, 0.62962963,\n",
      "       0.64814815, 0.64814815, 0.64814815, 0.64814815, 0.62962963,\n",
      "       0.62962963, 0.61111111, 0.62962963, 0.61111111]), 'split1_test_score': array([0.64814815, 0.62962963, 0.62962963, 0.62962963, 0.62962963,\n",
      "       0.62962963, 0.62962963, 0.66666667, 0.61111111, 0.66666667,\n",
      "       0.57407407, 0.68518519, 0.62962963, 0.68518519]), 'split2_test_score': array([0.69811321, 0.66037736, 0.66037736, 0.67924528, 0.66037736,\n",
      "       0.67924528, 0.66037736, 0.69811321, 0.69811321, 0.71698113,\n",
      "       0.66037736, 0.69811321, 0.64150943, 0.69811321]), 'split3_test_score': array([0.66037736, 0.67924528, 0.67924528, 0.66037736, 0.66037736,\n",
      "       0.66037736, 0.67924528, 0.67924528, 0.66037736, 0.69811321,\n",
      "       0.67924528, 0.69811321, 0.67924528, 0.71698113]), 'split4_test_score': array([0.62264151, 0.62264151, 0.62264151, 0.62264151, 0.62264151,\n",
      "       0.64150943, 0.62264151, 0.62264151, 0.62264151, 0.66037736,\n",
      "       0.62264151, 0.67924528, 0.62264151, 0.67924528]), 'mean_test_score': array([0.65178197, 0.64060098, 0.63689727, 0.64430468, 0.6405311 ,\n",
      "       0.65178197, 0.64800839, 0.66296296, 0.64807827, 0.6743536 ,\n",
      "       0.63319357, 0.6743536 , 0.6405311 , 0.67812718]), 'std_test_score': array([0.0267341 , 0.02528657, 0.03021132, 0.02181368, 0.01640408,\n",
      "       0.01695624, 0.0205427 , 0.02592169, 0.03055607, 0.03045089,\n",
      "       0.03599689, 0.03246506, 0.0202853 , 0.03592016]), 'rank_test_score': array([ 5, 10, 13,  9, 11,  6,  8,  4,  7,  2, 14,  2, 11,  1])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.652 (+/-0.053) for {'C': 0.01, 'solver': 'lbfgs'}\n",
      "0.641 (+/-0.051) for {'C': 0.01, 'solver': 'liblinear'}\n",
      "0.637 (+/-0.06) for {'C': 0.03, 'solver': 'lbfgs'}\n",
      "0.644 (+/-0.044) for {'C': 0.03, 'solver': 'liblinear'}\n",
      "0.641 (+/-0.033) for {'C': 0.1, 'solver': 'lbfgs'}\n",
      "0.652 (+/-0.034) for {'C': 0.1, 'solver': 'liblinear'}\n",
      "0.648 (+/-0.041) for {'C': 0.3, 'solver': 'lbfgs'}\n",
      "0.663 (+/-0.052) for {'C': 0.3, 'solver': 'liblinear'}\n",
      "0.648 (+/-0.061) for {'C': 1, 'solver': 'lbfgs'}\n",
      "0.674 (+/-0.061) for {'C': 1, 'solver': 'liblinear'}\n",
      "0.633 (+/-0.072) for {'C': 3, 'solver': 'lbfgs'}\n",
      "0.674 (+/-0.065) for {'C': 3, 'solver': 'liblinear'}\n",
      "0.641 (+/-0.041) for {'C': 10, 'solver': 'lbfgs'}\n",
      "0.678 (+/-0.072) for {'C': 10, 'solver': 'liblinear'}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.678\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'C': 10, 'solver': 'liblinear'}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.94      0.79        33\n",
      "           1       0.38      0.35      0.36        17\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.50      0.40      0.44         5\n",
      "\n",
      "    accuracy                           0.58        67\n",
      "   macro avg       0.31      0.34      0.32        67\n",
      "weighted avg       0.47      0.58      0.52        67\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[31  2  0  0  0]\n",
      " [ 8  6  2  0  1]\n",
      " [ 3  4  0  0  1]\n",
      " [ 1  3  0  0  0]\n",
      " [ 2  1  0  0  2]]\n",
      "\n",
      "*** Final f1-score: \n",
      "0.582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.627, 'Logistic Regression': 0.582}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = [{\"C\": [0.01, 0.03, 0.1, 0.3, 1, 3, 10], \"solver\": [\"lbfgs\", \"liblinear\"]}]\n",
    "lr = GridSearchCV(LogisticRegression(), param_grid, cv=cv)\n",
    "lr, score = train_test3(X_train, X_test, y_train, y_test, param_grid, lr)\n",
    "summary1[\"Logistic Regression\"] = score\n",
    "summary1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "687e10bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.00207138, 0.00200925, 0.0032073 , 0.00299215]), 'std_fit_time': array([5.30723741e-04, 2.83498038e-05, 3.63926030e-04, 4.06440397e-05]), 'mean_score_time': array([0.00138659, 0.00098906, 0.00097976, 0.00122046]), 'std_score_time': array([7.74745249e-04, 2.35764995e-05, 2.14701722e-05, 3.93289524e-04]), 'param_max_depth': masked_array(data=[1, 3, 10, None],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 1}, {'max_depth': 3}, {'max_depth': 10}, {'max_depth': None}], 'split0_test_score': array([0.59259259, 0.57407407, 0.59259259, 0.53703704]), 'split1_test_score': array([0.64814815, 0.64814815, 0.61111111, 0.61111111]), 'split2_test_score': array([0.67924528, 0.62264151, 0.67924528, 0.54716981]), 'split3_test_score': array([0.71698113, 0.75471698, 0.67924528, 0.67924528]), 'split4_test_score': array([0.64150943, 0.69811321, 0.67924528, 0.71698113]), 'mean_test_score': array([0.65569532, 0.65953878, 0.64828791, 0.61830887]), 'std_test_score': array([0.04135385, 0.06219686, 0.03836446, 0.07094666]), 'rank_test_score': array([2, 1, 3, 4])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.656 (+/-0.083) for {'max_depth': 1}\n",
      "0.66 (+/-0.124) for {'max_depth': 3}\n",
      "0.648 (+/-0.077) for {'max_depth': 10}\n",
      "0.618 (+/-0.142) for {'max_depth': None}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.66\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'max_depth': 3}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89        33\n",
      "           1       0.50      0.82      0.62        17\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       1.00      0.40      0.57         5\n",
      "\n",
      "    accuracy                           0.70        67\n",
      "   macro avg       0.47      0.43      0.42        67\n",
      "weighted avg       0.61      0.70      0.64        67\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[31  2  0  0  0]\n",
      " [ 3 14  0  0  0]\n",
      " [ 2  6  0  0  0]\n",
      " [ 0  4  0  0  0]\n",
      " [ 1  2  0  0  2]]\n",
      "\n",
      "*** Final f1-score: \n",
      "0.701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.627, 'Logistic Regression': 0.582, 'Decision Trees': 0.701}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "param_grid = [{\"max_depth\": [1, 3, 10, None]}]\n",
    "dtc = GridSearchCV(DecisionTreeClassifier(random_state=0), param_grid, cv=cv)\n",
    "dtc, score = train_test3(X_train, X_test, y_train, y_test, param_grid, dtc)\n",
    "summary1[\"Decision Trees\"] = score\n",
    "summary1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6bb08a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([3.46989632e-03, 5.66983223e-03, 1.21190071e-02, 3.10738087e-02,\n",
      "       9.21025276e-02, 6.38078499e-01, 4.04380379e+00, 1.21225834e-02,\n",
      "       1.71347141e-02, 4.31528091e-02, 1.20161867e-01, 3.58987570e-01,\n",
      "       1.09433694e+00, 3.68470182e+00, 1.21247292e-02, 2.89621830e-02,\n",
      "       5.81598759e-02, 1.38331318e-01, 4.74009323e-01, 1.31042566e+00,\n",
      "       4.19512796e+00, 1.07204914e-02, 1.88240051e-02, 5.05047798e-02,\n",
      "       1.31715107e-01, 4.17556047e-01, 1.24299536e+00, 4.19852266e+00]), 'std_fit_time': array([0.00048012, 0.0006928 , 0.00104328, 0.00143766, 0.0032076 ,\n",
      "       0.30134551, 0.30661925, 0.0013874 , 0.00059821, 0.00083585,\n",
      "       0.00595374, 0.01087059, 0.05769164, 0.15686294, 0.00086138,\n",
      "       0.00314515, 0.0095746 , 0.01239498, 0.03451235, 0.16316891,\n",
      "       0.07641472, 0.00056035, 0.00041834, 0.00496659, 0.00591483,\n",
      "       0.01099195, 0.01779142, 0.03856618]), 'mean_score_time': array([0.00236669, 0.00266228, 0.00219121, 0.00361795, 0.00807204,\n",
      "       0.05508866, 0.28852754, 0.00630765, 0.00536122, 0.00728784,\n",
      "       0.01244392, 0.02689166, 0.07049346, 0.2604919 , 0.00586576,\n",
      "       0.00912371, 0.01078048, 0.01403189, 0.03062267, 0.0861701 ,\n",
      "       0.27084618, 0.00490317, 0.00580916, 0.0078938 , 0.01286469,\n",
      "       0.02824612, 0.07749619, 0.25440841]), 'std_score_time': array([0.00050904, 0.00128115, 0.00037237, 0.0004726 , 0.00069349,\n",
      "       0.02778327, 0.04110032, 0.00142718, 0.0007952 , 0.00039707,\n",
      "       0.00226425, 0.00096022, 0.00239707, 0.02988143, 0.00081921,\n",
      "       0.00112641, 0.00220222, 0.00264311, 0.00423341, 0.01140655,\n",
      "       0.04196746, 0.00025131, 0.00041697, 0.00047761, 0.00016743,\n",
      "       0.00041861, 0.00137647, 0.00913505]), 'param_max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 10, 10, 10,\n",
      "                   10, 10, 10, 10, None, None, None, None, None, None,\n",
      "                   None],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[1, 3, 10, 30, 100, 300, 1000, 1, 3, 10, 30, 100, 300,\n",
      "                   1000, 1, 3, 10, 30, 100, 300, 1000, 1, 3, 10, 30, 100,\n",
      "                   300, 1000],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 1, 'n_estimators': 1}, {'max_depth': 1, 'n_estimators': 3}, {'max_depth': 1, 'n_estimators': 10}, {'max_depth': 1, 'n_estimators': 30}, {'max_depth': 1, 'n_estimators': 100}, {'max_depth': 1, 'n_estimators': 300}, {'max_depth': 1, 'n_estimators': 1000}, {'max_depth': 3, 'n_estimators': 1}, {'max_depth': 3, 'n_estimators': 3}, {'max_depth': 3, 'n_estimators': 10}, {'max_depth': 3, 'n_estimators': 30}, {'max_depth': 3, 'n_estimators': 100}, {'max_depth': 3, 'n_estimators': 300}, {'max_depth': 3, 'n_estimators': 1000}, {'max_depth': 10, 'n_estimators': 1}, {'max_depth': 10, 'n_estimators': 3}, {'max_depth': 10, 'n_estimators': 10}, {'max_depth': 10, 'n_estimators': 30}, {'max_depth': 10, 'n_estimators': 100}, {'max_depth': 10, 'n_estimators': 300}, {'max_depth': 10, 'n_estimators': 1000}, {'max_depth': None, 'n_estimators': 1}, {'max_depth': None, 'n_estimators': 3}, {'max_depth': None, 'n_estimators': 10}, {'max_depth': None, 'n_estimators': 30}, {'max_depth': None, 'n_estimators': 100}, {'max_depth': None, 'n_estimators': 300}, {'max_depth': None, 'n_estimators': 1000}], 'split0_test_score': array([0.53703704, 0.55555556, 0.53703704, 0.53703704, 0.53703704,\n",
      "       0.55555556, 0.53703704, 0.59259259, 0.53703704, 0.53703704,\n",
      "       0.55555556, 0.57407407, 0.55555556, 0.55555556, 0.44444444,\n",
      "       0.53703704, 0.57407407, 0.57407407, 0.55555556, 0.59259259,\n",
      "       0.59259259, 0.46296296, 0.51851852, 0.55555556, 0.55555556,\n",
      "       0.55555556, 0.59259259, 0.57407407]), 'split1_test_score': array([0.64814815, 0.62962963, 0.64814815, 0.62962963, 0.62962963,\n",
      "       0.62962963, 0.62962963, 0.64814815, 0.62962963, 0.61111111,\n",
      "       0.62962963, 0.61111111, 0.61111111, 0.62962963, 0.55555556,\n",
      "       0.55555556, 0.55555556, 0.55555556, 0.59259259, 0.61111111,\n",
      "       0.61111111, 0.55555556, 0.55555556, 0.61111111, 0.57407407,\n",
      "       0.57407407, 0.59259259, 0.61111111]), 'split2_test_score': array([0.60377358, 0.64150943, 0.64150943, 0.62264151, 0.60377358,\n",
      "       0.62264151, 0.64150943, 0.67924528, 0.67924528, 0.71698113,\n",
      "       0.75471698, 0.73584906, 0.73584906, 0.73584906, 0.60377358,\n",
      "       0.67924528, 0.69811321, 0.71698113, 0.73584906, 0.73584906,\n",
      "       0.73584906, 0.62264151, 0.67924528, 0.71698113, 0.71698113,\n",
      "       0.75471698, 0.73584906, 0.73584906]), 'split3_test_score': array([0.50943396, 0.69811321, 0.71698113, 0.64150943, 0.67924528,\n",
      "       0.67924528, 0.66037736, 0.66037736, 0.64150943, 0.64150943,\n",
      "       0.66037736, 0.69811321, 0.69811321, 0.66037736, 0.64150943,\n",
      "       0.67924528, 0.64150943, 0.62264151, 0.66037736, 0.67924528,\n",
      "       0.67924528, 0.60377358, 0.62264151, 0.66037736, 0.64150943,\n",
      "       0.62264151, 0.71698113, 0.66037736]), 'split4_test_score': array([0.62264151, 0.58490566, 0.60377358, 0.62264151, 0.62264151,\n",
      "       0.62264151, 0.62264151, 0.49056604, 0.64150943, 0.64150943,\n",
      "       0.66037736, 0.66037736, 0.66037736, 0.66037736, 0.66037736,\n",
      "       0.69811321, 0.71698113, 0.66037736, 0.69811321, 0.71698113,\n",
      "       0.69811321, 0.60377358, 0.66037736, 0.69811321, 0.66037736,\n",
      "       0.67924528, 0.69811321, 0.69811321]), 'mean_test_score': array([0.58420685, 0.6219427 , 0.62948987, 0.61069182, 0.61446541,\n",
      "       0.6219427 , 0.61823899, 0.61418588, 0.62578616, 0.62962963,\n",
      "       0.65213138, 0.65590496, 0.65220126, 0.64835779, 0.58113208,\n",
      "       0.62983927, 0.63724668, 0.62592593, 0.64849755, 0.66715584,\n",
      "       0.66338225, 0.56974144, 0.60726765, 0.64842767, 0.62969951,\n",
      "       0.63724668, 0.66722572, 0.65590496]), 'std_test_score': array([0.05246817, 0.04903649, 0.05891719, 0.03746727, 0.04604933,\n",
      "       0.03937234, 0.04256769, 0.06821723, 0.04742046, 0.05801529,\n",
      "       0.06402034, 0.05812982, 0.06356178, 0.05814922, 0.07716935,\n",
      "       0.06880925, 0.06441228, 0.05853092, 0.06632753, 0.05665362,\n",
      "       0.05376386, 0.05782331, 0.0612998 , 0.05887067, 0.0588051 ,\n",
      "       0.07271958, 0.0620951 , 0.05812982]), 'rank_test_score': array([26, 19, 16, 24, 22, 19, 21, 23, 18, 15,  7,  4,  6, 10, 27, 13, 11,\n",
      "       17,  8,  2,  3, 28, 25,  9, 14, 11,  1,  4])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.584 (+/-0.105) for {'max_depth': 1, 'n_estimators': 1}\n",
      "0.622 (+/-0.098) for {'max_depth': 1, 'n_estimators': 3}\n",
      "0.629 (+/-0.118) for {'max_depth': 1, 'n_estimators': 10}\n",
      "0.611 (+/-0.075) for {'max_depth': 1, 'n_estimators': 30}\n",
      "0.614 (+/-0.092) for {'max_depth': 1, 'n_estimators': 100}\n",
      "0.622 (+/-0.079) for {'max_depth': 1, 'n_estimators': 300}\n",
      "0.618 (+/-0.085) for {'max_depth': 1, 'n_estimators': 1000}\n",
      "0.614 (+/-0.136) for {'max_depth': 3, 'n_estimators': 1}\n",
      "0.626 (+/-0.095) for {'max_depth': 3, 'n_estimators': 3}\n",
      "0.63 (+/-0.116) for {'max_depth': 3, 'n_estimators': 10}\n",
      "0.652 (+/-0.128) for {'max_depth': 3, 'n_estimators': 30}\n",
      "0.656 (+/-0.116) for {'max_depth': 3, 'n_estimators': 100}\n",
      "0.652 (+/-0.127) for {'max_depth': 3, 'n_estimators': 300}\n",
      "0.648 (+/-0.116) for {'max_depth': 3, 'n_estimators': 1000}\n",
      "0.581 (+/-0.154) for {'max_depth': 10, 'n_estimators': 1}\n",
      "0.63 (+/-0.138) for {'max_depth': 10, 'n_estimators': 3}\n",
      "0.637 (+/-0.129) for {'max_depth': 10, 'n_estimators': 10}\n",
      "0.626 (+/-0.117) for {'max_depth': 10, 'n_estimators': 30}\n",
      "0.648 (+/-0.133) for {'max_depth': 10, 'n_estimators': 100}\n",
      "0.667 (+/-0.113) for {'max_depth': 10, 'n_estimators': 300}\n",
      "0.663 (+/-0.108) for {'max_depth': 10, 'n_estimators': 1000}\n",
      "0.57 (+/-0.116) for {'max_depth': None, 'n_estimators': 1}\n",
      "0.607 (+/-0.123) for {'max_depth': None, 'n_estimators': 3}\n",
      "0.648 (+/-0.118) for {'max_depth': None, 'n_estimators': 10}\n",
      "0.63 (+/-0.118) for {'max_depth': None, 'n_estimators': 30}\n",
      "0.637 (+/-0.145) for {'max_depth': None, 'n_estimators': 100}\n",
      "0.667 (+/-0.124) for {'max_depth': None, 'n_estimators': 300}\n",
      "0.656 (+/-0.116) for {'max_depth': None, 'n_estimators': 1000}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.667\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'max_depth': None, 'n_estimators': 300}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.97      0.86        33\n",
      "           1       0.42      0.47      0.44        17\n",
      "           2       0.33      0.12      0.18         8\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.33      0.20      0.25         5\n",
      "\n",
      "    accuracy                           0.63        67\n",
      "   macro avg       0.37      0.35      0.35        67\n",
      "weighted avg       0.56      0.63      0.58        67\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[32  0  0  0  1]\n",
      " [ 6  8  2  1  0]\n",
      " [ 2  4  1  0  1]\n",
      " [ 0  4  0  0  0]\n",
      " [ 1  3  0  0  1]]\n",
      "\n",
      "*** Final f1-score: \n",
      "0.627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.627,\n",
       " 'Logistic Regression': 0.582,\n",
       " 'Decision Trees': 0.701,\n",
       " 'Random Forest': 0.627}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = [{\"n_estimators\": [1, 3, 10, 30, 100, 300, 1000], \"max_depth\": [1, 3, 10, None]}]\n",
    "rfc = GridSearchCV(RandomForestClassifier(random_state=0), param_grid, cv=cv)\n",
    "rfc, score = train_test3(X_train, X_test, y_train, y_test, param_grid, rfc)\n",
    "summary1[\"Random Forest\"] = score\n",
    "summary1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "70ff9832",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:02:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:03:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:03:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:03:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:03:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:03:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:03:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:03:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:03:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:03:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:03:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:03:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:03:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.4833055 , 0.48737102, 0.50499396, 0.4765111 , 0.40622301,\n",
      "       0.35074062, 0.34520054]), 'std_fit_time': array([0.01025385, 0.00886356, 0.00563748, 0.01278434, 0.01017674,\n",
      "       0.01234809, 0.02334312]), 'mean_score_time': array([0.01076527, 0.01059775, 0.01072869, 0.01043649, 0.01004825,\n",
      "       0.00986066, 0.01103754]), 'std_score_time': array([0.00039409, 0.00076857, 0.00086544, 0.00091715, 0.00060093,\n",
      "       0.00046504, 0.00119254]), 'param_reg_alpha': masked_array(data=[0.01, 0.03, 0.1, 0.3, 1, 3, 10],\n",
      "             mask=[False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'reg_alpha': 0.01}, {'reg_alpha': 0.03}, {'reg_alpha': 0.1}, {'reg_alpha': 0.3}, {'reg_alpha': 1}, {'reg_alpha': 3}, {'reg_alpha': 10}], 'split0_test_score': array([0.59259259, 0.61111111, 0.55555556, 0.57407407, 0.59259259,\n",
      "       0.59259259, 0.57407407]), 'split1_test_score': array([0.57407407, 0.57407407, 0.61111111, 0.66666667, 0.66666667,\n",
      "       0.7037037 , 0.66666667]), 'split2_test_score': array([0.73584906, 0.71698113, 0.69811321, 0.77358491, 0.73584906,\n",
      "       0.77358491, 0.71698113]), 'split3_test_score': array([0.62264151, 0.64150943, 0.66037736, 0.67924528, 0.69811321,\n",
      "       0.67924528, 0.69811321]), 'split4_test_score': array([0.69811321, 0.67924528, 0.64150943, 0.69811321, 0.67924528,\n",
      "       0.67924528, 0.67924528]), 'mean_test_score': array([0.64465409, 0.64458421, 0.63333333, 0.67833683, 0.67449336,\n",
      "       0.68567435, 0.66701607]), 'std_test_score': array([0.06221076, 0.05008849, 0.04803721, 0.063986  , 0.04714656,\n",
      "       0.05796586, 0.04950036]), 'rank_test_score': array([5, 6, 7, 2, 3, 1, 4])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.645 (+/-0.124) for {'reg_alpha': 0.01}\n",
      "0.645 (+/-0.1) for {'reg_alpha': 0.03}\n",
      "0.633 (+/-0.096) for {'reg_alpha': 0.1}\n",
      "0.678 (+/-0.128) for {'reg_alpha': 0.3}\n",
      "0.674 (+/-0.094) for {'reg_alpha': 1}\n",
      "0.686 (+/-0.116) for {'reg_alpha': 3}\n",
      "0.667 (+/-0.099) for {'reg_alpha': 10}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.686\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'reg_alpha': 3}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88        33\n",
      "           1       0.48      0.59      0.53        17\n",
      "           2       0.20      0.12      0.15         8\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       1.00      0.20      0.33         5\n",
      "\n",
      "    accuracy                           0.66        67\n",
      "   macro avg       0.50      0.38      0.38        67\n",
      "weighted avg       0.61      0.66      0.61        67\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[32  0  1  0  0]\n",
      " [ 5 10  2  0  0]\n",
      " [ 2  5  1  0  0]\n",
      " [ 0  3  1  0  0]\n",
      " [ 1  3  0  0  1]]\n",
      "\n",
      "*** Final f1-score: \n",
      "0.657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.627,\n",
       " 'Logistic Regression': 0.582,\n",
       " 'Decision Trees': 0.701,\n",
       " 'Random Forest': 0.627,\n",
       " 'XGBoost': 0.657}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "param_grid = [{\"reg_alpha\": [0.01, 0.03, 0.1, 0.3, 1, 3, 10]}]\n",
    "xgbc = GridSearchCV(XGBClassifier(random_state=0), param_grid, cv=cv)\n",
    "xgbc, score = train_test3(X_train, X_test, y_train, y_test, param_grid, xgbc)\n",
    "summary1[\"XGBoost\"] = score\n",
    "summary1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0468f393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.15839496, 0.14385982, 0.14429955, 0.14486575, 0.1460094 ,\n",
      "       0.14496641, 0.14527016]), 'std_fit_time': array([0.01079799, 0.00301826, 0.00539299, 0.0033822 , 0.00422028,\n",
      "       0.00347374, 0.00389351]), 'mean_score_time': array([0.00622206, 0.00492492, 0.00454741, 0.00457201, 0.00451503,\n",
      "       0.00460296, 0.0047812 ]), 'std_score_time': array([0.00074746, 0.00067029, 0.00048046, 0.00049647, 0.00045483,\n",
      "       0.00049593, 0.00074403]), 'param_C': masked_array(data=[0.01, 0.03, 0.1, 0.3, 1, 3, 10],\n",
      "             mask=[False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.01}, {'C': 0.03}, {'C': 0.1}, {'C': 0.3}, {'C': 1}, {'C': 3}, {'C': 10}], 'split0_test_score': array([0.37037037, 0.55555556, 0.40740741, 0.57407407, 0.48148148,\n",
      "       0.59259259, 0.61111111]), 'split1_test_score': array([0.51851852, 0.5       , 0.51851852, 0.51851852, 0.62962963,\n",
      "       0.53703704, 0.53703704]), 'split2_test_score': array([0.47169811, 0.30188679, 0.62264151, 0.37735849, 0.37735849,\n",
      "       0.13207547, 0.13207547]), 'split3_test_score': array([0.60377358, 0.54716981, 0.50943396, 0.66037736, 0.58490566,\n",
      "       0.47169811, 0.47169811]), 'split4_test_score': array([0.69811321, 0.50943396, 0.58490566, 0.50943396, 0.66037736,\n",
      "       0.66037736, 0.66037736]), 'mean_test_score': array([0.53249476, 0.48280922, 0.52858141, 0.52795248, 0.54675052,\n",
      "       0.47875611, 0.48245982]), 'std_test_score': array([0.11196966, 0.09292108, 0.07371669, 0.0924922 , 0.10410526,\n",
      "       0.18416241, 0.18658482]), 'rank_test_score': array([2, 5, 3, 4, 1, 7, 6])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.532 (+/-0.224) for {'C': 0.01}\n",
      "0.483 (+/-0.186) for {'C': 0.03}\n",
      "0.529 (+/-0.147) for {'C': 0.1}\n",
      "0.528 (+/-0.185) for {'C': 0.3}\n",
      "0.547 (+/-0.208) for {'C': 1}\n",
      "0.479 (+/-0.368) for {'C': 3}\n",
      "0.482 (+/-0.373) for {'C': 10}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.547\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'C': 1}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.64      0.78        33\n",
      "           1       0.37      1.00      0.54        17\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.57        67\n",
      "   macro avg       0.27      0.33      0.26        67\n",
      "weighted avg       0.59      0.57      0.52        67\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[21 12  0  0  0]\n",
      " [ 0 17  0  0  0]\n",
      " [ 0  8  0  0  0]\n",
      " [ 0  4  0  0  0]\n",
      " [ 0  5  0  0  0]]\n",
      "\n",
      "*** Final f1-score: \n",
      "0.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.627,\n",
       " 'Logistic Regression': 0.582,\n",
       " 'Decision Trees': 0.701,\n",
       " 'Random Forest': 0.627,\n",
       " 'XGBoost': 0.657,\n",
       " 'Linear SVMs': 0.567}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "param_grid = [{\"C\": [0.01, 0.03, 0.1, 0.3, 1, 3, 10]}]\n",
    "lsvc = GridSearchCV(LinearSVC(random_state=0), param_grid, cv=cv)\n",
    "lsvc, score = train_test3(X_train, X_test, y_train, y_test, param_grid, lsvc)\n",
    "summary1[\"Linear SVMs\"] = score\n",
    "summary1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d10b697-4e96-4cd8-ac88-75809ec1f8e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.01323442, 0.02241068, 0.02387977, 0.02742066, 0.02893438,\n",
      "       0.03109779, 0.03314805, 0.0128458 , 0.02238574, 0.02638521,\n",
      "       0.02940617, 0.03025351, 0.029427  , 0.03288956, 0.01507168,\n",
      "       0.02322707, 0.0256001 , 0.02880778, 0.02939916, 0.03117352,\n",
      "       0.0324151 , 0.01271482, 0.02469478, 0.03547873, 0.029635  ,\n",
      "       0.03142991, 0.03108864, 0.03373022, 0.013095  , 0.02375269,\n",
      "       0.02561369, 0.03288865, 0.03042951, 0.03018394, 0.03032689]), 'std_fit_time': array([0.00143252, 0.00064854, 0.00027634, 0.00082337, 0.00129953,\n",
      "       0.00300584, 0.00555231, 0.00071842, 0.00049924, 0.00213834,\n",
      "       0.00176088, 0.00264867, 0.00094086, 0.00797926, 0.00225449,\n",
      "       0.00075742, 0.00083409, 0.00115257, 0.00152003, 0.00248876,\n",
      "       0.00379209, 0.00039493, 0.00057756, 0.00535717, 0.00082397,\n",
      "       0.00209196, 0.00142048, 0.00423433, 0.00048308, 0.00095243,\n",
      "       0.00105278, 0.00556243, 0.00049716, 0.00074724, 0.00032867]), 'mean_score_time': array([0.00715756, 0.00855513, 0.00839715, 0.00978665, 0.00940623,\n",
      "       0.01203475, 0.00963483, 0.00658641, 0.00890322, 0.00987802,\n",
      "       0.00921421, 0.00978975, 0.00910926, 0.01198106, 0.00813046,\n",
      "       0.00819011, 0.00826974, 0.00878053, 0.00969124, 0.01048059,\n",
      "       0.01002283, 0.00699854, 0.00852408, 0.01253753, 0.00934548,\n",
      "       0.00936289, 0.00970387, 0.00900168, 0.00658789, 0.00823932,\n",
      "       0.00820599, 0.01044884, 0.00954142, 0.00923123, 0.00923114]), 'std_score_time': array([3.91579476e-04, 1.14790974e-03, 4.83919792e-04, 7.22605666e-04,\n",
      "       4.66107056e-04, 2.68115554e-03, 8.24322017e-04, 4.79622564e-04,\n",
      "       1.78444304e-03, 2.04646715e-03, 4.65946557e-04, 7.84830035e-04,\n",
      "       1.84160968e-04, 3.01013533e-03, 1.63093118e-03, 3.70451882e-04,\n",
      "       4.22605991e-04, 3.69952701e-04, 3.72172456e-04, 1.80071470e-03,\n",
      "       6.42374154e-04, 4.74806275e-05, 9.02500036e-04, 3.06141802e-03,\n",
      "       4.23167910e-04, 4.42848668e-04, 4.71979022e-04, 4.74407203e-05,\n",
      "       4.26290649e-04, 6.06970782e-04, 4.37077861e-04, 1.62359590e-03,\n",
      "       6.24796520e-04, 4.70597923e-04, 5.21826378e-04]), 'param_C': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.3, 0.3, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3,\n",
      "                   3, 10, 10, 10, 10, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=['scale', 'auto', 0.1, 0.3, 1, 3, 10, 'scale', 'auto',\n",
      "                   0.1, 0.3, 1, 3, 10, 'scale', 'auto', 0.1, 0.3, 1, 3,\n",
      "                   10, 'scale', 'auto', 0.1, 0.3, 1, 3, 10, 'scale',\n",
      "                   'auto', 0.1, 0.3, 1, 3, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.1, 'gamma': 'scale'}, {'C': 0.1, 'gamma': 'auto'}, {'C': 0.1, 'gamma': 0.1}, {'C': 0.1, 'gamma': 0.3}, {'C': 0.1, 'gamma': 1}, {'C': 0.1, 'gamma': 3}, {'C': 0.1, 'gamma': 10}, {'C': 0.3, 'gamma': 'scale'}, {'C': 0.3, 'gamma': 'auto'}, {'C': 0.3, 'gamma': 0.1}, {'C': 0.3, 'gamma': 0.3}, {'C': 0.3, 'gamma': 1}, {'C': 0.3, 'gamma': 3}, {'C': 0.3, 'gamma': 10}, {'C': 1, 'gamma': 'scale'}, {'C': 1, 'gamma': 'auto'}, {'C': 1, 'gamma': 0.1}, {'C': 1, 'gamma': 0.3}, {'C': 1, 'gamma': 1}, {'C': 1, 'gamma': 3}, {'C': 1, 'gamma': 10}, {'C': 3, 'gamma': 'scale'}, {'C': 3, 'gamma': 'auto'}, {'C': 3, 'gamma': 0.1}, {'C': 3, 'gamma': 0.3}, {'C': 3, 'gamma': 1}, {'C': 3, 'gamma': 3}, {'C': 3, 'gamma': 10}, {'C': 10, 'gamma': 'scale'}, {'C': 10, 'gamma': 'auto'}, {'C': 10, 'gamma': 0.1}, {'C': 10, 'gamma': 0.3}, {'C': 10, 'gamma': 1}, {'C': 10, 'gamma': 3}, {'C': 10, 'gamma': 10}], 'split0_test_score': array([0.48148148, 0.48148148, 0.48148148, 0.48148148, 0.48148148,\n",
      "       0.48148148, 0.48148148, 0.48148148, 0.48148148, 0.48148148,\n",
      "       0.48148148, 0.48148148, 0.48148148, 0.48148148, 0.59259259,\n",
      "       0.48148148, 0.48148148, 0.48148148, 0.48148148, 0.48148148,\n",
      "       0.48148148, 0.55555556, 0.48148148, 0.48148148, 0.48148148,\n",
      "       0.48148148, 0.48148148, 0.48148148, 0.55555556, 0.48148148,\n",
      "       0.48148148, 0.48148148, 0.48148148, 0.48148148, 0.48148148]), 'split1_test_score': array([0.48148148, 0.48148148, 0.48148148, 0.48148148, 0.48148148,\n",
      "       0.48148148, 0.48148148, 0.48148148, 0.48148148, 0.48148148,\n",
      "       0.48148148, 0.48148148, 0.48148148, 0.48148148, 0.64814815,\n",
      "       0.48148148, 0.48148148, 0.48148148, 0.48148148, 0.48148148,\n",
      "       0.48148148, 0.64814815, 0.48148148, 0.48148148, 0.48148148,\n",
      "       0.48148148, 0.48148148, 0.48148148, 0.64814815, 0.48148148,\n",
      "       0.48148148, 0.48148148, 0.48148148, 0.48148148, 0.48148148]), 'split2_test_score': array([0.50943396, 0.50943396, 0.50943396, 0.50943396, 0.50943396,\n",
      "       0.50943396, 0.50943396, 0.50943396, 0.50943396, 0.50943396,\n",
      "       0.50943396, 0.50943396, 0.50943396, 0.50943396, 0.73584906,\n",
      "       0.50943396, 0.50943396, 0.50943396, 0.50943396, 0.50943396,\n",
      "       0.50943396, 0.67924528, 0.50943396, 0.50943396, 0.50943396,\n",
      "       0.50943396, 0.50943396, 0.50943396, 0.69811321, 0.50943396,\n",
      "       0.50943396, 0.50943396, 0.50943396, 0.50943396, 0.50943396]), 'split3_test_score': array([0.50943396, 0.50943396, 0.50943396, 0.50943396, 0.50943396,\n",
      "       0.50943396, 0.50943396, 0.50943396, 0.50943396, 0.50943396,\n",
      "       0.50943396, 0.50943396, 0.50943396, 0.50943396, 0.71698113,\n",
      "       0.50943396, 0.50943396, 0.50943396, 0.50943396, 0.50943396,\n",
      "       0.50943396, 0.67924528, 0.50943396, 0.50943396, 0.50943396,\n",
      "       0.50943396, 0.50943396, 0.50943396, 0.69811321, 0.50943396,\n",
      "       0.50943396, 0.50943396, 0.50943396, 0.50943396, 0.50943396]), 'split4_test_score': array([0.50943396, 0.50943396, 0.50943396, 0.50943396, 0.50943396,\n",
      "       0.50943396, 0.50943396, 0.50943396, 0.50943396, 0.50943396,\n",
      "       0.50943396, 0.50943396, 0.50943396, 0.50943396, 0.64150943,\n",
      "       0.50943396, 0.50943396, 0.50943396, 0.50943396, 0.50943396,\n",
      "       0.50943396, 0.66037736, 0.50943396, 0.50943396, 0.50943396,\n",
      "       0.50943396, 0.50943396, 0.50943396, 0.64150943, 0.50943396,\n",
      "       0.50943396, 0.50943396, 0.50943396, 0.50943396, 0.50943396]), 'mean_test_score': array([0.49825297, 0.49825297, 0.49825297, 0.49825297, 0.49825297,\n",
      "       0.49825297, 0.49825297, 0.49825297, 0.49825297, 0.49825297,\n",
      "       0.49825297, 0.49825297, 0.49825297, 0.49825297, 0.66701607,\n",
      "       0.49825297, 0.49825297, 0.49825297, 0.49825297, 0.49825297,\n",
      "       0.49825297, 0.64451433, 0.49825297, 0.49825297, 0.49825297,\n",
      "       0.49825297, 0.49825297, 0.49825297, 0.64828791, 0.49825297,\n",
      "       0.49825297, 0.49825297, 0.49825297, 0.49825297, 0.49825297]), 'std_test_score': array([0.01369386, 0.01369386, 0.01369386, 0.01369386, 0.01369386,\n",
      "       0.01369386, 0.01369386, 0.01369386, 0.01369386, 0.01369386,\n",
      "       0.01369386, 0.01369386, 0.01369386, 0.01369386, 0.05249748,\n",
      "       0.01369386, 0.01369386, 0.01369386, 0.01369386, 0.01369386,\n",
      "       0.01369386, 0.04602387, 0.01369386, 0.01369386, 0.01369386,\n",
      "       0.01369386, 0.01369386, 0.01369386, 0.05217351, 0.01369386,\n",
      "       0.01369386, 0.01369386, 0.01369386, 0.01369386, 0.01369386]), 'rank_test_score': array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 3,\n",
      "       4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.498 (+/-0.027) for {'C': 0.1, 'gamma': 'scale'}\n",
      "0.498 (+/-0.027) for {'C': 0.1, 'gamma': 'auto'}\n",
      "0.498 (+/-0.027) for {'C': 0.1, 'gamma': 0.1}\n",
      "0.498 (+/-0.027) for {'C': 0.1, 'gamma': 0.3}\n",
      "0.498 (+/-0.027) for {'C': 0.1, 'gamma': 1}\n",
      "0.498 (+/-0.027) for {'C': 0.1, 'gamma': 3}\n",
      "0.498 (+/-0.027) for {'C': 0.1, 'gamma': 10}\n",
      "0.498 (+/-0.027) for {'C': 0.3, 'gamma': 'scale'}\n",
      "0.498 (+/-0.027) for {'C': 0.3, 'gamma': 'auto'}\n",
      "0.498 (+/-0.027) for {'C': 0.3, 'gamma': 0.1}\n",
      "0.498 (+/-0.027) for {'C': 0.3, 'gamma': 0.3}\n",
      "0.498 (+/-0.027) for {'C': 0.3, 'gamma': 1}\n",
      "0.498 (+/-0.027) for {'C': 0.3, 'gamma': 3}\n",
      "0.498 (+/-0.027) for {'C': 0.3, 'gamma': 10}\n",
      "0.667 (+/-0.105) for {'C': 1, 'gamma': 'scale'}\n",
      "0.498 (+/-0.027) for {'C': 1, 'gamma': 'auto'}\n",
      "0.498 (+/-0.027) for {'C': 1, 'gamma': 0.1}\n",
      "0.498 (+/-0.027) for {'C': 1, 'gamma': 0.3}\n",
      "0.498 (+/-0.027) for {'C': 1, 'gamma': 1}\n",
      "0.498 (+/-0.027) for {'C': 1, 'gamma': 3}\n",
      "0.498 (+/-0.027) for {'C': 1, 'gamma': 10}\n",
      "0.645 (+/-0.092) for {'C': 3, 'gamma': 'scale'}\n",
      "0.498 (+/-0.027) for {'C': 3, 'gamma': 'auto'}\n",
      "0.498 (+/-0.027) for {'C': 3, 'gamma': 0.1}\n",
      "0.498 (+/-0.027) for {'C': 3, 'gamma': 0.3}\n",
      "0.498 (+/-0.027) for {'C': 3, 'gamma': 1}\n",
      "0.498 (+/-0.027) for {'C': 3, 'gamma': 3}\n",
      "0.498 (+/-0.027) for {'C': 3, 'gamma': 10}\n",
      "0.648 (+/-0.104) for {'C': 10, 'gamma': 'scale'}\n",
      "0.498 (+/-0.027) for {'C': 10, 'gamma': 'auto'}\n",
      "0.498 (+/-0.027) for {'C': 10, 'gamma': 0.1}\n",
      "0.498 (+/-0.027) for {'C': 10, 'gamma': 0.3}\n",
      "0.498 (+/-0.027) for {'C': 10, 'gamma': 1}\n",
      "0.498 (+/-0.027) for {'C': 10, 'gamma': 3}\n",
      "0.498 (+/-0.027) for {'C': 10, 'gamma': 10}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.667\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'C': 1, 'gamma': 'scale'}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.94      0.81        33\n",
      "           1       0.43      0.59      0.50        17\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.61        67\n",
      "   macro avg       0.23      0.31      0.26        67\n",
      "weighted avg       0.46      0.61      0.52        67\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[31  2  0  0  0]\n",
      " [ 7 10  0  0  0]\n",
      " [ 3  5  0  0  0]\n",
      " [ 1  3  0  0  0]\n",
      " [ 2  3  0  0  0]]\n",
      "\n",
      "*** Final f1-score: \n",
      "0.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.627,\n",
       " 'Logistic Regression': 0.582,\n",
       " 'Decision Trees': 0.701,\n",
       " 'Random Forest': 0.627,\n",
       " 'XGBoost': 0.657,\n",
       " 'Linear SVMs': 0.567,\n",
       " 'Kernelized SVMs': 0.612}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid = [{\"C\": [0.1, 0.3, 1, 3, 10], \"gamma\": [\"scale\", \"auto\", 0.1, 0.3, 1, 3, 10]}]\n",
    "svc = GridSearchCV(SVC(random_state=0), param_grid, cv=cv)\n",
    "svc, score = train_test3(X_train, X_test, y_train, y_test, param_grid, svc)\n",
    "summary1[\"Kernelized SVMs\"] = score\n",
    "summary1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "07ee84f7-fe90-4924-b1fd-28540f9f7785",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.27363782, 0.11872449, 0.30509291, 0.0617527 , 0.16075153,\n",
      "       0.34780478, 1.15163546, 0.29573755, 0.08745847]), 'std_fit_time': array([0.0628951 , 0.13259249, 0.06739269, 0.00281978, 0.04159285,\n",
      "       0.04074882, 0.2771079 , 0.09087761, 0.00237132]), 'mean_score_time': array([0.0048831 , 0.00463738, 0.00435438, 0.00561604, 0.00448542,\n",
      "       0.00499291, 0.0059773 , 0.00516977, 0.00500855]), 'std_score_time': array([0.00086978, 0.00133605, 0.00040151, 0.00083186, 0.00042634,\n",
      "       0.00021045, 0.00060658, 0.0003746 , 0.00063166]), 'param_hidden_layer_sizes': masked_array(data=[(10,), (10,), (10,), (30,), (30,), (30,), (100,),\n",
      "                   (100,), (100,)],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_solver': masked_array(data=['lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
      "                   'lbfgs', 'sgd', 'adam'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'hidden_layer_sizes': (10,), 'solver': 'lbfgs'}, {'hidden_layer_sizes': (10,), 'solver': 'sgd'}, {'hidden_layer_sizes': (10,), 'solver': 'adam'}, {'hidden_layer_sizes': (30,), 'solver': 'lbfgs'}, {'hidden_layer_sizes': (30,), 'solver': 'sgd'}, {'hidden_layer_sizes': (30,), 'solver': 'adam'}, {'hidden_layer_sizes': (100,), 'solver': 'lbfgs'}, {'hidden_layer_sizes': (100,), 'solver': 'sgd'}, {'hidden_layer_sizes': (100,), 'solver': 'adam'}], 'split0_test_score': array([0.61111111, 0.48148148, 0.5       , 0.48148148, 0.55555556,\n",
      "       0.55555556, 0.64814815, 0.55555556, 0.57407407]), 'split1_test_score': array([0.62962963, 0.48148148, 0.55555556, 0.48148148, 0.55555556,\n",
      "       0.64814815, 0.62962963, 0.53703704, 0.57407407]), 'split2_test_score': array([0.75471698, 0.66037736, 0.56603774, 0.50943396, 0.56603774,\n",
      "       0.52830189, 0.67924528, 0.62264151, 0.50943396]), 'split3_test_score': array([0.67924528, 0.50943396, 0.69811321, 0.50943396, 0.58490566,\n",
      "       0.67924528, 0.58490566, 0.49056604, 0.64150943]), 'split4_test_score': array([0.66037736, 0.50943396, 0.58490566, 0.50943396, 0.56603774,\n",
      "       0.60377358, 0.66037736, 0.56603774, 0.58490566]), 'mean_test_score': array([0.66701607, 0.52844165, 0.58092243, 0.49825297, 0.56561845,\n",
      "       0.60300489, 0.64046122, 0.55436758, 0.57679944]), 'std_test_score': array([0.04981603, 0.06714184, 0.06505846, 0.01369386, 0.01072261,\n",
      "       0.0560055 , 0.03213624, 0.04282503, 0.04196679]), 'rank_test_score': array([1, 8, 4, 9, 6, 3, 2, 7, 5])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.667 (+/-0.1) for {'hidden_layer_sizes': (10,), 'solver': 'lbfgs'}\n",
      "0.528 (+/-0.134) for {'hidden_layer_sizes': (10,), 'solver': 'sgd'}\n",
      "0.581 (+/-0.13) for {'hidden_layer_sizes': (10,), 'solver': 'adam'}\n",
      "0.498 (+/-0.027) for {'hidden_layer_sizes': (30,), 'solver': 'lbfgs'}\n",
      "0.566 (+/-0.021) for {'hidden_layer_sizes': (30,), 'solver': 'sgd'}\n",
      "0.603 (+/-0.112) for {'hidden_layer_sizes': (30,), 'solver': 'adam'}\n",
      "0.64 (+/-0.064) for {'hidden_layer_sizes': (100,), 'solver': 'lbfgs'}\n",
      "0.554 (+/-0.086) for {'hidden_layer_sizes': (100,), 'solver': 'sgd'}\n",
      "0.577 (+/-0.084) for {'hidden_layer_sizes': (100,), 'solver': 'adam'}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.667\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'hidden_layer_sizes': (10,), 'solver': 'lbfgs'}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85        33\n",
      "           1       0.41      0.65      0.50        17\n",
      "           2       0.00      0.00      0.00         8\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.63        67\n",
      "   macro avg       0.24      0.32      0.27        67\n",
      "weighted avg       0.49      0.63      0.55        67\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[31  2  0  0  0]\n",
      " [ 6 11  0  0  0]\n",
      " [ 2  6  0  0  0]\n",
      " [ 0  4  0  0  0]\n",
      " [ 1  4  0  0  0]]\n",
      "\n",
      "*** Final f1-score: \n",
      "0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.627,\n",
       " 'Logistic Regression': 0.582,\n",
       " 'Decision Trees': 0.701,\n",
       " 'Random Forest': 0.627,\n",
       " 'XGBoost': 0.657,\n",
       " 'Linear SVMs': 0.567,\n",
       " 'Kernelized SVMs': 0.612,\n",
       " 'Neural Networks': 0.627}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "param_grid = [{\"hidden_layer_sizes\": [(10,), (30,), (100,)], \"solver\": [\"lbfgs\", \"sgd\", \"adam\"]}]\n",
    "mlpc = GridSearchCV(MLPClassifier(random_state=0), param_grid, cv=cv)\n",
    "mlpc, score = train_test3(X_train, X_test, y_train, y_test, param_grid, mlpc)\n",
    "summary1[\"Neural Networks\"] = score\n",
    "summary1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03a4932-78d3-4a1c-97a1-745fc769ce59",
   "metadata": {},
   "source": [
    "# Best model decsion tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f8c19ea3-bdd3-4e7d-88c4-1e9926c28c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.627,\n",
       " 'Logistic Regression': 0.582,\n",
       " 'Decision Trees': 0.701,\n",
       " 'Random Forest': 0.627,\n",
       " 'XGBoost': 0.97,\n",
       " 'Linear SVMs': 0.567,\n",
       " 'Kernelized SVMs': 0.612,\n",
       " 'Neural Networks': 0.627}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e8c08de4-09a6-424d-984f-09cfa262122d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=0),\n",
       "             param_grid=[{'max_depth': [1, 3, 10, None]}])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_best = dtc\n",
    "clf_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc9b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_test, clf_best.predict(X_test)\n",
    "\n",
    "print(metrics.confusion_matrix(y_true, y_pred))\n",
    "print(metrics.classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f07f9b9-74f3-4265-872d-7721d2f01e59",
   "metadata": {},
   "source": [
    "## Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c08cf0c0-abae-4478-91ec-239f0580842c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 334 entries, 0 to 333\n",
      "Data columns (total 24 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Team      334 non-null    object \n",
      " 1   Season    334 non-null    int64  \n",
      " 2   GP        334 non-null    int64  \n",
      " 3   W         334 non-null    int64  \n",
      " 4   L         334 non-null    int64  \n",
      " 5   OT        334 non-null    int64  \n",
      " 6   P         334 non-null    int64  \n",
      " 7   P%        334 non-null    float64\n",
      " 8   RW        334 non-null    int64  \n",
      " 9   ROW       334 non-null    int64  \n",
      " 10  S/O Win   334 non-null    int64  \n",
      " 11  GF        334 non-null    int64  \n",
      " 12  GA        334 non-null    int64  \n",
      " 13  GF/GP     334 non-null    float64\n",
      " 14  GA/GP     334 non-null    float64\n",
      " 15  PP%       334 non-null    float64\n",
      " 16  PK%       334 non-null    float64\n",
      " 17  Net PP%   334 non-null    float64\n",
      " 18  Net PK%   334 non-null    float64\n",
      " 19  Shots/GP  334 non-null    float64\n",
      " 20  SA/GP     334 non-null    float64\n",
      " 21  FOW%      334 non-null    float64\n",
      " 22  cup       334 non-null    int64  \n",
      " 23  rp        334 non-null    int64  \n",
      "dtypes: float64(10), int64(13), object(1)\n",
      "memory usage: 62.8+ KB\n"
     ]
    }
   ],
   "source": [
    "stats.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c8ae80ca-d0a9-454d-aeb2-cba182fecb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = stats.columns[3:22]\n",
    "target = \"cup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "763efe18-b53e-4b7c-b8df-bc0ad503e3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((267, 19), (267,), (67, 19), (67,))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = stats[features]\n",
    "y = stats[target]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ad957eb2-2aab-4ea4-9653-9a0242a025e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def train_test2(X_train, X_test, y_train, y_test, param_grid, clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"*** Parameter estimation results: \")\n",
    "    print(clf.cv_results_)\n",
    "    print()\n",
    "    \n",
    "    print(\"*** Grid scores: \")\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    params = clf.cv_results_['params']\n",
    "\n",
    "    for mean, std, param in zip(means, stds, params):\n",
    "        print(f\"{round(mean, 3)} (+/-{round(std*2, 3)}) for {param}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"*** Highest accuracy score: \")\n",
    "    print(f\"{round(clf.best_score_, 3)}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"*** Best parameters set found: \")\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    \n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    \n",
    "    print(\"*** Classification report for the best parameters set: \")\n",
    "    print(metrics.classification_report(y_true, y_pred))\n",
    "    print()\n",
    "    \n",
    "    print(\"*** Confusion matrix for the best parameters set: \")\n",
    "    print(metrics.confusion_matrix(y_true, y_pred))\n",
    "    print()\n",
    "    \n",
    "    print(\"*** Final accuracy score: \")\n",
    "    test_score = round(clf.score(X_test, y_test), 3)\n",
    "    print(test_score)\n",
    "    \n",
    "    return clf, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "95b136b9-3f1b-450c-9307-ca6c82eb61dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{\"n_neighbors\": [1, 3, 10, 30, 100]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "803e787b-43c2-43a1-a4f2-1cb3bcf27c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cc3c9460-6e29-4e87-8260-5aed54f3efb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid=[{'n_neighbors': [1, 3, 10, 30, 100]}])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knc = GridSearchCV(KNeighborsClassifier(), param_grid, cv=cv)\n",
    "knc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3a63b7f1-b66e-46fd-80c2-594e0339cbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.00684452, 0.00572886, 0.00541744, 0.0053884 , 0.00519457]), 'std_fit_time': array([0.00152982, 0.00036058, 0.00042503, 0.00080077, 0.00016558]), 'mean_score_time': array([0.01052814, 0.00819063, 0.00882478, 0.00883212, 0.01008897]), 'std_score_time': array([0.00202496, 0.00040483, 0.00072655, 0.00043885, 0.00012333]), 'param_n_neighbors': masked_array(data=[1, 3, 10, 30, 100],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_neighbors': 1}, {'n_neighbors': 3}, {'n_neighbors': 10}, {'n_neighbors': 30}, {'n_neighbors': 100}], 'split0_test_score': array([0.94444444, 0.96296296, 0.96296296, 0.96296296, 0.96296296]), 'split1_test_score': array([0.94444444, 0.96296296, 0.96296296, 0.96296296, 0.96296296]), 'split2_test_score': array([0.96226415, 0.98113208, 0.98113208, 0.98113208, 0.98113208]), 'split3_test_score': array([0.98113208, 0.96226415, 0.96226415, 0.96226415, 0.96226415]), 'split4_test_score': array([0.9245283 , 0.96226415, 0.96226415, 0.96226415, 0.96226415]), 'mean_test_score': array([0.95136268, 0.96631726, 0.96631726, 0.96631726, 0.96631726]), 'std_test_score': array([0.01908333, 0.007414  , 0.007414  , 0.007414  , 0.007414  ]), 'rank_test_score': array([5, 1, 1, 1, 1])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.951 (+/-0.038) for {'n_neighbors': 1}\n",
      "0.966 (+/-0.015) for {'n_neighbors': 3}\n",
      "0.966 (+/-0.015) for {'n_neighbors': 10}\n",
      "0.966 (+/-0.015) for {'n_neighbors': 30}\n",
      "0.966 (+/-0.015) for {'n_neighbors': 100}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.966\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'n_neighbors': 3}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        65\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.97        67\n",
      "   macro avg       0.49      0.50      0.49        67\n",
      "weighted avg       0.94      0.97      0.96        67\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[65  0]\n",
      " [ 2  0]]\n",
      "\n",
      "*** Final accuracy score: \n",
      "0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.97}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knc, score = train_test2(X_train, X_test, y_train, y_test, param_grid, knc)\n",
    "summary2 = dict()\n",
    "summary2[\"k-NNs\"] = score\n",
    "summary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "42ccdb4c-82e9-4057-82fd-e640e313b751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.05829287, 0.00760469, 0.05874715, 0.00728498, 0.06283097,\n",
      "       0.00837164, 0.06143498, 0.01035299, 0.06303535, 0.00856161,\n",
      "       0.06095729, 0.01045976, 0.05849328, 0.01193175]), 'std_fit_time': array([0.00803773, 0.00081403, 0.0074945 , 0.00037241, 0.00637367,\n",
      "       0.00051481, 0.00377914, 0.00136148, 0.00446304, 0.00098305,\n",
      "       0.00597875, 0.00170424, 0.00187088, 0.00276263]), 'mean_score_time': array([0.0050436 , 0.00383635, 0.00500078, 0.00367208, 0.00486264,\n",
      "       0.00395255, 0.00441704, 0.00535536, 0.00547748, 0.00320053,\n",
      "       0.00479288, 0.00465679, 0.00521827, 0.0046824 ]), 'std_score_time': array([0.00101913, 0.00083657, 0.00109751, 0.0005417 , 0.00072961,\n",
      "       0.00063275, 0.00047833, 0.00120527, 0.00078621, 0.00074993,\n",
      "       0.00034175, 0.00077543, 0.00130858, 0.0005878 ]), 'param_C': masked_array(data=[0.01, 0.01, 0.03, 0.03, 0.1, 0.1, 0.3, 0.3, 1, 1, 3, 3,\n",
      "                   10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_solver': masked_array(data=['lbfgs', 'liblinear', 'lbfgs', 'liblinear', 'lbfgs',\n",
      "                   'liblinear', 'lbfgs', 'liblinear', 'lbfgs',\n",
      "                   'liblinear', 'lbfgs', 'liblinear', 'lbfgs',\n",
      "                   'liblinear'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.01, 'solver': 'lbfgs'}, {'C': 0.01, 'solver': 'liblinear'}, {'C': 0.03, 'solver': 'lbfgs'}, {'C': 0.03, 'solver': 'liblinear'}, {'C': 0.1, 'solver': 'lbfgs'}, {'C': 0.1, 'solver': 'liblinear'}, {'C': 0.3, 'solver': 'lbfgs'}, {'C': 0.3, 'solver': 'liblinear'}, {'C': 1, 'solver': 'lbfgs'}, {'C': 1, 'solver': 'liblinear'}, {'C': 3, 'solver': 'lbfgs'}, {'C': 3, 'solver': 'liblinear'}, {'C': 10, 'solver': 'lbfgs'}, {'C': 10, 'solver': 'liblinear'}], 'split0_test_score': array([0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
      "       0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
      "       0.94444444, 0.94444444, 0.94444444, 0.94444444]), 'split1_test_score': array([0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296]), 'split2_test_score': array([0.98113208, 0.98113208, 0.98113208, 0.98113208, 0.98113208,\n",
      "       0.98113208, 0.98113208, 0.98113208, 0.98113208, 0.98113208,\n",
      "       0.98113208, 0.98113208, 0.98113208, 0.98113208]), 'split3_test_score': array([0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.94339623, 0.96226415, 0.94339623]), 'split4_test_score': array([0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415]), 'mean_test_score': array([0.96261356, 0.96261356, 0.96261356, 0.96261356, 0.96261356,\n",
      "       0.96261356, 0.96261356, 0.96261356, 0.96261356, 0.96261356,\n",
      "       0.96261356, 0.95883997, 0.96261356, 0.95883997]), 'std_test_score': array([0.01160533, 0.01160533, 0.01160533, 0.01160533, 0.01160533,\n",
      "       0.01160533, 0.01160533, 0.01160533, 0.01160533, 0.01160533,\n",
      "       0.01160533, 0.01393845, 0.01160533, 0.01393845]), 'rank_test_score': array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 13,  1, 13])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.963 (+/-0.023) for {'C': 0.01, 'solver': 'lbfgs'}\n",
      "0.963 (+/-0.023) for {'C': 0.01, 'solver': 'liblinear'}\n",
      "0.963 (+/-0.023) for {'C': 0.03, 'solver': 'lbfgs'}\n",
      "0.963 (+/-0.023) for {'C': 0.03, 'solver': 'liblinear'}\n",
      "0.963 (+/-0.023) for {'C': 0.1, 'solver': 'lbfgs'}\n",
      "0.963 (+/-0.023) for {'C': 0.1, 'solver': 'liblinear'}\n",
      "0.963 (+/-0.023) for {'C': 0.3, 'solver': 'lbfgs'}\n",
      "0.963 (+/-0.023) for {'C': 0.3, 'solver': 'liblinear'}\n",
      "0.963 (+/-0.023) for {'C': 1, 'solver': 'lbfgs'}\n",
      "0.963 (+/-0.023) for {'C': 1, 'solver': 'liblinear'}\n",
      "0.963 (+/-0.023) for {'C': 3, 'solver': 'lbfgs'}\n",
      "0.959 (+/-0.028) for {'C': 3, 'solver': 'liblinear'}\n",
      "0.963 (+/-0.023) for {'C': 10, 'solver': 'lbfgs'}\n",
      "0.959 (+/-0.028) for {'C': 10, 'solver': 'liblinear'}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.963\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'C': 0.01, 'solver': 'lbfgs'}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        65\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.97        67\n",
      "   macro avg       0.49      0.50      0.49        67\n",
      "weighted avg       0.94      0.97      0.96        67\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[65  0]\n",
      " [ 2  0]]\n",
      "\n",
      "*** Final accuracy score: \n",
      "0.97\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.97, 'Logistic Regression': 0.97}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{\"C\": [0.01, 0.03, 0.1, 0.3, 1, 3, 10], \"solver\": [\"lbfgs\", \"liblinear\"]}]\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = GridSearchCV(LogisticRegression(), param_grid, cv=cv)\n",
    "lr, score = train_test2(X_train, X_test, y_train, y_test, param_grid, lr)\n",
    "summary2[\"Logistic Regression\"] = score\n",
    "summary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3a51947e-6f36-42a1-8066-e626434bb6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.00740552, 0.00903144, 0.00863862, 0.0089191 ]), 'std_fit_time': array([0.00159382, 0.00182067, 0.00085915, 0.00100178]), 'mean_score_time': array([0.00405927, 0.00457711, 0.00420918, 0.00466838]), 'std_score_time': array([0.00072842, 0.0010936 , 0.00041022, 0.00055641]), 'param_max_depth': masked_array(data=[1, 3, 10, None],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 1}, {'max_depth': 3}, {'max_depth': 10}, {'max_depth': None}], 'split0_test_score': array([0.94444444, 0.94444444, 0.92592593, 0.92592593]), 'split1_test_score': array([0.98148148, 0.98148148, 0.96296296, 0.96296296]), 'split2_test_score': array([0.98113208, 0.98113208, 0.96226415, 0.96226415]), 'split3_test_score': array([0.96226415, 0.98113208, 0.98113208, 0.98113208]), 'split4_test_score': array([0.96226415, 0.96226415, 0.96226415, 0.96226415]), 'mean_test_score': array([0.96631726, 0.97009085, 0.95890985, 0.95890985]), 'std_test_score': array([0.01386151, 0.01478215, 0.01800387, 0.01800387]), 'rank_test_score': array([2, 1, 3, 3])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.966 (+/-0.028) for {'max_depth': 1}\n",
      "0.97 (+/-0.03) for {'max_depth': 3}\n",
      "0.959 (+/-0.036) for {'max_depth': 10}\n",
      "0.959 (+/-0.036) for {'max_depth': None}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.97\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'max_depth': 3}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        65\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.97        67\n",
      "   macro avg       0.49      0.50      0.49        67\n",
      "weighted avg       0.94      0.97      0.96        67\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[65  0]\n",
      " [ 2  0]]\n",
      "\n",
      "*** Final accuracy score: \n",
      "0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.97, 'Logistic Regression': 0.97, 'Decision Trees': 0.97}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{\"max_depth\": [1, 3, 10, None]}]\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = GridSearchCV(DecisionTreeClassifier(random_state=0), param_grid, cv=cv)\n",
    "dtc, score = train_test2(X_train, X_test, y_train, y_test, param_grid, dtc)\n",
    "summary2[\"Decision Trees\"] = score\n",
    "summary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d1524ba1-d890-4a76-832c-4cdfda4fd788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.01143079, 0.01644697, 0.03899956, 0.09834642, 0.35269933,\n",
      "       1.00366192, 3.36989622, 0.01103539, 0.0181664 , 0.04230118,\n",
      "       0.12101111, 0.369695  , 1.1031004 , 3.70587335, 0.01075873,\n",
      "       0.01849866, 0.04525037, 0.11868601, 0.38814602, 1.16573496,\n",
      "       3.73831077, 0.01065001, 0.01811938, 0.04671192, 0.1235693 ,\n",
      "       0.373844  , 1.1279521 , 3.7267159 ]), 'std_fit_time': array([1.07200895e-03, 1.43559971e-03, 4.37260615e-03, 5.73453030e-03,\n",
      "       2.86590547e-03, 2.70753912e-02, 3.81842814e-02, 7.00829619e-05,\n",
      "       7.54321428e-04, 6.44944353e-04, 1.16522598e-02, 6.86896862e-03,\n",
      "       3.68938001e-02, 7.86668177e-02, 1.12491231e-03, 9.87204273e-04,\n",
      "       1.40250069e-03, 2.26705272e-03, 1.97528237e-02, 7.37420224e-02,\n",
      "       5.98509052e-02, 4.19994385e-04, 1.52335808e-04, 3.62715698e-03,\n",
      "       5.87130244e-03, 6.39382822e-03, 6.60354807e-03, 3.46957367e-02]), 'mean_score_time': array([0.00548553, 0.00645056, 0.00744843, 0.01081862, 0.02783146,\n",
      "       0.07547498, 0.25917077, 0.00542545, 0.00604486, 0.00685053,\n",
      "       0.01202216, 0.02989125, 0.07762499, 0.24491191, 0.005231  ,\n",
      "       0.00660448, 0.00774803, 0.01256943, 0.03088856, 0.07650981,\n",
      "       0.24265852, 0.00499034, 0.00596533, 0.0080205 , 0.01379328,\n",
      "       0.02907763, 0.07403879, 0.25001278]), 'std_score_time': array([5.40413985e-04, 6.89080306e-04, 7.13802307e-04, 1.03552404e-03,\n",
      "       9.17512133e-04, 3.57489461e-03, 3.65173072e-02, 4.98789423e-04,\n",
      "       6.57013778e-04, 1.04480516e-03, 5.99329672e-04, 2.16040540e-03,\n",
      "       3.10632928e-03, 6.47920220e-03, 3.86201409e-04, 1.18295770e-03,\n",
      "       5.08894806e-04, 5.15081630e-04, 3.53477964e-03, 2.58142098e-03,\n",
      "       6.43202760e-03, 3.02041619e-05, 6.46422313e-04, 9.33263959e-04,\n",
      "       2.08821041e-03, 2.18239201e-03, 1.59970655e-03, 8.95723906e-03]), 'param_max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 10, 10, 10,\n",
      "                   10, 10, 10, 10, None, None, None, None, None, None,\n",
      "                   None],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[1, 3, 10, 30, 100, 300, 1000, 1, 3, 10, 30, 100, 300,\n",
      "                   1000, 1, 3, 10, 30, 100, 300, 1000, 1, 3, 10, 30, 100,\n",
      "                   300, 1000],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 1, 'n_estimators': 1}, {'max_depth': 1, 'n_estimators': 3}, {'max_depth': 1, 'n_estimators': 10}, {'max_depth': 1, 'n_estimators': 30}, {'max_depth': 1, 'n_estimators': 100}, {'max_depth': 1, 'n_estimators': 300}, {'max_depth': 1, 'n_estimators': 1000}, {'max_depth': 3, 'n_estimators': 1}, {'max_depth': 3, 'n_estimators': 3}, {'max_depth': 3, 'n_estimators': 10}, {'max_depth': 3, 'n_estimators': 30}, {'max_depth': 3, 'n_estimators': 100}, {'max_depth': 3, 'n_estimators': 300}, {'max_depth': 3, 'n_estimators': 1000}, {'max_depth': 10, 'n_estimators': 1}, {'max_depth': 10, 'n_estimators': 3}, {'max_depth': 10, 'n_estimators': 10}, {'max_depth': 10, 'n_estimators': 30}, {'max_depth': 10, 'n_estimators': 100}, {'max_depth': 10, 'n_estimators': 300}, {'max_depth': 10, 'n_estimators': 1000}, {'max_depth': None, 'n_estimators': 1}, {'max_depth': None, 'n_estimators': 3}, {'max_depth': None, 'n_estimators': 10}, {'max_depth': None, 'n_estimators': 30}, {'max_depth': None, 'n_estimators': 100}, {'max_depth': None, 'n_estimators': 300}, {'max_depth': None, 'n_estimators': 1000}], 'split0_test_score': array([0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.90740741, 0.94444444, 0.94444444,\n",
      "       0.94444444, 0.96296296, 0.96296296, 0.96296296, 0.90740741,\n",
      "       0.92592593, 0.94444444, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.90740741, 0.92592593, 0.94444444, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296]), 'split1_test_score': array([0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.92592593,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.92592593, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296]), 'split2_test_score': array([0.98113208, 0.98113208, 0.98113208, 0.98113208, 0.98113208,\n",
      "       0.98113208, 0.98113208, 0.96226415, 0.98113208, 0.98113208,\n",
      "       0.98113208, 0.98113208, 0.98113208, 0.98113208, 0.96226415,\n",
      "       0.96226415, 0.98113208, 0.98113208, 0.98113208, 0.98113208,\n",
      "       0.98113208, 0.96226415, 0.96226415, 0.98113208, 0.98113208,\n",
      "       0.98113208, 0.98113208, 0.98113208]), 'split3_test_score': array([0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.90566038, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.90566038,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.90566038, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415]), 'split4_test_score': array([0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.94339623,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.94339623, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415]), 'mean_test_score': array([0.96631726, 0.96631726, 0.96631726, 0.96631726, 0.96631726,\n",
      "       0.96631726, 0.96631726, 0.94011181, 0.96261356, 0.96261356,\n",
      "       0.96261356, 0.96631726, 0.96631726, 0.96631726, 0.92893082,\n",
      "       0.95513627, 0.96261356, 0.96631726, 0.96631726, 0.96631726,\n",
      "       0.96631726, 0.92893082, 0.95513627, 0.96261356, 0.96631726,\n",
      "       0.96631726, 0.96631726, 0.96631726]), 'std_test_score': array([0.007414  , 0.007414  , 0.007414  , 0.007414  , 0.007414  ,\n",
      "       0.007414  , 0.007414  , 0.02742301, 0.01160533, 0.01160533,\n",
      "       0.01160533, 0.007414  , 0.007414  , 0.007414  , 0.02160629,\n",
      "       0.01460768, 0.01160533, 0.007414  , 0.007414  , 0.007414  ,\n",
      "       0.007414  , 0.02160629, 0.01460768, 0.01160533, 0.007414  ,\n",
      "       0.007414  , 0.007414  , 0.007414  ]), 'rank_test_score': array([ 1,  1,  1,  1,  1,  1,  1, 26, 19, 19, 19,  1,  1,  1, 27, 24, 19,\n",
      "        1,  1,  1,  1, 27, 24, 19,  1,  1,  1,  1])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.966 (+/-0.015) for {'max_depth': 1, 'n_estimators': 1}\n",
      "0.966 (+/-0.015) for {'max_depth': 1, 'n_estimators': 3}\n",
      "0.966 (+/-0.015) for {'max_depth': 1, 'n_estimators': 10}\n",
      "0.966 (+/-0.015) for {'max_depth': 1, 'n_estimators': 30}\n",
      "0.966 (+/-0.015) for {'max_depth': 1, 'n_estimators': 100}\n",
      "0.966 (+/-0.015) for {'max_depth': 1, 'n_estimators': 300}\n",
      "0.966 (+/-0.015) for {'max_depth': 1, 'n_estimators': 1000}\n",
      "0.94 (+/-0.055) for {'max_depth': 3, 'n_estimators': 1}\n",
      "0.963 (+/-0.023) for {'max_depth': 3, 'n_estimators': 3}\n",
      "0.963 (+/-0.023) for {'max_depth': 3, 'n_estimators': 10}\n",
      "0.963 (+/-0.023) for {'max_depth': 3, 'n_estimators': 30}\n",
      "0.966 (+/-0.015) for {'max_depth': 3, 'n_estimators': 100}\n",
      "0.966 (+/-0.015) for {'max_depth': 3, 'n_estimators': 300}\n",
      "0.966 (+/-0.015) for {'max_depth': 3, 'n_estimators': 1000}\n",
      "0.929 (+/-0.043) for {'max_depth': 10, 'n_estimators': 1}\n",
      "0.955 (+/-0.029) for {'max_depth': 10, 'n_estimators': 3}\n",
      "0.963 (+/-0.023) for {'max_depth': 10, 'n_estimators': 10}\n",
      "0.966 (+/-0.015) for {'max_depth': 10, 'n_estimators': 30}\n",
      "0.966 (+/-0.015) for {'max_depth': 10, 'n_estimators': 100}\n",
      "0.966 (+/-0.015) for {'max_depth': 10, 'n_estimators': 300}\n",
      "0.966 (+/-0.015) for {'max_depth': 10, 'n_estimators': 1000}\n",
      "0.929 (+/-0.043) for {'max_depth': None, 'n_estimators': 1}\n",
      "0.955 (+/-0.029) for {'max_depth': None, 'n_estimators': 3}\n",
      "0.963 (+/-0.023) for {'max_depth': None, 'n_estimators': 10}\n",
      "0.966 (+/-0.015) for {'max_depth': None, 'n_estimators': 30}\n",
      "0.966 (+/-0.015) for {'max_depth': None, 'n_estimators': 100}\n",
      "0.966 (+/-0.015) for {'max_depth': None, 'n_estimators': 300}\n",
      "0.966 (+/-0.015) for {'max_depth': None, 'n_estimators': 1000}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.966\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'max_depth': 1, 'n_estimators': 1}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        65\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.97        67\n",
      "   macro avg       0.49      0.50      0.49        67\n",
      "weighted avg       0.94      0.97      0.96        67\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[65  0]\n",
      " [ 2  0]]\n",
      "\n",
      "*** Final accuracy score: \n",
      "0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.97,\n",
       " 'Logistic Regression': 0.97,\n",
       " 'Decision Trees': 0.97,\n",
       " 'Random Forest': 0.97}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{\"n_estimators\": [1, 3, 10, 30, 100, 300, 1000], \"max_depth\": [1, 3, 10, None]}]\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = GridSearchCV(RandomForestClassifier(random_state=0), param_grid, cv=cv)\n",
    "rfc, score = train_test2(X_train, X_test, y_train, y_test, param_grid, rfc)\n",
    "summary2[\"Random Forest\"] = score\n",
    "summary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2ad429a9-d904-4e9b-bde9-7e0eea626eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:05:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:05:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:05:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:05:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:05:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:05:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:05:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:05:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:05:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:05:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:05:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:05:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:05:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.12016835, 0.11474562, 0.11539731, 0.11238031, 0.11495314,\n",
      "       0.1193501 , 0.11166716, 0.10262437, 0.10258498]), 'std_fit_time': array([0.00618629, 0.00434593, 0.00580417, 0.00503404, 0.004038  ,\n",
      "       0.00648923, 0.00349238, 0.00447704, 0.00256594]), 'mean_score_time': array([0.01000204, 0.00988731, 0.00939236, 0.00821753, 0.00925107,\n",
      "       0.01042047, 0.00937834, 0.01003046, 0.01012125]), 'std_score_time': array([0.00112203, 0.00049359, 0.0011563 , 0.00137728, 0.00100214,\n",
      "       0.00052299, 0.00097089, 0.00282342, 0.00094317]), 'param_reg_alpha': masked_array(data=[0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'reg_alpha': 0.001}, {'reg_alpha': 0.003}, {'reg_alpha': 0.01}, {'reg_alpha': 0.03}, {'reg_alpha': 0.1}, {'reg_alpha': 0.3}, {'reg_alpha': 1}, {'reg_alpha': 3}, {'reg_alpha': 10}], 'split0_test_score': array([0.92592593, 0.92592593, 0.92592593, 0.92592593, 0.92592593,\n",
      "       0.92592593, 0.92592593, 0.96296296, 0.96296296]), 'split1_test_score': array([0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296]), 'split2_test_score': array([0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.98113208, 0.98113208, 0.98113208, 0.98113208]), 'split3_test_score': array([0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415]), 'split4_test_score': array([0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415]), 'mean_test_score': array([0.95513627, 0.95513627, 0.95513627, 0.95513627, 0.95513627,\n",
      "       0.95890985, 0.95890985, 0.96631726, 0.96631726]), 'std_test_score': array([0.01460768, 0.01460768, 0.01460768, 0.01460768, 0.01460768,\n",
      "       0.01800387, 0.01800387, 0.007414  , 0.007414  ]), 'rank_test_score': array([5, 5, 5, 5, 5, 3, 3, 1, 1])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.955 (+/-0.029) for {'reg_alpha': 0.001}\n",
      "0.955 (+/-0.029) for {'reg_alpha': 0.003}\n",
      "0.955 (+/-0.029) for {'reg_alpha': 0.01}\n",
      "0.955 (+/-0.029) for {'reg_alpha': 0.03}\n",
      "0.955 (+/-0.029) for {'reg_alpha': 0.1}\n",
      "0.959 (+/-0.036) for {'reg_alpha': 0.3}\n",
      "0.959 (+/-0.036) for {'reg_alpha': 1}\n",
      "0.966 (+/-0.015) for {'reg_alpha': 3}\n",
      "0.966 (+/-0.015) for {'reg_alpha': 10}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.966\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'reg_alpha': 3}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        65\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.97        67\n",
      "   macro avg       0.49      0.50      0.49        67\n",
      "weighted avg       0.94      0.97      0.96        67\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[65  0]\n",
      " [ 2  0]]\n",
      "\n",
      "*** Final accuracy score: \n",
      "0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.627,\n",
       " 'Logistic Regression': 0.582,\n",
       " 'Decision Trees': 0.701,\n",
       " 'Random Forest': 0.627,\n",
       " 'XGBoost': 0.97,\n",
       " 'Linear SVMs': 0.567,\n",
       " 'Kernelized SVMs': 0.612,\n",
       " 'Neural Networks': 0.627}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{\"reg_alpha\": [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10]}]\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgbc = GridSearchCV(XGBClassifier(random_state=0), param_grid, cv=cv)\n",
    "xgbc, score = train_test2(X_train, X_test, y_train, y_test, param_grid, xgbc)\n",
    "summary1[\"XGBoost\"] = score\n",
    "summary1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e9aff040-931c-40e6-a0d0-6d3e80ebd7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.02605696, 0.02586846, 0.02514954, 0.02816329, 0.02692542,\n",
      "       0.0258976 , 0.02658186]), 'std_fit_time': array([0.00707599, 0.00341715, 0.0030827 , 0.00554427, 0.00500049,\n",
      "       0.00434996, 0.0034846 ]), 'mean_score_time': array([0.00566907, 0.00497155, 0.00569744, 0.00581403, 0.00501986,\n",
      "       0.00500898, 0.00522938]), 'std_score_time': array([1.71260378e-03, 6.69091597e-04, 3.34010233e-04, 7.58747137e-04,\n",
      "       8.88706990e-04, 1.40131724e-05, 9.43533646e-04]), 'param_C': masked_array(data=[0.01, 0.03, 0.1, 0.3, 1, 3, 10],\n",
      "             mask=[False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.01}, {'C': 0.03}, {'C': 0.1}, {'C': 0.3}, {'C': 1}, {'C': 3}, {'C': 10}], 'split0_test_score': array([0.96296296, 0.81481481, 0.96296296, 0.94444444, 0.94444444,\n",
      "       0.94444444, 0.94444444]), 'split1_test_score': array([0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296]), 'split2_test_score': array([0.98113208, 0.98113208, 0.98113208, 0.98113208, 0.98113208,\n",
      "       0.98113208, 0.98113208]), 'split3_test_score': array([0.22641509, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415]), 'split4_test_score': array([0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415]), 'mean_test_score': array([0.81914745, 0.93668763, 0.96631726, 0.96261356, 0.96261356,\n",
      "       0.96261356, 0.96261356]), 'std_test_score': array([0.29645197, 0.06136286, 0.007414  , 0.01160533, 0.01160533,\n",
      "       0.01160533, 0.01160533]), 'rank_test_score': array([7, 6, 1, 2, 2, 2, 2])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.819 (+/-0.593) for {'C': 0.01}\n",
      "0.937 (+/-0.123) for {'C': 0.03}\n",
      "0.966 (+/-0.015) for {'C': 0.1}\n",
      "0.963 (+/-0.023) for {'C': 0.3}\n",
      "0.963 (+/-0.023) for {'C': 1}\n",
      "0.963 (+/-0.023) for {'C': 3}\n",
      "0.963 (+/-0.023) for {'C': 10}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.966\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'C': 0.1}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        65\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.97        67\n",
      "   macro avg       0.49      0.50      0.49        67\n",
      "weighted avg       0.94      0.97      0.96        67\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[65  0]\n",
      " [ 2  0]]\n",
      "\n",
      "*** Final accuracy score: \n",
      "0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.97,\n",
       " 'Logistic Regression': 0.97,\n",
       " 'Decision Trees': 0.97,\n",
       " 'Random Forest': 0.97,\n",
       " 'Linear SVMs': 0.97}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{\"C\": [0.01, 0.03, 0.1, 0.3, 1, 3, 10]}]\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lsvc = GridSearchCV(LinearSVC(random_state=0), param_grid, cv=cv)\n",
    "lsvc, score = train_test2(X_train, X_test, y_train, y_test, param_grid, lsvc)\n",
    "summary2[\"Linear SVMs\"] = score\n",
    "summary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7f033a4b-a985-4fc6-9443-62dd5e73eb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.00855131, 0.01105428, 0.00779929, 0.01004729, 0.01332932,\n",
      "       0.01206164, 0.01148286, 0.01243219, 0.01201391, 0.00663857,\n",
      "       0.01403699, 0.01041512, 0.01254687, 0.01474662, 0.01618142,\n",
      "       0.0182291 , 0.01612506, 0.01602325, 0.00760503, 0.01357117,\n",
      "       0.01091046, 0.01252093, 0.01474113, 0.01599369, 0.01850042,\n",
      "       0.0163938 , 0.01699996, 0.00728908, 0.01459022, 0.01159692,\n",
      "       0.01302481, 0.01555138, 0.01803026, 0.01726255, 0.01652503,\n",
      "       0.01689711, 0.00779061, 0.01489048, 0.01233125, 0.01382623,\n",
      "       0.01508584, 0.01845384, 0.01680698, 0.01692896, 0.01706333,\n",
      "       0.00836859, 0.01462684, 0.01233273, 0.01348891, 0.01849174,\n",
      "       0.0192277 , 0.01878877, 0.01753688, 0.01787047, 0.00909386,\n",
      "       0.01436858, 0.01097693, 0.01363859, 0.01642332, 0.01717534,\n",
      "       0.01746073, 0.01731477, 0.01861358]), 'std_fit_time': array([2.15505506e-03, 6.57775022e-04, 3.94538638e-04, 9.69236009e-05,\n",
      "       1.76551409e-03, 7.66387901e-04, 5.94004636e-04, 7.77823966e-04,\n",
      "       8.80169233e-04, 5.09913154e-04, 7.04501471e-04, 4.37199517e-04,\n",
      "       4.60892766e-04, 2.54067865e-03, 2.52499094e-04, 2.50483892e-03,\n",
      "       7.80980976e-04, 6.34142196e-04, 4.91554365e-04, 8.98646069e-04,\n",
      "       2.58523254e-04, 7.23322230e-04, 7.66309291e-04, 3.74859660e-04,\n",
      "       2.73251547e-03, 4.26195110e-04, 5.17299050e-04, 4.69472193e-04,\n",
      "       1.12979044e-03, 4.62949407e-04, 6.56723446e-04, 4.15670233e-04,\n",
      "       4.60167607e-03, 1.84781858e-03, 4.33568680e-04, 5.20350537e-04,\n",
      "       3.97662676e-04, 9.24810965e-04, 7.53201129e-04, 9.17938487e-04,\n",
      "       9.08496986e-04, 2.57230946e-03, 6.71600628e-04, 6.35957834e-04,\n",
      "       3.65564694e-04, 5.82536396e-04, 4.45558809e-04, 4.73425760e-04,\n",
      "       7.39269907e-04, 3.28431243e-03, 1.89191561e-03, 2.87869484e-03,\n",
      "       4.28166792e-04, 1.57456992e-03, 3.20529342e-04, 6.77969453e-04,\n",
      "       1.03408279e-03, 9.80246460e-04, 7.88973249e-04, 1.48862774e-03,\n",
      "       3.52290881e-04, 3.93764047e-04, 1.59889408e-03]), 'mean_score_time': array([0.00481906, 0.00701542, 0.00530791, 0.00626984, 0.00698009,\n",
      "       0.00673018, 0.0069169 , 0.00661526, 0.00720029, 0.00425096,\n",
      "       0.00786867, 0.00641809, 0.00804853, 0.00910907, 0.00922999,\n",
      "       0.00883532, 0.00938568, 0.00937839, 0.00433817, 0.00808549,\n",
      "       0.00718517, 0.00777922, 0.00852699, 0.00865183, 0.00909328,\n",
      "       0.00963016, 0.00863919, 0.00434742, 0.00857072, 0.00699925,\n",
      "       0.00762463, 0.00821195, 0.01055689, 0.01001973, 0.00927095,\n",
      "       0.00921264, 0.00450101, 0.00825405, 0.00755992, 0.00772414,\n",
      "       0.00856776, 0.00998621, 0.0092041 , 0.00926876, 0.00899491,\n",
      "       0.0047996 , 0.00802765, 0.0070262 , 0.00808892, 0.01072674,\n",
      "       0.01081076, 0.00912094, 0.00956616, 0.00970101, 0.00502024,\n",
      "       0.00860791, 0.00670967, 0.00775471, 0.00918694, 0.0081049 ,\n",
      "       0.00922608, 0.00929942, 0.01061721]), 'std_score_time': array([1.19203436e-03, 6.92873106e-05, 6.02062289e-04, 4.06245435e-04,\n",
      "       5.69680560e-04, 6.61199443e-04, 7.89589618e-04, 3.66773447e-04,\n",
      "       4.00656939e-04, 4.21047356e-04, 4.38427032e-04, 5.04680776e-04,\n",
      "       5.07915293e-04, 1.59422672e-04, 3.72169878e-04, 4.47582126e-04,\n",
      "       5.03434085e-04, 4.78113336e-04, 4.55191873e-04, 6.28392735e-04,\n",
      "       4.10756324e-04, 1.21874918e-03, 4.52441866e-04, 4.25978829e-04,\n",
      "       3.03038511e-04, 7.08564942e-04, 5.20634397e-04, 6.15629931e-04,\n",
      "       9.70688016e-04, 4.33925037e-04, 4.92091512e-04, 4.88211130e-04,\n",
      "       2.05686111e-03, 6.15864503e-04, 3.91672643e-04, 4.28489346e-04,\n",
      "       6.16609644e-04, 7.38980653e-04, 4.65905521e-04, 6.03308924e-04,\n",
      "       9.79580391e-04, 1.97450002e-03, 3.41469957e-04, 7.05582277e-04,\n",
      "       1.15368541e-04, 4.02927737e-04, 6.92715899e-05, 1.28745415e-04,\n",
      "       6.56231408e-04, 3.04900750e-03, 2.71780340e-03, 2.11811313e-04,\n",
      "       4.37036554e-04, 1.81631064e-03, 3.09759232e-05, 5.19169809e-04,\n",
      "       9.13445627e-04, 3.98143511e-04, 2.23252051e-04, 9.44772187e-04,\n",
      "       3.58223134e-04, 7.43317105e-04, 2.76242580e-03]), 'param_C': masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=['scale', 'auto', 0.01, 0.03, 0.1, 0.3, 1, 3, 10,\n",
      "                   'scale', 'auto', 0.01, 0.03, 0.1, 0.3, 1, 3, 10,\n",
      "                   'scale', 'auto', 0.01, 0.03, 0.1, 0.3, 1, 3, 10,\n",
      "                   'scale', 'auto', 0.01, 0.03, 0.1, 0.3, 1, 3, 10,\n",
      "                   'scale', 'auto', 0.01, 0.03, 0.1, 0.3, 1, 3, 10,\n",
      "                   'scale', 'auto', 0.01, 0.03, 0.1, 0.3, 1, 3, 10,\n",
      "                   'scale', 'auto', 0.01, 0.03, 0.1, 0.3, 1, 3, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.01, 'gamma': 'scale'}, {'C': 0.01, 'gamma': 'auto'}, {'C': 0.01, 'gamma': 0.01}, {'C': 0.01, 'gamma': 0.03}, {'C': 0.01, 'gamma': 0.1}, {'C': 0.01, 'gamma': 0.3}, {'C': 0.01, 'gamma': 1}, {'C': 0.01, 'gamma': 3}, {'C': 0.01, 'gamma': 10}, {'C': 0.03, 'gamma': 'scale'}, {'C': 0.03, 'gamma': 'auto'}, {'C': 0.03, 'gamma': 0.01}, {'C': 0.03, 'gamma': 0.03}, {'C': 0.03, 'gamma': 0.1}, {'C': 0.03, 'gamma': 0.3}, {'C': 0.03, 'gamma': 1}, {'C': 0.03, 'gamma': 3}, {'C': 0.03, 'gamma': 10}, {'C': 0.1, 'gamma': 'scale'}, {'C': 0.1, 'gamma': 'auto'}, {'C': 0.1, 'gamma': 0.01}, {'C': 0.1, 'gamma': 0.03}, {'C': 0.1, 'gamma': 0.1}, {'C': 0.1, 'gamma': 0.3}, {'C': 0.1, 'gamma': 1}, {'C': 0.1, 'gamma': 3}, {'C': 0.1, 'gamma': 10}, {'C': 0.3, 'gamma': 'scale'}, {'C': 0.3, 'gamma': 'auto'}, {'C': 0.3, 'gamma': 0.01}, {'C': 0.3, 'gamma': 0.03}, {'C': 0.3, 'gamma': 0.1}, {'C': 0.3, 'gamma': 0.3}, {'C': 0.3, 'gamma': 1}, {'C': 0.3, 'gamma': 3}, {'C': 0.3, 'gamma': 10}, {'C': 1, 'gamma': 'scale'}, {'C': 1, 'gamma': 'auto'}, {'C': 1, 'gamma': 0.01}, {'C': 1, 'gamma': 0.03}, {'C': 1, 'gamma': 0.1}, {'C': 1, 'gamma': 0.3}, {'C': 1, 'gamma': 1}, {'C': 1, 'gamma': 3}, {'C': 1, 'gamma': 10}, {'C': 3, 'gamma': 'scale'}, {'C': 3, 'gamma': 'auto'}, {'C': 3, 'gamma': 0.01}, {'C': 3, 'gamma': 0.03}, {'C': 3, 'gamma': 0.1}, {'C': 3, 'gamma': 0.3}, {'C': 3, 'gamma': 1}, {'C': 3, 'gamma': 3}, {'C': 3, 'gamma': 10}, {'C': 10, 'gamma': 'scale'}, {'C': 10, 'gamma': 'auto'}, {'C': 10, 'gamma': 0.01}, {'C': 10, 'gamma': 0.03}, {'C': 10, 'gamma': 0.1}, {'C': 10, 'gamma': 0.3}, {'C': 10, 'gamma': 1}, {'C': 10, 'gamma': 3}, {'C': 10, 'gamma': 10}], 'split0_test_score': array([0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296]), 'split1_test_score': array([0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296]), 'split2_test_score': array([0.98113208, 0.98113208, 0.98113208, 0.98113208, 0.98113208,\n",
      "       0.98113208, 0.98113208, 0.98113208, 0.98113208, 0.98113208,\n",
      "       0.98113208, 0.98113208, 0.98113208, 0.98113208, 0.98113208,\n",
      "       0.98113208, 0.98113208, 0.98113208, 0.98113208, 0.98113208,\n",
      "       0.98113208, 0.98113208, 0.98113208, 0.98113208, 0.98113208,\n",
      "       0.98113208, 0.98113208, 0.98113208, 0.98113208, 0.98113208,\n",
      "       0.98113208, 0.98113208, 0.98113208, 0.98113208, 0.98113208,\n",
      "       0.98113208, 0.98113208, 0.98113208, 0.98113208, 0.98113208,\n",
      "       0.98113208, 0.98113208, 0.98113208, 0.98113208, 0.98113208,\n",
      "       0.98113208, 0.98113208, 0.98113208, 0.98113208, 0.98113208,\n",
      "       0.98113208, 0.98113208, 0.98113208, 0.98113208, 0.98113208,\n",
      "       0.98113208, 0.98113208, 0.98113208, 0.98113208, 0.98113208,\n",
      "       0.98113208, 0.98113208, 0.98113208]), 'split3_test_score': array([0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415]), 'split4_test_score': array([0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.94339623, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.94339623, 0.96226415, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415]), 'mean_test_score': array([0.96631726, 0.96631726, 0.96631726, 0.96631726, 0.96631726,\n",
      "       0.96631726, 0.96631726, 0.96631726, 0.96631726, 0.96631726,\n",
      "       0.96631726, 0.96631726, 0.96631726, 0.96631726, 0.96631726,\n",
      "       0.96631726, 0.96631726, 0.96631726, 0.96631726, 0.96631726,\n",
      "       0.96631726, 0.96631726, 0.96631726, 0.96631726, 0.96631726,\n",
      "       0.96631726, 0.96631726, 0.96631726, 0.96631726, 0.96631726,\n",
      "       0.96631726, 0.96631726, 0.96631726, 0.96631726, 0.96631726,\n",
      "       0.96631726, 0.96631726, 0.96631726, 0.96631726, 0.96631726,\n",
      "       0.96631726, 0.96631726, 0.96631726, 0.96631726, 0.96631726,\n",
      "       0.96631726, 0.96631726, 0.96254368, 0.96631726, 0.96631726,\n",
      "       0.96631726, 0.96631726, 0.96631726, 0.96631726, 0.96631726,\n",
      "       0.96631726, 0.96254368, 0.96631726, 0.96631726, 0.96631726,\n",
      "       0.96631726, 0.96631726, 0.96631726]), 'std_test_score': array([0.007414  , 0.007414  , 0.007414  , 0.007414  , 0.007414  ,\n",
      "       0.007414  , 0.007414  , 0.007414  , 0.007414  , 0.007414  ,\n",
      "       0.007414  , 0.007414  , 0.007414  , 0.007414  , 0.007414  ,\n",
      "       0.007414  , 0.007414  , 0.007414  , 0.007414  , 0.007414  ,\n",
      "       0.007414  , 0.007414  , 0.007414  , 0.007414  , 0.007414  ,\n",
      "       0.007414  , 0.007414  , 0.007414  , 0.007414  , 0.007414  ,\n",
      "       0.007414  , 0.007414  , 0.007414  , 0.007414  , 0.007414  ,\n",
      "       0.007414  , 0.007414  , 0.007414  , 0.007414  , 0.007414  ,\n",
      "       0.007414  , 0.007414  , 0.007414  , 0.007414  , 0.007414  ,\n",
      "       0.007414  , 0.007414  , 0.01193803, 0.007414  , 0.007414  ,\n",
      "       0.007414  , 0.007414  , 0.007414  , 0.007414  , 0.007414  ,\n",
      "       0.007414  , 0.01193803, 0.007414  , 0.007414  , 0.007414  ,\n",
      "       0.007414  , 0.007414  , 0.007414  ]), 'rank_test_score': array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 62,  1,  1,  1,\n",
      "        1,  1,  1,  1,  1, 62,  1,  1,  1,  1,  1,  1])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.966 (+/-0.015) for {'C': 0.01, 'gamma': 'scale'}\n",
      "0.966 (+/-0.015) for {'C': 0.01, 'gamma': 'auto'}\n",
      "0.966 (+/-0.015) for {'C': 0.01, 'gamma': 0.01}\n",
      "0.966 (+/-0.015) for {'C': 0.01, 'gamma': 0.03}\n",
      "0.966 (+/-0.015) for {'C': 0.01, 'gamma': 0.1}\n",
      "0.966 (+/-0.015) for {'C': 0.01, 'gamma': 0.3}\n",
      "0.966 (+/-0.015) for {'C': 0.01, 'gamma': 1}\n",
      "0.966 (+/-0.015) for {'C': 0.01, 'gamma': 3}\n",
      "0.966 (+/-0.015) for {'C': 0.01, 'gamma': 10}\n",
      "0.966 (+/-0.015) for {'C': 0.03, 'gamma': 'scale'}\n",
      "0.966 (+/-0.015) for {'C': 0.03, 'gamma': 'auto'}\n",
      "0.966 (+/-0.015) for {'C': 0.03, 'gamma': 0.01}\n",
      "0.966 (+/-0.015) for {'C': 0.03, 'gamma': 0.03}\n",
      "0.966 (+/-0.015) for {'C': 0.03, 'gamma': 0.1}\n",
      "0.966 (+/-0.015) for {'C': 0.03, 'gamma': 0.3}\n",
      "0.966 (+/-0.015) for {'C': 0.03, 'gamma': 1}\n",
      "0.966 (+/-0.015) for {'C': 0.03, 'gamma': 3}\n",
      "0.966 (+/-0.015) for {'C': 0.03, 'gamma': 10}\n",
      "0.966 (+/-0.015) for {'C': 0.1, 'gamma': 'scale'}\n",
      "0.966 (+/-0.015) for {'C': 0.1, 'gamma': 'auto'}\n",
      "0.966 (+/-0.015) for {'C': 0.1, 'gamma': 0.01}\n",
      "0.966 (+/-0.015) for {'C': 0.1, 'gamma': 0.03}\n",
      "0.966 (+/-0.015) for {'C': 0.1, 'gamma': 0.1}\n",
      "0.966 (+/-0.015) for {'C': 0.1, 'gamma': 0.3}\n",
      "0.966 (+/-0.015) for {'C': 0.1, 'gamma': 1}\n",
      "0.966 (+/-0.015) for {'C': 0.1, 'gamma': 3}\n",
      "0.966 (+/-0.015) for {'C': 0.1, 'gamma': 10}\n",
      "0.966 (+/-0.015) for {'C': 0.3, 'gamma': 'scale'}\n",
      "0.966 (+/-0.015) for {'C': 0.3, 'gamma': 'auto'}\n",
      "0.966 (+/-0.015) for {'C': 0.3, 'gamma': 0.01}\n",
      "0.966 (+/-0.015) for {'C': 0.3, 'gamma': 0.03}\n",
      "0.966 (+/-0.015) for {'C': 0.3, 'gamma': 0.1}\n",
      "0.966 (+/-0.015) for {'C': 0.3, 'gamma': 0.3}\n",
      "0.966 (+/-0.015) for {'C': 0.3, 'gamma': 1}\n",
      "0.966 (+/-0.015) for {'C': 0.3, 'gamma': 3}\n",
      "0.966 (+/-0.015) for {'C': 0.3, 'gamma': 10}\n",
      "0.966 (+/-0.015) for {'C': 1, 'gamma': 'scale'}\n",
      "0.966 (+/-0.015) for {'C': 1, 'gamma': 'auto'}\n",
      "0.966 (+/-0.015) for {'C': 1, 'gamma': 0.01}\n",
      "0.966 (+/-0.015) for {'C': 1, 'gamma': 0.03}\n",
      "0.966 (+/-0.015) for {'C': 1, 'gamma': 0.1}\n",
      "0.966 (+/-0.015) for {'C': 1, 'gamma': 0.3}\n",
      "0.966 (+/-0.015) for {'C': 1, 'gamma': 1}\n",
      "0.966 (+/-0.015) for {'C': 1, 'gamma': 3}\n",
      "0.966 (+/-0.015) for {'C': 1, 'gamma': 10}\n",
      "0.966 (+/-0.015) for {'C': 3, 'gamma': 'scale'}\n",
      "0.966 (+/-0.015) for {'C': 3, 'gamma': 'auto'}\n",
      "0.963 (+/-0.024) for {'C': 3, 'gamma': 0.01}\n",
      "0.966 (+/-0.015) for {'C': 3, 'gamma': 0.03}\n",
      "0.966 (+/-0.015) for {'C': 3, 'gamma': 0.1}\n",
      "0.966 (+/-0.015) for {'C': 3, 'gamma': 0.3}\n",
      "0.966 (+/-0.015) for {'C': 3, 'gamma': 1}\n",
      "0.966 (+/-0.015) for {'C': 3, 'gamma': 3}\n",
      "0.966 (+/-0.015) for {'C': 3, 'gamma': 10}\n",
      "0.966 (+/-0.015) for {'C': 10, 'gamma': 'scale'}\n",
      "0.966 (+/-0.015) for {'C': 10, 'gamma': 'auto'}\n",
      "0.963 (+/-0.024) for {'C': 10, 'gamma': 0.01}\n",
      "0.966 (+/-0.015) for {'C': 10, 'gamma': 0.03}\n",
      "0.966 (+/-0.015) for {'C': 10, 'gamma': 0.1}\n",
      "0.966 (+/-0.015) for {'C': 10, 'gamma': 0.3}\n",
      "0.966 (+/-0.015) for {'C': 10, 'gamma': 1}\n",
      "0.966 (+/-0.015) for {'C': 10, 'gamma': 3}\n",
      "0.966 (+/-0.015) for {'C': 10, 'gamma': 10}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.966\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'C': 0.01, 'gamma': 'scale'}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        65\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.97        67\n",
      "   macro avg       0.49      0.50      0.49        67\n",
      "weighted avg       0.94      0.97      0.96        67\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[65  0]\n",
      " [ 2  0]]\n",
      "\n",
      "*** Final accuracy score: \n",
      "0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.97,\n",
       " 'Logistic Regression': 0.97,\n",
       " 'Decision Trees': 0.97,\n",
       " 'Random Forest': 0.97,\n",
       " 'Linear SVMs': 0.97,\n",
       " 'Kernelized SVMs': 0.97}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{\"C\": [0.01, 0.03, 0.1, 0.3, 1, 3, 10], \"gamma\": [\"scale\", \"auto\", 0.01, 0.03, 0.1, 0.3, 1, 3, 10]}]\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = GridSearchCV(SVC(random_state=0), param_grid, cv=cv)\n",
    "svc, score = train_test2(X_train, X_test, y_train, y_test, param_grid, svc)\n",
    "summary2[\"Kernelized SVMs\"] = score\n",
    "summary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "27428f5d-a0a2-4018-86ee-b1b3f5115676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.03845387, 0.11582527, 0.03956838, 0.03720169, 0.10496726,\n",
      "       0.12545953, 0.16902094, 0.27187705, 0.07630239]), 'std_fit_time': array([0.00414517, 0.06027077, 0.00295537, 0.00573436, 0.06369191,\n",
      "       0.05122949, 0.00532609, 0.10634331, 0.00170399]), 'mean_score_time': array([0.004847  , 0.0050281 , 0.00444355, 0.00795102, 0.01094561,\n",
      "       0.00527325, 0.00562401, 0.00521441, 0.00499907]), 'std_score_time': array([0.00102954, 0.00107933, 0.0004889 , 0.0012974 , 0.01160592,\n",
      "       0.00103761, 0.00050239, 0.00149827, 0.00062017]), 'param_hidden_layer_sizes': masked_array(data=[(10,), (10,), (10,), (30,), (30,), (30,), (100,),\n",
      "                   (100,), (100,)],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_solver': masked_array(data=['lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
      "                   'lbfgs', 'sgd', 'adam'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'hidden_layer_sizes': (10,), 'solver': 'lbfgs'}, {'hidden_layer_sizes': (10,), 'solver': 'sgd'}, {'hidden_layer_sizes': (10,), 'solver': 'adam'}, {'hidden_layer_sizes': (30,), 'solver': 'lbfgs'}, {'hidden_layer_sizes': (30,), 'solver': 'sgd'}, {'hidden_layer_sizes': (30,), 'solver': 'adam'}, {'hidden_layer_sizes': (100,), 'solver': 'lbfgs'}, {'hidden_layer_sizes': (100,), 'solver': 'sgd'}, {'hidden_layer_sizes': (100,), 'solver': 'adam'}], 'split0_test_score': array([0.96296296, 0.03703704, 0.94444444, 0.96296296, 0.96296296,\n",
      "       0.96296296, 0.96296296, 0.96296296, 0.96296296]), 'split1_test_score': array([0.96296296, 0.96296296, 0.94444444, 0.96296296, 0.96296296,\n",
      "       0.90740741, 0.96296296, 0.96296296, 0.96296296]), 'split2_test_score': array([0.98113208, 0.98113208, 0.96226415, 0.98113208, 0.98113208,\n",
      "       0.98113208, 0.98113208, 0.98113208, 0.98113208]), 'split3_test_score': array([0.96226415, 0.96226415, 0.98113208, 0.96226415, 0.79245283,\n",
      "       0.90566038, 0.96226415, 0.96226415, 0.96226415]), 'split4_test_score': array([0.96226415, 0.96226415, 0.94339623, 0.96226415, 0.96226415,\n",
      "       0.96226415, 0.96226415, 0.96226415, 0.96226415]), 'mean_test_score': array([0.96631726, 0.78113208, 0.95513627, 0.96631726, 0.932355  ,\n",
      "       0.94388539, 0.96631726, 0.96631726, 0.96631726]), 'std_test_score': array([0.007414  , 0.3721176 , 0.01478545, 0.007414  , 0.07031369,\n",
      "       0.0312437 , 0.007414  , 0.007414  , 0.007414  ]), 'rank_test_score': array([1, 9, 6, 1, 8, 7, 1, 1, 1])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.966 (+/-0.015) for {'hidden_layer_sizes': (10,), 'solver': 'lbfgs'}\n",
      "0.781 (+/-0.744) for {'hidden_layer_sizes': (10,), 'solver': 'sgd'}\n",
      "0.955 (+/-0.03) for {'hidden_layer_sizes': (10,), 'solver': 'adam'}\n",
      "0.966 (+/-0.015) for {'hidden_layer_sizes': (30,), 'solver': 'lbfgs'}\n",
      "0.932 (+/-0.141) for {'hidden_layer_sizes': (30,), 'solver': 'sgd'}\n",
      "0.944 (+/-0.062) for {'hidden_layer_sizes': (30,), 'solver': 'adam'}\n",
      "0.966 (+/-0.015) for {'hidden_layer_sizes': (100,), 'solver': 'lbfgs'}\n",
      "0.966 (+/-0.015) for {'hidden_layer_sizes': (100,), 'solver': 'sgd'}\n",
      "0.966 (+/-0.015) for {'hidden_layer_sizes': (100,), 'solver': 'adam'}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.966\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'hidden_layer_sizes': (10,), 'solver': 'lbfgs'}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        65\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.97        67\n",
      "   macro avg       0.49      0.50      0.49        67\n",
      "weighted avg       0.94      0.97      0.96        67\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[65  0]\n",
      " [ 2  0]]\n",
      "\n",
      "*** Final accuracy score: \n",
      "0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.97,\n",
       " 'Logistic Regression': 0.97,\n",
       " 'Decision Trees': 0.97,\n",
       " 'Random Forest': 0.97,\n",
       " 'Linear SVMs': 0.97,\n",
       " 'Kernelized SVMs': 0.97,\n",
       " 'Neural Networks': 0.97}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{\"hidden_layer_sizes\": [(10,), (30,), (100,)], \"solver\": [\"lbfgs\", \"sgd\", \"adam\"]}]\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlpc = GridSearchCV(MLPClassifier(random_state=0), param_grid, cv=cv)\n",
    "mlpc, score = train_test2(X_train, X_test, y_train, y_test, param_grid, mlpc)\n",
    "summary2[\"Neural Networks\"] = score\n",
    "summary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b2673f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.97,\n",
       " 'Logistic Regression': 0.97,\n",
       " 'Decision Trees': 0.97,\n",
       " 'Random Forest': 0.97,\n",
       " 'Linear SVMs': 0.97,\n",
       " 'Kernelized SVMs': 0.97,\n",
       " 'Neural Networks': 0.97}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bfa12336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(random_state=0),\n",
       "             param_grid=[{'C': [0.01, 0.03, 0.1, 0.3, 1, 3, 10],\n",
       "                          'gamma': ['scale', 'auto', 0.01, 0.03, 0.1, 0.3, 1, 3,\n",
       "                                    10]}])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_best = svc\n",
    "clf_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8eb83d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[65  0]\n",
      " [ 2  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        65\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.97        67\n",
      "   macro avg       0.49      0.50      0.49        67\n",
      "weighted avg       0.94      0.97      0.96        67\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\max\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = y_test, clf_best.predict(X_test)\n",
    "\n",
    "print(metrics.confusion_matrix(y_true, y_pred))\n",
    "print(metrics.classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf5793d",
   "metadata": {},
   "source": [
    "### Clsutering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a0271ef5-cb6e-498c-a987-56e22363aa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"W\",\"L\",\"OT\",\"P\",\"P%\",\"RW\",\"ROW\",\"S/O Win\",\"GF\",\"GA\",\"GF/GP\",\"GA/GP\",\"PP%\",\"PK%\",\"Net PP%\",\"Net PK%\",\"Shots/GP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2bfcc556-317f-4ca5-9c92-9e613a54b0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stats[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6134f937-9a5b-4e8a-95eb-ab5a3a95c6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=5, random_state=0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=0)\n",
    "kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "705c88af-9247-4b59-b935-516531730973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=5, random_state=0)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1b2c579c-d6fc-42fc-89ee-251ce191f44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1,\n",
       "       4, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 2, 2, 2, 2, 3, 3, 3, 2, 2, 2, 2,\n",
       "       2, 3, 3, 2, 2, 2, 2, 2, 2, 3, 1, 1, 3, 1, 2, 2, 1, 2, 3, 2, 3, 3,\n",
       "       0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 0, 3, 3, 3, 2, 3, 0,\n",
       "       0, 3, 0, 2, 0, 0, 0, 3, 0, 0, 0, 3, 3, 3, 0, 3, 0, 0, 0, 3, 3, 0,\n",
       "       2, 3, 0, 3, 3, 2, 2, 2, 0, 2, 0, 0, 3, 0, 3, 0, 0, 3, 0, 2, 3, 2,\n",
       "       2, 0, 3, 3, 2, 2, 2, 3, 2, 2, 2, 3, 2, 3, 2, 3, 2, 2, 2, 0, 0, 3,\n",
       "       1, 2, 2, 2, 2, 0, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,\n",
       "       2, 0, 2, 2, 3, 2, 3, 3, 1, 0, 2, 3, 2, 2, 3, 2, 2, 3, 3, 2, 0, 2,\n",
       "       2, 2, 2, 2, 2, 2, 3, 2, 2, 0, 2, 2, 3, 2, 2, 3, 2, 3, 2, 2, 2, 2,\n",
       "       3, 2, 3, 3, 3, 3, 2, 2, 0, 2, 3, 2, 3, 0, 3, 3, 0, 2, 2, 2, 2, 2,\n",
       "       2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 3, 2, 0, 0, 0, 2, 3, 0, 3, 3, 2,\n",
       "       3, 2, 0, 2, 2, 2, 2, 2, 3, 2, 3, 2, 1, 2, 2, 3, 3, 3, 1, 3, 2, 0,\n",
       "       2, 2, 0, 2, 3, 3, 3, 2, 3, 0, 2, 0, 0, 2, 2, 0, 3, 3, 2, 0, 2, 2,\n",
       "       2, 2, 3, 3])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2a3ee042-a724-4a70-a0f8-4245b30295ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats[\"label\"] = kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "362dd391-68c5-4475-b5a1-8c5ccc5cc29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    118\n",
       "3     89\n",
       "0     57\n",
       "1     37\n",
       "4     33\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.label.value_counts()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49711a85",
   "metadata": {},
   "source": [
    "### Highest PK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5c9eaa5d-a876-42e6-bc40-0a32ef258813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Season</th>\n",
       "      <th>GP</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>OT</th>\n",
       "      <th>P</th>\n",
       "      <th>P%</th>\n",
       "      <th>RW</th>\n",
       "      <th>ROW</th>\n",
       "      <th>S/O Win</th>\n",
       "      <th>GF</th>\n",
       "      <th>GA</th>\n",
       "      <th>GF/GP</th>\n",
       "      <th>GA/GP</th>\n",
       "      <th>PP%</th>\n",
       "      <th>PK%</th>\n",
       "      <th>Net PP%</th>\n",
       "      <th>Net PK%</th>\n",
       "      <th>Shots/GP</th>\n",
       "      <th>SA/GP</th>\n",
       "      <th>FOW%</th>\n",
       "      <th>cup</th>\n",
       "      <th>rp</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Los Angeles Kings</td>\n",
       "      <td>20132014</td>\n",
       "      <td>82</td>\n",
       "      <td>46</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>0.610</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "      <td>198</td>\n",
       "      <td>168</td>\n",
       "      <td>2.41</td>\n",
       "      <td>2.05</td>\n",
       "      <td>15.1</td>\n",
       "      <td>83.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>84.8</td>\n",
       "      <td>31.6</td>\n",
       "      <td>26.2</td>\n",
       "      <td>52.8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Dallas Stars</td>\n",
       "      <td>20132014</td>\n",
       "      <td>82</td>\n",
       "      <td>40</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>91</td>\n",
       "      <td>0.555</td>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>231</td>\n",
       "      <td>223</td>\n",
       "      <td>2.82</td>\n",
       "      <td>2.72</td>\n",
       "      <td>15.9</td>\n",
       "      <td>81.4</td>\n",
       "      <td>14.1</td>\n",
       "      <td>84.4</td>\n",
       "      <td>31.7</td>\n",
       "      <td>30.4</td>\n",
       "      <td>50.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Florida Panthers</td>\n",
       "      <td>20112012</td>\n",
       "      <td>82</td>\n",
       "      <td>38</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "      <td>94</td>\n",
       "      <td>0.573</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>197</td>\n",
       "      <td>216</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.63</td>\n",
       "      <td>18.5</td>\n",
       "      <td>79.5</td>\n",
       "      <td>16.4</td>\n",
       "      <td>81.2</td>\n",
       "      <td>29.7</td>\n",
       "      <td>30.5</td>\n",
       "      <td>50.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Washington Capitals</td>\n",
       "      <td>20192020</td>\n",
       "      <td>69</td>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>90</td>\n",
       "      <td>0.652</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>236</td>\n",
       "      <td>212</td>\n",
       "      <td>3.42</td>\n",
       "      <td>3.07</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82.6</td>\n",
       "      <td>15.3</td>\n",
       "      <td>85.1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>30.2</td>\n",
       "      <td>48.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Columbus Blue Jackets</td>\n",
       "      <td>20132014</td>\n",
       "      <td>82</td>\n",
       "      <td>43</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "      <td>0.567</td>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>226</td>\n",
       "      <td>214</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.61</td>\n",
       "      <td>19.3</td>\n",
       "      <td>82.1</td>\n",
       "      <td>16.4</td>\n",
       "      <td>85.4</td>\n",
       "      <td>29.6</td>\n",
       "      <td>30.8</td>\n",
       "      <td>51.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>St. Louis Blues</td>\n",
       "      <td>20172018</td>\n",
       "      <td>82</td>\n",
       "      <td>44</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>94</td>\n",
       "      <td>0.573</td>\n",
       "      <td>33</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>223</td>\n",
       "      <td>222</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.71</td>\n",
       "      <td>15.5</td>\n",
       "      <td>79.7</td>\n",
       "      <td>11.8</td>\n",
       "      <td>81.8</td>\n",
       "      <td>32.6</td>\n",
       "      <td>29.7</td>\n",
       "      <td>50.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Tampa Bay Lightning</td>\n",
       "      <td>20192020</td>\n",
       "      <td>70</td>\n",
       "      <td>43</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>92</td>\n",
       "      <td>0.657</td>\n",
       "      <td>35</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>243</td>\n",
       "      <td>194</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.77</td>\n",
       "      <td>23.1</td>\n",
       "      <td>81.4</td>\n",
       "      <td>19.8</td>\n",
       "      <td>84.0</td>\n",
       "      <td>31.1</td>\n",
       "      <td>30.9</td>\n",
       "      <td>50.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>St. Louis Blues</td>\n",
       "      <td>20192020</td>\n",
       "      <td>71</td>\n",
       "      <td>42</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>94</td>\n",
       "      <td>0.662</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>223</td>\n",
       "      <td>190</td>\n",
       "      <td>3.14</td>\n",
       "      <td>2.68</td>\n",
       "      <td>24.3</td>\n",
       "      <td>79.3</td>\n",
       "      <td>21.3</td>\n",
       "      <td>81.8</td>\n",
       "      <td>30.7</td>\n",
       "      <td>29.6</td>\n",
       "      <td>51.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Florida Panthers</td>\n",
       "      <td>20152016</td>\n",
       "      <td>82</td>\n",
       "      <td>47</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>103</td>\n",
       "      <td>0.628</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>232</td>\n",
       "      <td>200</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.44</td>\n",
       "      <td>16.9</td>\n",
       "      <td>79.5</td>\n",
       "      <td>15.1</td>\n",
       "      <td>81.3</td>\n",
       "      <td>28.8</td>\n",
       "      <td>29.5</td>\n",
       "      <td>50.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Colorado Avalanche</td>\n",
       "      <td>20142015</td>\n",
       "      <td>82</td>\n",
       "      <td>39</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>90</td>\n",
       "      <td>0.549</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>209</td>\n",
       "      <td>223</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.72</td>\n",
       "      <td>15.0</td>\n",
       "      <td>84.7</td>\n",
       "      <td>14.2</td>\n",
       "      <td>86.3</td>\n",
       "      <td>27.9</td>\n",
       "      <td>33.2</td>\n",
       "      <td>50.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Team    Season  GP   W   L  OT    P     P%  RW  ROW  \\\n",
       "238      Los Angeles Kings  20132014  82  46  28   8  100  0.610  34   38   \n",
       "237           Dallas Stars  20132014  82  40  31  11   91  0.555  34   36   \n",
       "285       Florida Panthers  20112012  82  38  26  18   94  0.573  31   32   \n",
       "44     Washington Capitals  20192020  69  41  20   8   90  0.652  31   37   \n",
       "241  Columbus Blue Jackets  20132014  82  43  32   7   93  0.567  35   38   \n",
       "110        St. Louis Blues  20172018  82  44  32   6   94  0.573  33   41   \n",
       "43     Tampa Bay Lightning  20192020  70  43  21   6   92  0.657  35   41   \n",
       "48         St. Louis Blues  20192020  71  42  19  10   94  0.662  33   40   \n",
       "165       Florida Panthers  20152016  82  47  26   9  103  0.628  39   40   \n",
       "203     Colorado Avalanche  20142015  82  39  31  12   90  0.549  27   29   \n",
       "\n",
       "     S/O Win   GF   GA  GF/GP  GA/GP   PP%   PK%  Net PP%  Net PK%  Shots/GP  \\\n",
       "238        8  198  168   2.41   2.05  15.1  83.1     13.0     84.8      31.6   \n",
       "237        4  231  223   2.82   2.72  15.9  81.4     14.1     84.4      31.7   \n",
       "285        6  197  216   2.40   2.63  18.5  79.5     16.4     81.2      29.7   \n",
       "44         4  236  212   3.42   3.07  19.4  82.6     15.3     85.1      32.0   \n",
       "241        5  226  214   2.76   2.61  19.3  82.1     16.4     85.4      29.6   \n",
       "110        3  223  222   2.72   2.71  15.5  79.7     11.8     81.8      32.6   \n",
       "43         2  243  194   3.47   2.77  23.1  81.4     19.8     84.0      31.1   \n",
       "48         2  223  190   3.14   2.68  24.3  79.3     21.3     81.8      30.7   \n",
       "165        7  232  200   2.83   2.44  16.9  79.5     15.1     81.3      28.8   \n",
       "203       10  209  223   2.55   2.72  15.0  84.7     14.2     86.3      27.9   \n",
       "\n",
       "     SA/GP  FOW%  cup  rp  label  \n",
       "238   26.2  52.8    1   4      2  \n",
       "237   30.4  50.1    0   1      2  \n",
       "285   30.5  50.6    0   1      2  \n",
       "44    30.2  48.3    0   1      2  \n",
       "241   30.8  51.6    0   1      2  \n",
       "110   29.7  50.6    0   0      2  \n",
       "43    30.9  50.5    1   4      2  \n",
       "48    29.6  51.6    0   1      2  \n",
       "165   29.5  50.1    0   1      2  \n",
       "203   33.2  50.8    0   0      2  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats[stats.label == 2].sample(n=10, random_state=0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bbff0e",
   "metadata": {},
   "source": [
    "### worst wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d17e4c92-85dc-4a24-8921-06c2e4230e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Season</th>\n",
       "      <th>GP</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>OT</th>\n",
       "      <th>P</th>\n",
       "      <th>P%</th>\n",
       "      <th>RW</th>\n",
       "      <th>ROW</th>\n",
       "      <th>S/O Win</th>\n",
       "      <th>GF</th>\n",
       "      <th>GA</th>\n",
       "      <th>GF/GP</th>\n",
       "      <th>GA/GP</th>\n",
       "      <th>PP%</th>\n",
       "      <th>PK%</th>\n",
       "      <th>Net PP%</th>\n",
       "      <th>Net PK%</th>\n",
       "      <th>Shots/GP</th>\n",
       "      <th>SA/GP</th>\n",
       "      <th>FOW%</th>\n",
       "      <th>cup</th>\n",
       "      <th>rp</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Montréal Canadiens</td>\n",
       "      <td>20192020</td>\n",
       "      <td>71</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>0.500</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>208</td>\n",
       "      <td>220</td>\n",
       "      <td>2.93</td>\n",
       "      <td>3.10</td>\n",
       "      <td>17.7</td>\n",
       "      <td>78.7</td>\n",
       "      <td>15.1</td>\n",
       "      <td>81.5</td>\n",
       "      <td>34.1</td>\n",
       "      <td>31.1</td>\n",
       "      <td>50.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Detroit Red Wings</td>\n",
       "      <td>20182019</td>\n",
       "      <td>82</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>74</td>\n",
       "      <td>0.451</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>224</td>\n",
       "      <td>272</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3.32</td>\n",
       "      <td>18.1</td>\n",
       "      <td>77.1</td>\n",
       "      <td>14.8</td>\n",
       "      <td>80.0</td>\n",
       "      <td>29.2</td>\n",
       "      <td>33.7</td>\n",
       "      <td>50.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Buffalo Sabres</td>\n",
       "      <td>20142015</td>\n",
       "      <td>82</td>\n",
       "      <td>23</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>54</td>\n",
       "      <td>0.329</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>153</td>\n",
       "      <td>269</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.28</td>\n",
       "      <td>13.4</td>\n",
       "      <td>75.1</td>\n",
       "      <td>9.8</td>\n",
       "      <td>77.8</td>\n",
       "      <td>24.2</td>\n",
       "      <td>35.6</td>\n",
       "      <td>44.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Montréal Canadiens</td>\n",
       "      <td>20152016</td>\n",
       "      <td>82</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>82</td>\n",
       "      <td>0.500</td>\n",
       "      <td>30</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>216</td>\n",
       "      <td>233</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.84</td>\n",
       "      <td>16.2</td>\n",
       "      <td>81.9</td>\n",
       "      <td>12.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>29.4</td>\n",
       "      <td>50.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Calgary Flames</td>\n",
       "      <td>20132014</td>\n",
       "      <td>82</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>77</td>\n",
       "      <td>0.470</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>202</td>\n",
       "      <td>238</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.90</td>\n",
       "      <td>15.7</td>\n",
       "      <td>81.7</td>\n",
       "      <td>12.9</td>\n",
       "      <td>86.8</td>\n",
       "      <td>26.8</td>\n",
       "      <td>28.6</td>\n",
       "      <td>46.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>New Jersey Devils</td>\n",
       "      <td>20162017</td>\n",
       "      <td>82</td>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "      <td>14</td>\n",
       "      <td>70</td>\n",
       "      <td>0.427</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>180</td>\n",
       "      <td>241</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.94</td>\n",
       "      <td>17.5</td>\n",
       "      <td>79.6</td>\n",
       "      <td>12.8</td>\n",
       "      <td>81.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>31.4</td>\n",
       "      <td>49.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Calgary Flames</td>\n",
       "      <td>20152016</td>\n",
       "      <td>82</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>77</td>\n",
       "      <td>0.470</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>229</td>\n",
       "      <td>257</td>\n",
       "      <td>2.79</td>\n",
       "      <td>3.13</td>\n",
       "      <td>17.0</td>\n",
       "      <td>75.5</td>\n",
       "      <td>14.4</td>\n",
       "      <td>79.8</td>\n",
       "      <td>29.2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>48.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Toronto Maple Leafs</td>\n",
       "      <td>20152016</td>\n",
       "      <td>82</td>\n",
       "      <td>29</td>\n",
       "      <td>42</td>\n",
       "      <td>11</td>\n",
       "      <td>69</td>\n",
       "      <td>0.421</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>192</td>\n",
       "      <td>240</td>\n",
       "      <td>2.34</td>\n",
       "      <td>2.93</td>\n",
       "      <td>15.4</td>\n",
       "      <td>81.6</td>\n",
       "      <td>12.4</td>\n",
       "      <td>82.7</td>\n",
       "      <td>30.7</td>\n",
       "      <td>30.5</td>\n",
       "      <td>50.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Minnesota Wild</td>\n",
       "      <td>20112012</td>\n",
       "      <td>82</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>81</td>\n",
       "      <td>0.494</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>166</td>\n",
       "      <td>217</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2.65</td>\n",
       "      <td>15.1</td>\n",
       "      <td>82.1</td>\n",
       "      <td>13.6</td>\n",
       "      <td>83.9</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.4</td>\n",
       "      <td>51.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Minnesota Wild</td>\n",
       "      <td>20102011</td>\n",
       "      <td>82</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>86</td>\n",
       "      <td>0.524</td>\n",
       "      <td>31</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>203</td>\n",
       "      <td>228</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.78</td>\n",
       "      <td>18.2</td>\n",
       "      <td>82.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>85.1</td>\n",
       "      <td>26.2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>50.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Team    Season  GP   W   L  OT   P     P%  RW  ROW  \\\n",
       "38    Montréal Canadiens  20192020  71  31  31   9  71  0.500  19   27   \n",
       "77     Detroit Red Wings  20182019  82  32  40  10  74  0.451  20   29   \n",
       "190       Buffalo Sabres  20142015  82  23  51   8  54  0.329  14   15   \n",
       "161   Montréal Canadiens  20152016  82  38  38   6  82  0.500  30   33   \n",
       "232       Calgary Flames  20132014  82  35  40   7  77  0.470  21   28   \n",
       "124    New Jersey Devils  20162017  82  28  40  14  70  0.427  18   25   \n",
       "172       Calgary Flames  20152016  82  35  40   7  77  0.470  24   33   \n",
       "163  Toronto Maple Leafs  20152016  82  29  42  11  69  0.421  20   23   \n",
       "302       Minnesota Wild  20112012  82  35  36  11  81  0.494  22   24   \n",
       "333       Minnesota Wild  20102011  82  39  35   8  86  0.524  31   36   \n",
       "\n",
       "     S/O Win   GF   GA  GF/GP  GA/GP   PP%   PK%  Net PP%  Net PK%  Shots/GP  \\\n",
       "38         4  208  220   2.93   3.10  17.7  78.7     15.1     81.5      34.1   \n",
       "77         3  224  272   2.73   3.32  18.1  77.1     14.8     80.0      29.2   \n",
       "190        8  153  269   1.87   3.28  13.4  75.1      9.8     77.8      24.2   \n",
       "161        5  216  233   2.63   2.84  16.2  81.9     12.0     85.0      30.5   \n",
       "232        7  202  238   2.46   2.90  15.7  81.7     12.9     86.8      26.8   \n",
       "124        3  180  241   2.20   2.94  17.5  79.6     12.8     81.9      27.8   \n",
       "172        2  229  257   2.79   3.13  17.0  75.5     14.4     79.8      29.2   \n",
       "163        6  192  240   2.34   2.93  15.4  81.6     12.4     82.7      30.7   \n",
       "302       11  166  217   2.02   2.65  15.1  82.1     13.6     83.9      26.5   \n",
       "333        3  203  228   2.48   2.78  18.2  82.8     15.8     85.1      26.2   \n",
       "\n",
       "     SA/GP  FOW%  cup  rp  label  \n",
       "38    31.1  50.4    0   1      3  \n",
       "77    33.7  50.8    0   0      3  \n",
       "190   35.6  44.9    0   0      3  \n",
       "161   29.4  50.3    0   0      3  \n",
       "232   28.6  46.2    0   0      3  \n",
       "124   31.4  49.2    0   0      3  \n",
       "172   29.0  48.6    0   0      3  \n",
       "163   30.5  50.6    0   0      3  \n",
       "302   31.4  51.2    0   0      3  \n",
       "333   32.0  50.8    0   0      3  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats[stats.label == 3].sample(n=10, random_state=0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ab23f",
   "metadata": {},
   "source": [
    "### Shortend NHL season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3f2b50a0-d085-4b95-912a-d5dcf498f214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Season</th>\n",
       "      <th>GP</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>OT</th>\n",
       "      <th>P</th>\n",
       "      <th>P%</th>\n",
       "      <th>RW</th>\n",
       "      <th>ROW</th>\n",
       "      <th>S/O Win</th>\n",
       "      <th>GF</th>\n",
       "      <th>GA</th>\n",
       "      <th>GF/GP</th>\n",
       "      <th>GA/GP</th>\n",
       "      <th>PP%</th>\n",
       "      <th>PK%</th>\n",
       "      <th>Net PP%</th>\n",
       "      <th>Net PK%</th>\n",
       "      <th>Shots/GP</th>\n",
       "      <th>SA/GP</th>\n",
       "      <th>FOW%</th>\n",
       "      <th>cup</th>\n",
       "      <th>rp</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>San Jose Sharks</td>\n",
       "      <td>20202021</td>\n",
       "      <td>56</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "      <td>0.438</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>146</td>\n",
       "      <td>196</td>\n",
       "      <td>2.61</td>\n",
       "      <td>3.50</td>\n",
       "      <td>14.1</td>\n",
       "      <td>80.4</td>\n",
       "      <td>11.5</td>\n",
       "      <td>83.2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>48.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Dallas Stars</td>\n",
       "      <td>20202021</td>\n",
       "      <td>56</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>0.536</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>156</td>\n",
       "      <td>148</td>\n",
       "      <td>2.79</td>\n",
       "      <td>2.64</td>\n",
       "      <td>23.6</td>\n",
       "      <td>79.1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>81.1</td>\n",
       "      <td>30.3</td>\n",
       "      <td>27.1</td>\n",
       "      <td>51.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Calgary Flames</td>\n",
       "      <td>20202021</td>\n",
       "      <td>56</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>0.491</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>160</td>\n",
       "      <td>2.77</td>\n",
       "      <td>2.86</td>\n",
       "      <td>18.3</td>\n",
       "      <td>80.2</td>\n",
       "      <td>14.3</td>\n",
       "      <td>81.4</td>\n",
       "      <td>30.2</td>\n",
       "      <td>28.2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Florida Panthers</td>\n",
       "      <td>20202021</td>\n",
       "      <td>56</td>\n",
       "      <td>37</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>79</td>\n",
       "      <td>0.705</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>151</td>\n",
       "      <td>3.36</td>\n",
       "      <td>2.70</td>\n",
       "      <td>20.5</td>\n",
       "      <td>79.8</td>\n",
       "      <td>18.4</td>\n",
       "      <td>82.1</td>\n",
       "      <td>34.9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Columbus Blue Jackets</td>\n",
       "      <td>20192020</td>\n",
       "      <td>70</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>81</td>\n",
       "      <td>0.579</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>183</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.61</td>\n",
       "      <td>16.4</td>\n",
       "      <td>81.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>83.4</td>\n",
       "      <td>32.5</td>\n",
       "      <td>29.9</td>\n",
       "      <td>48.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>New York Islanders</td>\n",
       "      <td>20192020</td>\n",
       "      <td>68</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.588</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>189</td>\n",
       "      <td>190</td>\n",
       "      <td>2.78</td>\n",
       "      <td>2.79</td>\n",
       "      <td>17.3</td>\n",
       "      <td>80.7</td>\n",
       "      <td>14.3</td>\n",
       "      <td>84.1</td>\n",
       "      <td>29.6</td>\n",
       "      <td>31.2</td>\n",
       "      <td>49.9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>St. Louis Blues</td>\n",
       "      <td>20202021</td>\n",
       "      <td>56</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>63</td>\n",
       "      <td>0.563</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>167</td>\n",
       "      <td>167</td>\n",
       "      <td>2.98</td>\n",
       "      <td>2.98</td>\n",
       "      <td>23.2</td>\n",
       "      <td>77.8</td>\n",
       "      <td>22.6</td>\n",
       "      <td>81.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.8</td>\n",
       "      <td>53.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tampa Bay Lightning</td>\n",
       "      <td>20202021</td>\n",
       "      <td>56</td>\n",
       "      <td>36</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>0.670</td>\n",
       "      <td>29</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>180</td>\n",
       "      <td>145</td>\n",
       "      <td>3.21</td>\n",
       "      <td>2.59</td>\n",
       "      <td>22.2</td>\n",
       "      <td>84.2</td>\n",
       "      <td>20.6</td>\n",
       "      <td>85.8</td>\n",
       "      <td>30.2</td>\n",
       "      <td>28.3</td>\n",
       "      <td>50.1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Philadelphia Flyers</td>\n",
       "      <td>20202021</td>\n",
       "      <td>56</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>58</td>\n",
       "      <td>0.518</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>197</td>\n",
       "      <td>2.86</td>\n",
       "      <td>3.52</td>\n",
       "      <td>19.2</td>\n",
       "      <td>73.1</td>\n",
       "      <td>15.6</td>\n",
       "      <td>73.7</td>\n",
       "      <td>30.2</td>\n",
       "      <td>29.2</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Winnipeg Jets</td>\n",
       "      <td>20202021</td>\n",
       "      <td>56</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>0.563</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>152</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2.71</td>\n",
       "      <td>23.0</td>\n",
       "      <td>80.5</td>\n",
       "      <td>21.1</td>\n",
       "      <td>82.6</td>\n",
       "      <td>29.7</td>\n",
       "      <td>30.6</td>\n",
       "      <td>50.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Team    Season  GP   W   L  OT   P     P%  RW  ROW  \\\n",
       "25        San Jose Sharks  20202021  56  21  28   7  49  0.438  15   16   \n",
       "23           Dallas Stars  20202021  56  23  19  14  60  0.536  17   21   \n",
       "18         Calgary Flames  20202021  56  26  27   3  55  0.491  22   25   \n",
       "11       Florida Panthers  20202021  56  37  14   5  79  0.705  26   36   \n",
       "57  Columbus Blue Jackets  20192020  70  33  22  15  81  0.579  25   33   \n",
       "32     New York Islanders  20192020  68  35  23  10  80  0.588  24   32   \n",
       "17        St. Louis Blues  20202021  56  27  20   9  63  0.563  19   25   \n",
       "12    Tampa Bay Lightning  20202021  56  36  17   3  75  0.670  29   35   \n",
       "3     Philadelphia Flyers  20202021  56  25  23   8  58  0.518  17   22   \n",
       "28          Winnipeg Jets  20202021  56  30  23   3  63  0.563  24   30   \n",
       "\n",
       "    S/O Win   GF   GA  GF/GP  GA/GP   PP%   PK%  Net PP%  Net PK%  Shots/GP  \\\n",
       "25        5  146  196   2.61   3.50  14.1  80.4     11.5     83.2      30.0   \n",
       "23        2  156  148   2.79   2.64  23.6  79.1     21.0     81.1      30.3   \n",
       "18        1  155  160   2.77   2.86  18.3  80.2     14.3     81.4      30.2   \n",
       "11        1  188  151   3.36   2.70  20.5  79.8     18.4     82.1      34.9   \n",
       "57        0  180  183   2.57   2.61  16.4  81.7     13.8     83.4      32.5   \n",
       "32        3  189  190   2.78   2.79  17.3  80.7     14.3     84.1      29.6   \n",
       "17        2  167  167   2.98   2.98  23.2  77.8     22.6     81.3      29.0   \n",
       "12        1  180  145   3.21   2.59  22.2  84.2     20.6     85.8      30.2   \n",
       "3         3  160  197   2.86   3.52  19.2  73.1     15.6     73.7      30.2   \n",
       "28        0  170  152   3.04   2.71  23.0  80.5     21.1     82.6      29.7   \n",
       "\n",
       "    SA/GP  FOW%  cup  rp  label  \n",
       "25   32.0  48.4    0   0      1  \n",
       "23   27.1  51.8    0   0      1  \n",
       "18   28.2  50.0    0   0      1  \n",
       "11   30.0  50.2    0   1      1  \n",
       "57   29.9  48.5    0   1      1  \n",
       "32   31.2  49.9    0   3      1  \n",
       "17   29.8  53.3    0   1      1  \n",
       "12   28.3  50.1    1   4      1  \n",
       "3    29.2  54.0    0   0      1  \n",
       "28   30.6  50.5    0   2      1  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats[stats.label == 1].sample(n=10, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4a272fb1-cd5d-4dac-ba56-6d03b98e5850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>GP</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>OT</th>\n",
       "      <th>P</th>\n",
       "      <th>P%</th>\n",
       "      <th>RW</th>\n",
       "      <th>ROW</th>\n",
       "      <th>S/O Win</th>\n",
       "      <th>GF</th>\n",
       "      <th>GA</th>\n",
       "      <th>GF/GP</th>\n",
       "      <th>GA/GP</th>\n",
       "      <th>PP%</th>\n",
       "      <th>PK%</th>\n",
       "      <th>Net PP%</th>\n",
       "      <th>Net PK%</th>\n",
       "      <th>Shots/GP</th>\n",
       "      <th>SA/GP</th>\n",
       "      <th>FOW%</th>\n",
       "      <th>cup</th>\n",
       "      <th>rp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.015553e+07</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>46.105263</td>\n",
       "      <td>26.859649</td>\n",
       "      <td>9.035088</td>\n",
       "      <td>101.245614</td>\n",
       "      <td>0.617316</td>\n",
       "      <td>36.491228</td>\n",
       "      <td>42.298246</td>\n",
       "      <td>3.807018</td>\n",
       "      <td>258.649123</td>\n",
       "      <td>231.649123</td>\n",
       "      <td>3.154035</td>\n",
       "      <td>2.824386</td>\n",
       "      <td>20.828070</td>\n",
       "      <td>80.963158</td>\n",
       "      <td>18.131579</td>\n",
       "      <td>83.975439</td>\n",
       "      <td>32.014035</td>\n",
       "      <td>30.750877</td>\n",
       "      <td>50.014035</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1.473684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.019256e+07</td>\n",
       "      <td>60.621622</td>\n",
       "      <td>30.135135</td>\n",
       "      <td>23.513514</td>\n",
       "      <td>6.972973</td>\n",
       "      <td>67.243243</td>\n",
       "      <td>0.556919</td>\n",
       "      <td>23.135135</td>\n",
       "      <td>27.864865</td>\n",
       "      <td>2.270270</td>\n",
       "      <td>169.216216</td>\n",
       "      <td>169.945946</td>\n",
       "      <td>2.827568</td>\n",
       "      <td>2.827027</td>\n",
       "      <td>19.727027</td>\n",
       "      <td>80.535135</td>\n",
       "      <td>17.202703</td>\n",
       "      <td>83.113514</td>\n",
       "      <td>30.045946</td>\n",
       "      <td>29.886486</td>\n",
       "      <td>49.821622</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>1.081081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.014659e+07</td>\n",
       "      <td>80.127119</td>\n",
       "      <td>43.940678</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>9.186441</td>\n",
       "      <td>97.067797</td>\n",
       "      <td>0.605746</td>\n",
       "      <td>34.050847</td>\n",
       "      <td>39.271186</td>\n",
       "      <td>4.669492</td>\n",
       "      <td>224.618644</td>\n",
       "      <td>204.949153</td>\n",
       "      <td>2.812797</td>\n",
       "      <td>2.566441</td>\n",
       "      <td>19.165254</td>\n",
       "      <td>82.266949</td>\n",
       "      <td>16.905932</td>\n",
       "      <td>84.768644</td>\n",
       "      <td>30.605085</td>\n",
       "      <td>29.749153</td>\n",
       "      <td>50.247458</td>\n",
       "      <td>0.042373</td>\n",
       "      <td>1.305085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.015011e+07</td>\n",
       "      <td>80.943820</td>\n",
       "      <td>32.314607</td>\n",
       "      <td>38.483146</td>\n",
       "      <td>10.146067</td>\n",
       "      <td>74.775281</td>\n",
       "      <td>0.461876</td>\n",
       "      <td>23.382022</td>\n",
       "      <td>28.213483</td>\n",
       "      <td>4.101124</td>\n",
       "      <td>205.078652</td>\n",
       "      <td>247.370787</td>\n",
       "      <td>2.535281</td>\n",
       "      <td>3.058876</td>\n",
       "      <td>17.217978</td>\n",
       "      <td>79.621348</td>\n",
       "      <td>14.269663</td>\n",
       "      <td>82.097753</td>\n",
       "      <td>29.652809</td>\n",
       "      <td>31.562921</td>\n",
       "      <td>49.685393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.012929e+07</td>\n",
       "      <td>48.727273</td>\n",
       "      <td>23.878788</td>\n",
       "      <td>19.151515</td>\n",
       "      <td>5.696970</td>\n",
       "      <td>53.454545</td>\n",
       "      <td>0.549576</td>\n",
       "      <td>18.454545</td>\n",
       "      <td>20.696970</td>\n",
       "      <td>3.181818</td>\n",
       "      <td>127.969697</td>\n",
       "      <td>130.060606</td>\n",
       "      <td>2.630000</td>\n",
       "      <td>2.667576</td>\n",
       "      <td>17.669697</td>\n",
       "      <td>81.675758</td>\n",
       "      <td>15.687879</td>\n",
       "      <td>83.575758</td>\n",
       "      <td>29.006061</td>\n",
       "      <td>29.248485</td>\n",
       "      <td>50.078788</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.969697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Season         GP          W          L         OT           P  \\\n",
       "label                                                                         \n",
       "0      2.015553e+07  82.000000  46.105263  26.859649   9.035088  101.245614   \n",
       "1      2.019256e+07  60.621622  30.135135  23.513514   6.972973   67.243243   \n",
       "2      2.014659e+07  80.127119  43.940678  27.000000   9.186441   97.067797   \n",
       "3      2.015011e+07  80.943820  32.314607  38.483146  10.146067   74.775281   \n",
       "4      2.012929e+07  48.727273  23.878788  19.151515   5.696970   53.454545   \n",
       "\n",
       "             P%         RW        ROW   S/O Win          GF          GA  \\\n",
       "label                                                                     \n",
       "0      0.617316  36.491228  42.298246  3.807018  258.649123  231.649123   \n",
       "1      0.556919  23.135135  27.864865  2.270270  169.216216  169.945946   \n",
       "2      0.605746  34.050847  39.271186  4.669492  224.618644  204.949153   \n",
       "3      0.461876  23.382022  28.213483  4.101124  205.078652  247.370787   \n",
       "4      0.549576  18.454545  20.696970  3.181818  127.969697  130.060606   \n",
       "\n",
       "          GF/GP     GA/GP        PP%        PK%    Net PP%    Net PK%  \\\n",
       "label                                                                   \n",
       "0      3.154035  2.824386  20.828070  80.963158  18.131579  83.975439   \n",
       "1      2.827568  2.827027  19.727027  80.535135  17.202703  83.113514   \n",
       "2      2.812797  2.566441  19.165254  82.266949  16.905932  84.768644   \n",
       "3      2.535281  3.058876  17.217978  79.621348  14.269663  82.097753   \n",
       "4      2.630000  2.667576  17.669697  81.675758  15.687879  83.575758   \n",
       "\n",
       "        Shots/GP      SA/GP       FOW%       cup        rp  \n",
       "label                                                       \n",
       "0      32.014035  30.750877  50.014035  0.052632  1.473684  \n",
       "1      30.045946  29.886486  49.821622  0.054054  1.081081  \n",
       "2      30.605085  29.749153  50.247458  0.042373  1.305085  \n",
       "3      29.652809  31.562921  49.685393  0.000000  0.022472  \n",
       "4      29.006061  29.248485  50.078788  0.030303  0.969697  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.groupby(\"label\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4d018d62-e7bb-4a3d-8dfb-2d8d64e52ad6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "aggc = AgglomerativeClustering(n_clusters=3)\n",
    "stats[\"label_aggc\"] = aggc.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "81dc1855-cd0d-458c-a95c-a07209538292",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps=0.5\n",
      "-1    334\n",
      "Name: label_dbscan, dtype: int64\n",
      "\n",
      "eps=1\n",
      "-1    334\n",
      "Name: label_dbscan, dtype: int64\n",
      "\n",
      "eps=2\n",
      "-1    334\n",
      "Name: label_dbscan, dtype: int64\n",
      "\n",
      "eps=3\n",
      "-1    334\n",
      "Name: label_dbscan, dtype: int64\n",
      "\n",
      "eps=4\n",
      "-1    334\n",
      "Name: label_dbscan, dtype: int64\n",
      "\n",
      "eps=5\n",
      "-1    334\n",
      "Name: label_dbscan, dtype: int64\n",
      "\n",
      "eps=6\n",
      "-1    334\n",
      "Name: label_dbscan, dtype: int64\n",
      "\n",
      "eps=7\n",
      "-1    334\n",
      "Name: label_dbscan, dtype: int64\n",
      "\n",
      "eps=8\n",
      "-1    334\n",
      "Name: label_dbscan, dtype: int64\n",
      "\n",
      "eps=9\n",
      "-1    334\n",
      "Name: label_dbscan, dtype: int64\n",
      "\n",
      "eps=10\n",
      "-1    334\n",
      "Name: label_dbscan, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "eps_list = [0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "for eps in eps_list:\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=100)\n",
    "    stats[\"label_dbscan\"] = dbscan.fit_predict(X)\n",
    "\n",
    "    print(f\"eps={eps}\")\n",
    "    print(stats.label_dbscan.value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "048d16aa-0cb0-4c15-aa5c-6af5c4a8b70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1    334\n",
      "Name: label_dbscan, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(stats.label_dbscan.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "204bf56c-8bb8-46de-a6a3-0e7a89b0b216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    221\n",
      "1     61\n",
      "2     52\n",
      "Name: label_aggc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(stats.label_aggc.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "86977aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Season</th>\n",
       "      <th>GP</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>OT</th>\n",
       "      <th>P</th>\n",
       "      <th>P%</th>\n",
       "      <th>RW</th>\n",
       "      <th>ROW</th>\n",
       "      <th>S/O Win</th>\n",
       "      <th>GF</th>\n",
       "      <th>GA</th>\n",
       "      <th>GF/GP</th>\n",
       "      <th>GA/GP</th>\n",
       "      <th>PP%</th>\n",
       "      <th>PK%</th>\n",
       "      <th>Net PP%</th>\n",
       "      <th>Net PK%</th>\n",
       "      <th>Shots/GP</th>\n",
       "      <th>SA/GP</th>\n",
       "      <th>FOW%</th>\n",
       "      <th>cup</th>\n",
       "      <th>rp</th>\n",
       "      <th>label</th>\n",
       "      <th>label_aggc</th>\n",
       "      <th>label_dbscan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Columbus Blue Jackets</td>\n",
       "      <td>20202021</td>\n",
       "      <td>56</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>0.429</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>134</td>\n",
       "      <td>184</td>\n",
       "      <td>2.39</td>\n",
       "      <td>3.29</td>\n",
       "      <td>15.4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>83.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>45.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Pittsburgh Penguins</td>\n",
       "      <td>20122013</td>\n",
       "      <td>48</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0.750</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>162</td>\n",
       "      <td>119</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2.48</td>\n",
       "      <td>24.7</td>\n",
       "      <td>79.6</td>\n",
       "      <td>22.9</td>\n",
       "      <td>80.8</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.2</td>\n",
       "      <td>51.5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Winnipeg Jets</td>\n",
       "      <td>20122013</td>\n",
       "      <td>48</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>0.531</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>126</td>\n",
       "      <td>141</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>13.8</td>\n",
       "      <td>79.7</td>\n",
       "      <td>11.7</td>\n",
       "      <td>80.4</td>\n",
       "      <td>28.9</td>\n",
       "      <td>29.7</td>\n",
       "      <td>48.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Winnipeg Jets</td>\n",
       "      <td>20202021</td>\n",
       "      <td>56</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>0.563</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>152</td>\n",
       "      <td>3.04</td>\n",
       "      <td>2.71</td>\n",
       "      <td>23.0</td>\n",
       "      <td>80.5</td>\n",
       "      <td>21.1</td>\n",
       "      <td>82.6</td>\n",
       "      <td>29.7</td>\n",
       "      <td>30.6</td>\n",
       "      <td>50.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Florida Panthers</td>\n",
       "      <td>20202021</td>\n",
       "      <td>56</td>\n",
       "      <td>37</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>79</td>\n",
       "      <td>0.705</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>188</td>\n",
       "      <td>151</td>\n",
       "      <td>3.36</td>\n",
       "      <td>2.70</td>\n",
       "      <td>20.5</td>\n",
       "      <td>79.8</td>\n",
       "      <td>18.4</td>\n",
       "      <td>82.1</td>\n",
       "      <td>34.9</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New York Rangers</td>\n",
       "      <td>20202021</td>\n",
       "      <td>56</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>0.536</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>176</td>\n",
       "      <td>155</td>\n",
       "      <td>3.14</td>\n",
       "      <td>2.77</td>\n",
       "      <td>20.7</td>\n",
       "      <td>82.3</td>\n",
       "      <td>18.4</td>\n",
       "      <td>87.0</td>\n",
       "      <td>28.7</td>\n",
       "      <td>29.7</td>\n",
       "      <td>44.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Philadelphia Flyers</td>\n",
       "      <td>20122013</td>\n",
       "      <td>48</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>0.510</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>139</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.90</td>\n",
       "      <td>21.6</td>\n",
       "      <td>85.9</td>\n",
       "      <td>19.9</td>\n",
       "      <td>87.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.6</td>\n",
       "      <td>48.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Minnesota Wild</td>\n",
       "      <td>20122013</td>\n",
       "      <td>48</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>0.573</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>118</td>\n",
       "      <td>125</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.60</td>\n",
       "      <td>17.9</td>\n",
       "      <td>80.7</td>\n",
       "      <td>17.9</td>\n",
       "      <td>81.5</td>\n",
       "      <td>28.8</td>\n",
       "      <td>27.1</td>\n",
       "      <td>52.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Toronto Maple Leafs</td>\n",
       "      <td>20122013</td>\n",
       "      <td>48</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>57</td>\n",
       "      <td>0.594</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>128</td>\n",
       "      <td>3.02</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.7</td>\n",
       "      <td>87.9</td>\n",
       "      <td>16.3</td>\n",
       "      <td>88.5</td>\n",
       "      <td>26.3</td>\n",
       "      <td>32.3</td>\n",
       "      <td>50.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Anaheim Ducks</td>\n",
       "      <td>20202021</td>\n",
       "      <td>56</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>43</td>\n",
       "      <td>0.384</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>177</td>\n",
       "      <td>2.21</td>\n",
       "      <td>3.16</td>\n",
       "      <td>8.9</td>\n",
       "      <td>79.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>81.1</td>\n",
       "      <td>26.8</td>\n",
       "      <td>30.6</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Team    Season  GP   W   L  OT   P     P%  RW  ROW  \\\n",
       "26   Columbus Blue Jackets  20202021  56  18  26  12  48  0.429  12   15   \n",
       "248    Pittsburgh Penguins  20122013  48  36  12   0  72  0.750  31   33   \n",
       "273          Winnipeg Jets  20122013  48  24  21   3  51  0.531  18   22   \n",
       "28           Winnipeg Jets  20202021  56  30  23   3  63  0.563  24   30   \n",
       "11        Florida Panthers  20202021  56  37  14   5  79  0.705  26   36   \n",
       "2         New York Rangers  20202021  56  27  23   6  60  0.536  24   26   \n",
       "247    Philadelphia Flyers  20122013  48  23  22   3  49  0.510  20   22   \n",
       "272         Minnesota Wild  20122013  48  26  19   3  55  0.573  19   22   \n",
       "253    Toronto Maple Leafs  20122013  48  26  17   5  57  0.594  24   26   \n",
       "22           Anaheim Ducks  20202021  56  17  30   9  43  0.384  11   15   \n",
       "\n",
       "     S/O Win   GF   GA  GF/GP  GA/GP   PP%   PK%  Net PP%  Net PK%  Shots/GP  \\\n",
       "26         3  134  184   2.39   3.29  15.4  79.0     13.7     83.5      29.0   \n",
       "248        3  162  119   3.38   2.48  24.7  79.6     22.9     80.8      30.0   \n",
       "273        2  126  141   2.63   2.94  13.8  79.7     11.7     80.4      28.9   \n",
       "28         0  170  152   3.04   2.71  23.0  80.5     21.1     82.6      29.7   \n",
       "11         1  188  151   3.36   2.70  20.5  79.8     18.4     82.1      34.9   \n",
       "2          1  176  155   3.14   2.77  20.7  82.3     18.4     87.0      28.7   \n",
       "247        1  132  139   2.75   2.90  21.6  85.9     19.9     87.0      29.0   \n",
       "272        4  118  125   2.46   2.60  17.9  80.7     17.9     81.5      28.8   \n",
       "253        0  145  128   3.02   2.67  18.7  87.9     16.3     88.5      26.3   \n",
       "22         2  124  177   2.21   3.16   8.9  79.9      4.9     81.1      26.8   \n",
       "\n",
       "     SA/GP  FOW%  cup  rp  label  label_aggc  label_dbscan  \n",
       "26    32.4  45.3    0   0      1           1            -1  \n",
       "248   29.2  51.5    0   3      4           1            -1  \n",
       "273   29.7  48.9    0   0      4           1            -1  \n",
       "28    30.6  50.5    0   2      1           1            -1  \n",
       "11    30.0  50.2    0   1      1           1            -1  \n",
       "2     29.7  44.5    0   0      1           1            -1  \n",
       "247   28.6  48.5    0   0      4           1            -1  \n",
       "272   27.1  52.5    0   1      4           1            -1  \n",
       "253   32.3  50.1    0   1      4           1            -1  \n",
       "22    30.6  51.0    0   0      4           1            -1  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats[stats.label_aggc == 1].sample(n=10, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c754c9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Season</th>\n",
       "      <th>GP</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>OT</th>\n",
       "      <th>P</th>\n",
       "      <th>P%</th>\n",
       "      <th>RW</th>\n",
       "      <th>ROW</th>\n",
       "      <th>S/O Win</th>\n",
       "      <th>GF</th>\n",
       "      <th>GA</th>\n",
       "      <th>GF/GP</th>\n",
       "      <th>GA/GP</th>\n",
       "      <th>PP%</th>\n",
       "      <th>PK%</th>\n",
       "      <th>Net PP%</th>\n",
       "      <th>Net PK%</th>\n",
       "      <th>Shots/GP</th>\n",
       "      <th>SA/GP</th>\n",
       "      <th>FOW%</th>\n",
       "      <th>cup</th>\n",
       "      <th>rp</th>\n",
       "      <th>label</th>\n",
       "      <th>label_aggc</th>\n",
       "      <th>label_dbscan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Dallas Stars</td>\n",
       "      <td>20162017</td>\n",
       "      <td>82</td>\n",
       "      <td>34</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>79</td>\n",
       "      <td>0.482</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "      <td>260</td>\n",
       "      <td>2.71</td>\n",
       "      <td>3.17</td>\n",
       "      <td>17.9</td>\n",
       "      <td>73.9</td>\n",
       "      <td>13.6</td>\n",
       "      <td>75.9</td>\n",
       "      <td>30.5</td>\n",
       "      <td>29.7</td>\n",
       "      <td>49.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Arizona Coyotes</td>\n",
       "      <td>20142015</td>\n",
       "      <td>82</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>0.341</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>165</td>\n",
       "      <td>267</td>\n",
       "      <td>2.01</td>\n",
       "      <td>3.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>76.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>78.1</td>\n",
       "      <td>29.2</td>\n",
       "      <td>33.2</td>\n",
       "      <td>51.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Anaheim Ducks</td>\n",
       "      <td>20182019</td>\n",
       "      <td>82</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>80</td>\n",
       "      <td>0.488</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>196</td>\n",
       "      <td>248</td>\n",
       "      <td>2.39</td>\n",
       "      <td>3.02</td>\n",
       "      <td>17.0</td>\n",
       "      <td>79.7</td>\n",
       "      <td>12.3</td>\n",
       "      <td>81.6</td>\n",
       "      <td>27.7</td>\n",
       "      <td>33.2</td>\n",
       "      <td>51.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Buffalo Sabres</td>\n",
       "      <td>20142015</td>\n",
       "      <td>82</td>\n",
       "      <td>23</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>54</td>\n",
       "      <td>0.329</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>153</td>\n",
       "      <td>269</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.28</td>\n",
       "      <td>13.4</td>\n",
       "      <td>75.1</td>\n",
       "      <td>9.8</td>\n",
       "      <td>77.8</td>\n",
       "      <td>24.2</td>\n",
       "      <td>35.6</td>\n",
       "      <td>44.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>New Jersey Devils</td>\n",
       "      <td>20182019</td>\n",
       "      <td>82</td>\n",
       "      <td>31</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>72</td>\n",
       "      <td>0.439</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>219</td>\n",
       "      <td>271</td>\n",
       "      <td>2.67</td>\n",
       "      <td>3.30</td>\n",
       "      <td>17.7</td>\n",
       "      <td>84.3</td>\n",
       "      <td>13.8</td>\n",
       "      <td>88.2</td>\n",
       "      <td>30.3</td>\n",
       "      <td>31.6</td>\n",
       "      <td>49.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Toronto Maple Leafs</td>\n",
       "      <td>20152016</td>\n",
       "      <td>82</td>\n",
       "      <td>29</td>\n",
       "      <td>42</td>\n",
       "      <td>11</td>\n",
       "      <td>69</td>\n",
       "      <td>0.421</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>192</td>\n",
       "      <td>240</td>\n",
       "      <td>2.34</td>\n",
       "      <td>2.93</td>\n",
       "      <td>15.4</td>\n",
       "      <td>81.6</td>\n",
       "      <td>12.4</td>\n",
       "      <td>82.7</td>\n",
       "      <td>30.7</td>\n",
       "      <td>30.5</td>\n",
       "      <td>50.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Ottawa Senators</td>\n",
       "      <td>20132014</td>\n",
       "      <td>82</td>\n",
       "      <td>37</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>88</td>\n",
       "      <td>0.537</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>229</td>\n",
       "      <td>258</td>\n",
       "      <td>2.79</td>\n",
       "      <td>3.15</td>\n",
       "      <td>18.5</td>\n",
       "      <td>80.9</td>\n",
       "      <td>14.8</td>\n",
       "      <td>82.5</td>\n",
       "      <td>32.8</td>\n",
       "      <td>34.7</td>\n",
       "      <td>51.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Edmonton Oilers</td>\n",
       "      <td>20152016</td>\n",
       "      <td>82</td>\n",
       "      <td>31</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>70</td>\n",
       "      <td>0.427</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>199</td>\n",
       "      <td>242</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.95</td>\n",
       "      <td>18.1</td>\n",
       "      <td>81.1</td>\n",
       "      <td>15.6</td>\n",
       "      <td>83.1</td>\n",
       "      <td>29.1</td>\n",
       "      <td>31.1</td>\n",
       "      <td>48.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Colorado Avalanche</td>\n",
       "      <td>20162017</td>\n",
       "      <td>82</td>\n",
       "      <td>22</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>0.293</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>276</td>\n",
       "      <td>2.01</td>\n",
       "      <td>3.37</td>\n",
       "      <td>12.6</td>\n",
       "      <td>76.6</td>\n",
       "      <td>11.7</td>\n",
       "      <td>78.5</td>\n",
       "      <td>28.1</td>\n",
       "      <td>31.7</td>\n",
       "      <td>53.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Philadelphia Flyers</td>\n",
       "      <td>20182019</td>\n",
       "      <td>82</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>82</td>\n",
       "      <td>0.500</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>241</td>\n",
       "      <td>280</td>\n",
       "      <td>2.94</td>\n",
       "      <td>3.41</td>\n",
       "      <td>17.1</td>\n",
       "      <td>78.5</td>\n",
       "      <td>12.4</td>\n",
       "      <td>80.2</td>\n",
       "      <td>31.5</td>\n",
       "      <td>32.5</td>\n",
       "      <td>54.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Team    Season  GP   W   L  OT   P     P%  RW  ROW  \\\n",
       "147         Dallas Stars  20162017  82  34  37  11  79  0.482  28   33   \n",
       "213      Arizona Coyotes  20142015  82  24  50   8  56  0.341  14   19   \n",
       "84         Anaheim Ducks  20182019  82  35  37  10  80  0.488  27   32   \n",
       "190       Buffalo Sabres  20142015  82  23  51   8  54  0.329  14   15   \n",
       "62     New Jersey Devils  20182019  82  31  41  10  72  0.439  24   28   \n",
       "163  Toronto Maple Leafs  20152016  82  29  42  11  69  0.421  20   23   \n",
       "222      Ottawa Senators  20132014  82  37  31  14  88  0.537  27   30   \n",
       "174      Edmonton Oilers  20152016  82  31  43   8  70  0.427  20   27   \n",
       "143   Colorado Avalanche  20162017  82  22  56   4  48  0.293  14   21   \n",
       "65   Philadelphia Flyers  20182019  82  37  37   8  82  0.500  28   34   \n",
       "\n",
       "     S/O Win   GF   GA  GF/GP  GA/GP   PP%   PK%  Net PP%  Net PK%  Shots/GP  \\\n",
       "147        1  222  260   2.71   3.17  17.9  73.9     13.6     75.9      30.5   \n",
       "213        5  165  267   2.01   3.26  20.0  76.7     17.0     78.1      29.2   \n",
       "84         3  196  248   2.39   3.02  17.0  79.7     12.3     81.6      27.7   \n",
       "190        8  153  269   1.87   3.28  13.4  75.1      9.8     77.8      24.2   \n",
       "62         3  219  271   2.67   3.30  17.7  84.3     13.8     88.2      30.3   \n",
       "163        6  192  240   2.34   2.93  15.4  81.6     12.4     82.7      30.7   \n",
       "222        7  229  258   2.79   3.15  18.5  80.9     14.8     82.5      32.8   \n",
       "174        4  199  242   2.43   2.95  18.1  81.1     15.6     83.1      29.1   \n",
       "143        1  165  276   2.01   3.37  12.6  76.6     11.7     78.5      28.1   \n",
       "65         3  241  280   2.94   3.41  17.1  78.5     12.4     80.2      31.5   \n",
       "\n",
       "     SA/GP  FOW%  cup  rp  label  label_aggc  label_dbscan  \n",
       "147   29.7  49.9    0   0      3           2            -1  \n",
       "213   33.2  51.9    0   0      3           2            -1  \n",
       "84    33.2  51.3    0   0      3           2            -1  \n",
       "190   35.6  44.9    0   0      3           2            -1  \n",
       "62    31.6  49.4    0   0      3           2            -1  \n",
       "163   30.5  50.6    0   0      3           2            -1  \n",
       "222   34.7  51.2    0   0      3           2            -1  \n",
       "174   31.1  48.8    0   0      3           2            -1  \n",
       "143   31.7  53.6    0   0      3           2            -1  \n",
       "65    32.5  54.7    0   0      3           2            -1  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats[stats.label_aggc == 2].sample(n=10, random_state=0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6cf3f6",
   "metadata": {},
   "source": [
    "### PK is proabbly the best indicator for future playoff reslults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3430323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
